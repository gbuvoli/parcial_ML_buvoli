

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Ejercicio 4a y 5. EDA y Modelos de ML para Fraud Detection &#8212; Parcial ML 2023-30</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'FRAUD_DETECTIONB';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="EJERCICIO 4B Y 5. PREDICCIONES DE VELOCIDAD DEL VIENTO" href="WIND_SPEED.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Ejercicio 4a y 5. EDA y Modelos de ML para Fraud Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="WIND_SPEED.html">EJERCICIO 4B Y 5. PREDICCIONES DE VELOCIDAD DEL VIENTO</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FFRAUD_DETECTIONB.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/FRAUD_DETECTIONB.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Ejercicio 4a y 5. EDA y Modelos de ML para Fraud Detection</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lectura-de-datos-y-merge">Lectura de datos y merge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manejo-de-datos-nulos">MANEJO DE DATOS NULOS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizaciones-y-estadistica-descriptiva">VISUALIZACIONES Y ESTADISTICA DESCRIPTIVA</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-bivariado">Analisis Bivariado</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering">FEATURE ENGINEERING</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#identificando-columnas-altamente-correlacionadas-con-vif">IDENTIFICANDO COLUMNAS ALTAMENTE CORRELACIONADAS CON VIF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-hot-encoder-para-variables-categoricas">One Hot Encoder para variables categóricas</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluando-modelos-de-clasificacion-fraude">EVALUANDO MODELOS DE CLASIFICACION - FRAUDE</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#oversampling">OVERSAMPLING</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-knn-clasificador">Modelo KNN - Clasificador</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluando-el-modelo">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-ridge">MODELO RIDGE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-lasso-regresion-logistica-con-regularizacion-l1">MODELO LASSO - Regresión Logística con Regularización L1</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-naive-bayes">MODELO NAIVE BAYES</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-xgboost">MODELO XGBoost</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Evaluando el modelo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduccion-de-dataset-para-poder-correr-los-modelos-faltantes">Reducción de dataset para poder correr los modelos faltantes:</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-svm">MODELO SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-mlp">MODELO MLP</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Evaluando el modelo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mejor-modelo">MEJOR MODELO</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ejercicio-4a-y-5-eda-y-modelos-de-ml-para-fraud-detection">
<h1>Ejercicio 4a y 5. EDA y Modelos de ML para Fraud Detection<a class="headerlink" href="#ejercicio-4a-y-5-eda-y-modelos-de-ml-para-fraud-detection" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="lectura-de-datos-y-merge">
<h2>Lectura de datos y merge<a class="headerlink" href="#lectura-de-datos-y-merge" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/train_transaction_new.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">),</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/train_identity_new.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;TransactionID&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/train_transaction_new.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">),</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/train_identity_new.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;TransactionID&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\lib\site-packages\pandas\util\_decorators.py:311,</span> in <span class="ni">deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">305</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_allow_args</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">306</span>     <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">307</span>         <span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">arguments</span><span class="o">=</span><span class="n">arguments</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">308</span>         <span class="ne">FutureWarning</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">309</span>         <span class="n">stacklevel</span><span class="o">=</span><span class="n">stacklevel</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">310</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">311</span> <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\lib\site-packages\pandas\io\parsers\readers.py:680,</span> in <span class="ni">read_csv</span><span class="nt">(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">665</span> <span class="n">kwds_defaults</span> <span class="o">=</span> <span class="n">_refine_defaults_read</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">666</span>     <span class="n">dialect</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">667</span>     <span class="n">delimiter</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">676</span>     <span class="n">defaults</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;delimiter&quot;</span><span class="p">:</span> <span class="s2">&quot;,&quot;</span><span class="p">},</span>
<span class="g g-Whitespace">    </span><span class="mi">677</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">678</span> <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwds_defaults</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">680</span> <span class="k">return</span> <span class="n">_read</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\lib\site-packages\pandas\io\parsers\readers.py:575,</span> in <span class="ni">_read</span><span class="nt">(filepath_or_buffer, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">572</span> <span class="n">_validate_names</span><span class="p">(</span><span class="n">kwds</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;names&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">574</span> <span class="c1"># Create the parser.</span>
<span class="ne">--&gt; </span><span class="mi">575</span> <span class="n">parser</span> <span class="o">=</span> <span class="n">TextFileReader</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">577</span> <span class="k">if</span> <span class="n">chunksize</span> <span class="ow">or</span> <span class="n">iterator</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">578</span>     <span class="k">return</span> <span class="n">parser</span>

<span class="nn">File ~\miniconda3\lib\site-packages\pandas\io\parsers\readers.py:934,</span> in <span class="ni">TextFileReader.__init__</span><span class="nt">(self, f, engine, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">931</span>     <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s2">&quot;has_index_names&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwds</span><span class="p">[</span><span class="s2">&quot;has_index_names&quot;</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">933</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span><span class="p">:</span> <span class="n">IOHandles</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">934</span> <span class="bp">self</span><span class="o">.</span><span class="n">_engine</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_engine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\lib\site-packages\pandas\io\parsers\readers.py:1218,</span> in <span class="ni">TextFileReader._make_engine</span><span class="nt">(self, f, engine)</span>
<span class="g g-Whitespace">   </span><span class="mi">1214</span>     <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;rb&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1215</span> <span class="c1"># error: No overload variant of &quot;get_handle&quot; matches argument types</span>
<span class="g g-Whitespace">   </span><span class="mi">1216</span> <span class="c1"># &quot;Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1217</span> <span class="c1"># , &quot;str&quot;, &quot;bool&quot;, &quot;Any&quot;, &quot;Any&quot;, &quot;Any&quot;, &quot;Any&quot;, &quot;Any&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1218</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span> <span class="o">=</span> <span class="n">get_handle</span><span class="p">(</span>  <span class="c1"># type: ignore[call-overload]</span>
<span class="g g-Whitespace">   </span><span class="mi">1219</span>     <span class="n">f</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1220</span>     <span class="n">mode</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1221</span>     <span class="n">encoding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;encoding&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1222</span>     <span class="n">compression</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1223</span>     <span class="n">memory_map</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;memory_map&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1224</span>     <span class="n">is_text</span><span class="o">=</span><span class="n">is_text</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1225</span>     <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;encoding_errors&quot;</span><span class="p">,</span> <span class="s2">&quot;strict&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1226</span>     <span class="n">storage_options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;storage_options&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1227</span> <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1228</span> <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">1229</span> <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span><span class="o">.</span><span class="n">handle</span>

<span class="nn">File ~\miniconda3\lib\site-packages\pandas\io\common.py:786,</span> in <span class="ni">get_handle</span><span class="nt">(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">781</span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">782</span>     <span class="c1"># Check whether the filename is to be opened in binary mode.</span>
<span class="g g-Whitespace">    </span><span class="mi">783</span>     <span class="c1"># Binary mode does not support &#39;encoding&#39; and &#39;newline&#39;.</span>
<span class="g g-Whitespace">    </span><span class="mi">784</span>     <span class="k">if</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">encoding</span> <span class="ow">and</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">785</span>         <span class="c1"># Encoding</span>
<span class="ne">--&gt; </span><span class="mi">786</span>         <span class="n">handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">787</span>             <span class="n">handle</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">788</span>             <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">789</span>             <span class="n">encoding</span><span class="o">=</span><span class="n">ioargs</span><span class="o">.</span><span class="n">encoding</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">790</span>             <span class="n">errors</span><span class="o">=</span><span class="n">errors</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">791</span>             <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">792</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">793</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">794</span>         <span class="c1"># Binary mode</span>
<span class="g g-Whitespace">    </span><span class="mi">795</span>         <span class="n">handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;/content/drive/MyDrive/train_transaction_new.csv&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span> <span class="c1">#Esto nos indica las dimensiones del df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(99999, 434)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="c1"># Conozcamos las columnas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;TransactionID&#39;,
 &#39;isFraud&#39;,
 &#39;TransactionDT&#39;,
 &#39;TransactionAmt&#39;,
 &#39;ProductCD&#39;,
 &#39;card1&#39;,
 &#39;card2&#39;,
 &#39;card3&#39;,
 &#39;card4&#39;,
 &#39;card5&#39;,
 &#39;card6&#39;,
 &#39;addr1&#39;,
 &#39;addr2&#39;,
 &#39;dist1&#39;,
 &#39;dist2&#39;,
 &#39;P_emaildomain&#39;,
 &#39;R_emaildomain&#39;,
 &#39;C1&#39;,
 &#39;C2&#39;,
 &#39;C3&#39;,
 &#39;C4&#39;,
 &#39;C5&#39;,
 &#39;C6&#39;,
 &#39;C7&#39;,
 &#39;C8&#39;,
 &#39;C9&#39;,
 &#39;C10&#39;,
 &#39;C11&#39;,
 &#39;C12&#39;,
 &#39;C13&#39;,
 &#39;C14&#39;,
 &#39;D1&#39;,
 &#39;D2&#39;,
 &#39;D3&#39;,
 &#39;D4&#39;,
 &#39;D5&#39;,
 &#39;D6&#39;,
 &#39;D7&#39;,
 &#39;D8&#39;,
 &#39;D9&#39;,
 &#39;D10&#39;,
 &#39;D11&#39;,
 &#39;D12&#39;,
 &#39;D13&#39;,
 &#39;D14&#39;,
 &#39;D15&#39;,
 &#39;M1&#39;,
 &#39;M2&#39;,
 &#39;M3&#39;,
 &#39;M4&#39;,
 &#39;M5&#39;,
 &#39;M6&#39;,
 &#39;M7&#39;,
 &#39;M8&#39;,
 &#39;M9&#39;,
 &#39;V1&#39;,
 &#39;V2&#39;,
 &#39;V3&#39;,
 &#39;V4&#39;,
 &#39;V5&#39;,
 &#39;V6&#39;,
 &#39;V7&#39;,
 &#39;V8&#39;,
 &#39;V9&#39;,
 &#39;V10&#39;,
 &#39;V11&#39;,
 &#39;V12&#39;,
 &#39;V13&#39;,
 &#39;V14&#39;,
 &#39;V15&#39;,
 &#39;V16&#39;,
 &#39;V17&#39;,
 &#39;V18&#39;,
 &#39;V19&#39;,
 &#39;V20&#39;,
 &#39;V21&#39;,
 &#39;V22&#39;,
 &#39;V23&#39;,
 &#39;V24&#39;,
 &#39;V25&#39;,
 &#39;V26&#39;,
 &#39;V27&#39;,
 &#39;V28&#39;,
 &#39;V29&#39;,
 &#39;V30&#39;,
 &#39;V31&#39;,
 &#39;V32&#39;,
 &#39;V33&#39;,
 &#39;V34&#39;,
 &#39;V35&#39;,
 &#39;V36&#39;,
 &#39;V37&#39;,
 &#39;V38&#39;,
 &#39;V39&#39;,
 &#39;V40&#39;,
 &#39;V41&#39;,
 &#39;V42&#39;,
 &#39;V43&#39;,
 &#39;V44&#39;,
 &#39;V45&#39;,
 &#39;V46&#39;,
 &#39;V47&#39;,
 &#39;V48&#39;,
 &#39;V49&#39;,
 &#39;V50&#39;,
 &#39;V51&#39;,
 &#39;V52&#39;,
 &#39;V53&#39;,
 &#39;V54&#39;,
 &#39;V55&#39;,
 &#39;V56&#39;,
 &#39;V57&#39;,
 &#39;V58&#39;,
 &#39;V59&#39;,
 &#39;V60&#39;,
 &#39;V61&#39;,
 &#39;V62&#39;,
 &#39;V63&#39;,
 &#39;V64&#39;,
 &#39;V65&#39;,
 &#39;V66&#39;,
 &#39;V67&#39;,
 &#39;V68&#39;,
 &#39;V69&#39;,
 &#39;V70&#39;,
 &#39;V71&#39;,
 &#39;V72&#39;,
 &#39;V73&#39;,
 &#39;V74&#39;,
 &#39;V75&#39;,
 &#39;V76&#39;,
 &#39;V77&#39;,
 &#39;V78&#39;,
 &#39;V79&#39;,
 &#39;V80&#39;,
 &#39;V81&#39;,
 &#39;V82&#39;,
 &#39;V83&#39;,
 &#39;V84&#39;,
 &#39;V85&#39;,
 &#39;V86&#39;,
 &#39;V87&#39;,
 &#39;V88&#39;,
 &#39;V89&#39;,
 &#39;V90&#39;,
 &#39;V91&#39;,
 &#39;V92&#39;,
 &#39;V93&#39;,
 &#39;V94&#39;,
 &#39;V95&#39;,
 &#39;V96&#39;,
 &#39;V97&#39;,
 &#39;V98&#39;,
 &#39;V99&#39;,
 &#39;V100&#39;,
 &#39;V101&#39;,
 &#39;V102&#39;,
 &#39;V103&#39;,
 &#39;V104&#39;,
 &#39;V105&#39;,
 &#39;V106&#39;,
 &#39;V107&#39;,
 &#39;V108&#39;,
 &#39;V109&#39;,
 &#39;V110&#39;,
 &#39;V111&#39;,
 &#39;V112&#39;,
 &#39;V113&#39;,
 &#39;V114&#39;,
 &#39;V115&#39;,
 &#39;V116&#39;,
 &#39;V117&#39;,
 &#39;V118&#39;,
 &#39;V119&#39;,
 &#39;V120&#39;,
 &#39;V121&#39;,
 &#39;V122&#39;,
 &#39;V123&#39;,
 &#39;V124&#39;,
 &#39;V125&#39;,
 &#39;V126&#39;,
 &#39;V127&#39;,
 &#39;V128&#39;,
 &#39;V129&#39;,
 &#39;V130&#39;,
 &#39;V131&#39;,
 &#39;V132&#39;,
 &#39;V133&#39;,
 &#39;V134&#39;,
 &#39;V135&#39;,
 &#39;V136&#39;,
 &#39;V137&#39;,
 &#39;V138&#39;,
 &#39;V139&#39;,
 &#39;V140&#39;,
 &#39;V141&#39;,
 &#39;V142&#39;,
 &#39;V143&#39;,
 &#39;V144&#39;,
 &#39;V145&#39;,
 &#39;V146&#39;,
 &#39;V147&#39;,
 &#39;V148&#39;,
 &#39;V149&#39;,
 &#39;V150&#39;,
 &#39;V151&#39;,
 &#39;V152&#39;,
 &#39;V153&#39;,
 &#39;V154&#39;,
 &#39;V155&#39;,
 &#39;V156&#39;,
 &#39;V157&#39;,
 &#39;V158&#39;,
 &#39;V159&#39;,
 &#39;V160&#39;,
 &#39;V161&#39;,
 &#39;V162&#39;,
 &#39;V163&#39;,
 &#39;V164&#39;,
 &#39;V165&#39;,
 &#39;V166&#39;,
 &#39;V167&#39;,
 &#39;V168&#39;,
 &#39;V169&#39;,
 &#39;V170&#39;,
 &#39;V171&#39;,
 &#39;V172&#39;,
 &#39;V173&#39;,
 &#39;V174&#39;,
 &#39;V175&#39;,
 &#39;V176&#39;,
 &#39;V177&#39;,
 &#39;V178&#39;,
 &#39;V179&#39;,
 &#39;V180&#39;,
 &#39;V181&#39;,
 &#39;V182&#39;,
 &#39;V183&#39;,
 &#39;V184&#39;,
 &#39;V185&#39;,
 &#39;V186&#39;,
 &#39;V187&#39;,
 &#39;V188&#39;,
 &#39;V189&#39;,
 &#39;V190&#39;,
 &#39;V191&#39;,
 &#39;V192&#39;,
 &#39;V193&#39;,
 &#39;V194&#39;,
 &#39;V195&#39;,
 &#39;V196&#39;,
 &#39;V197&#39;,
 &#39;V198&#39;,
 &#39;V199&#39;,
 &#39;V200&#39;,
 &#39;V201&#39;,
 &#39;V202&#39;,
 &#39;V203&#39;,
 &#39;V204&#39;,
 &#39;V205&#39;,
 &#39;V206&#39;,
 &#39;V207&#39;,
 &#39;V208&#39;,
 &#39;V209&#39;,
 &#39;V210&#39;,
 &#39;V211&#39;,
 &#39;V212&#39;,
 &#39;V213&#39;,
 &#39;V214&#39;,
 &#39;V215&#39;,
 &#39;V216&#39;,
 &#39;V217&#39;,
 &#39;V218&#39;,
 &#39;V219&#39;,
 &#39;V220&#39;,
 &#39;V221&#39;,
 &#39;V222&#39;,
 &#39;V223&#39;,
 &#39;V224&#39;,
 &#39;V225&#39;,
 &#39;V226&#39;,
 &#39;V227&#39;,
 &#39;V228&#39;,
 &#39;V229&#39;,
 &#39;V230&#39;,
 &#39;V231&#39;,
 &#39;V232&#39;,
 &#39;V233&#39;,
 &#39;V234&#39;,
 &#39;V235&#39;,
 &#39;V236&#39;,
 &#39;V237&#39;,
 &#39;V238&#39;,
 &#39;V239&#39;,
 &#39;V240&#39;,
 &#39;V241&#39;,
 &#39;V242&#39;,
 &#39;V243&#39;,
 &#39;V244&#39;,
 &#39;V245&#39;,
 &#39;V246&#39;,
 &#39;V247&#39;,
 &#39;V248&#39;,
 &#39;V249&#39;,
 &#39;V250&#39;,
 &#39;V251&#39;,
 &#39;V252&#39;,
 &#39;V253&#39;,
 &#39;V254&#39;,
 &#39;V255&#39;,
 &#39;V256&#39;,
 &#39;V257&#39;,
 &#39;V258&#39;,
 &#39;V259&#39;,
 &#39;V260&#39;,
 &#39;V261&#39;,
 &#39;V262&#39;,
 &#39;V263&#39;,
 &#39;V264&#39;,
 &#39;V265&#39;,
 &#39;V266&#39;,
 &#39;V267&#39;,
 &#39;V268&#39;,
 &#39;V269&#39;,
 &#39;V270&#39;,
 &#39;V271&#39;,
 &#39;V272&#39;,
 &#39;V273&#39;,
 &#39;V274&#39;,
 &#39;V275&#39;,
 &#39;V276&#39;,
 &#39;V277&#39;,
 &#39;V278&#39;,
 &#39;V279&#39;,
 &#39;V280&#39;,
 &#39;V281&#39;,
 &#39;V282&#39;,
 &#39;V283&#39;,
 &#39;V284&#39;,
 &#39;V285&#39;,
 &#39;V286&#39;,
 &#39;V287&#39;,
 &#39;V288&#39;,
 &#39;V289&#39;,
 &#39;V290&#39;,
 &#39;V291&#39;,
 &#39;V292&#39;,
 &#39;V293&#39;,
 &#39;V294&#39;,
 &#39;V295&#39;,
 &#39;V296&#39;,
 &#39;V297&#39;,
 &#39;V298&#39;,
 &#39;V299&#39;,
 &#39;V300&#39;,
 &#39;V301&#39;,
 &#39;V302&#39;,
 &#39;V303&#39;,
 &#39;V304&#39;,
 &#39;V305&#39;,
 &#39;V306&#39;,
 &#39;V307&#39;,
 &#39;V308&#39;,
 &#39;V309&#39;,
 &#39;V310&#39;,
 &#39;V311&#39;,
 &#39;V312&#39;,
 &#39;V313&#39;,
 &#39;V314&#39;,
 &#39;V315&#39;,
 &#39;V316&#39;,
 &#39;V317&#39;,
 &#39;V318&#39;,
 &#39;V319&#39;,
 &#39;V320&#39;,
 &#39;V321&#39;,
 &#39;V322&#39;,
 &#39;V323&#39;,
 &#39;V324&#39;,
 &#39;V325&#39;,
 &#39;V326&#39;,
 &#39;V327&#39;,
 &#39;V328&#39;,
 &#39;V329&#39;,
 &#39;V330&#39;,
 &#39;V331&#39;,
 &#39;V332&#39;,
 &#39;V333&#39;,
 &#39;V334&#39;,
 &#39;V335&#39;,
 &#39;V336&#39;,
 &#39;V337&#39;,
 &#39;V338&#39;,
 &#39;V339&#39;,
 &#39;id_01&#39;,
 &#39;id_02&#39;,
 &#39;id_03&#39;,
 &#39;id_04&#39;,
 &#39;id_05&#39;,
 &#39;id_06&#39;,
 &#39;id_07&#39;,
 &#39;id_08&#39;,
 &#39;id_09&#39;,
 &#39;id_10&#39;,
 &#39;id_11&#39;,
 &#39;id_12&#39;,
 &#39;id_13&#39;,
 &#39;id_14&#39;,
 &#39;id_15&#39;,
 &#39;id_16&#39;,
 &#39;id_17&#39;,
 &#39;id_18&#39;,
 &#39;id_19&#39;,
 &#39;id_20&#39;,
 &#39;id_21&#39;,
 &#39;id_22&#39;,
 &#39;id_23&#39;,
 &#39;id_24&#39;,
 &#39;id_25&#39;,
 &#39;id_26&#39;,
 &#39;id_27&#39;,
 &#39;id_28&#39;,
 &#39;id_29&#39;,
 &#39;id_30&#39;,
 &#39;id_31&#39;,
 &#39;id_32&#39;,
 &#39;id_33&#39;,
 &#39;id_34&#39;,
 &#39;id_35&#39;,
 &#39;id_36&#39;,
 &#39;id_37&#39;,
 &#39;id_38&#39;,
 &#39;DeviceType&#39;,
 &#39;DeviceInfo&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="c1">#Hagamos una revision rápida de los que contiene el df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TransactionID</th>
      <th>isFraud</th>
      <th>TransactionDT</th>
      <th>TransactionAmt</th>
      <th>ProductCD</th>
      <th>card1</th>
      <th>card2</th>
      <th>card3</th>
      <th>card4</th>
      <th>card5</th>
      <th>card6</th>
      <th>addr1</th>
      <th>addr2</th>
      <th>dist1</th>
      <th>dist2</th>
      <th>P_emaildomain</th>
      <th>R_emaildomain</th>
      <th>C1</th>
      <th>C2</th>
      <th>C3</th>
      <th>C4</th>
      <th>C5</th>
      <th>C6</th>
      <th>C7</th>
      <th>C8</th>
      <th>C9</th>
      <th>C10</th>
      <th>C11</th>
      <th>C12</th>
      <th>C13</th>
      <th>C14</th>
      <th>D1</th>
      <th>D2</th>
      <th>D3</th>
      <th>D4</th>
      <th>D5</th>
      <th>D6</th>
      <th>D7</th>
      <th>D8</th>
      <th>D9</th>
      <th>D10</th>
      <th>D11</th>
      <th>D12</th>
      <th>D13</th>
      <th>D14</th>
      <th>D15</th>
      <th>M1</th>
      <th>M2</th>
      <th>M3</th>
      <th>M4</th>
      <th>M5</th>
      <th>M6</th>
      <th>M7</th>
      <th>M8</th>
      <th>M9</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>V29</th>
      <th>V30</th>
      <th>V31</th>
      <th>V32</th>
      <th>V33</th>
      <th>V34</th>
      <th>V35</th>
      <th>V36</th>
      <th>V37</th>
      <th>V38</th>
      <th>V39</th>
      <th>V40</th>
      <th>V41</th>
      <th>V42</th>
      <th>V43</th>
      <th>V44</th>
      <th>V45</th>
      <th>V46</th>
      <th>V47</th>
      <th>V48</th>
      <th>V49</th>
      <th>V50</th>
      <th>V51</th>
      <th>V52</th>
      <th>V53</th>
      <th>V54</th>
      <th>V55</th>
      <th>V56</th>
      <th>V57</th>
      <th>V58</th>
      <th>V59</th>
      <th>V60</th>
      <th>V61</th>
      <th>V62</th>
      <th>V63</th>
      <th>V64</th>
      <th>V65</th>
      <th>V66</th>
      <th>V67</th>
      <th>V68</th>
      <th>V69</th>
      <th>V70</th>
      <th>V71</th>
      <th>V72</th>
      <th>V73</th>
      <th>V74</th>
      <th>V75</th>
      <th>V76</th>
      <th>V77</th>
      <th>V78</th>
      <th>V79</th>
      <th>V80</th>
      <th>V81</th>
      <th>V82</th>
      <th>V83</th>
      <th>V84</th>
      <th>V85</th>
      <th>V86</th>
      <th>V87</th>
      <th>V88</th>
      <th>V89</th>
      <th>V90</th>
      <th>V91</th>
      <th>V92</th>
      <th>V93</th>
      <th>V94</th>
      <th>V95</th>
      <th>V96</th>
      <th>V97</th>
      <th>V98</th>
      <th>V99</th>
      <th>V100</th>
      <th>V101</th>
      <th>V102</th>
      <th>V103</th>
      <th>V104</th>
      <th>V105</th>
      <th>V106</th>
      <th>V107</th>
      <th>V108</th>
      <th>V109</th>
      <th>V110</th>
      <th>V111</th>
      <th>V112</th>
      <th>V113</th>
      <th>V114</th>
      <th>V115</th>
      <th>V116</th>
      <th>V117</th>
      <th>V118</th>
      <th>V119</th>
      <th>V120</th>
      <th>V121</th>
      <th>V122</th>
      <th>V123</th>
      <th>V124</th>
      <th>V125</th>
      <th>V126</th>
      <th>V127</th>
      <th>V128</th>
      <th>V129</th>
      <th>V130</th>
      <th>V131</th>
      <th>V132</th>
      <th>V133</th>
      <th>V134</th>
      <th>V135</th>
      <th>V136</th>
      <th>V137</th>
      <th>V138</th>
      <th>V139</th>
      <th>V140</th>
      <th>V141</th>
      <th>V142</th>
      <th>V143</th>
      <th>V144</th>
      <th>V145</th>
      <th>V146</th>
      <th>V147</th>
      <th>V148</th>
      <th>V149</th>
      <th>V150</th>
      <th>V151</th>
      <th>V152</th>
      <th>V153</th>
      <th>V154</th>
      <th>V155</th>
      <th>V156</th>
      <th>V157</th>
      <th>V158</th>
      <th>V159</th>
      <th>V160</th>
      <th>V161</th>
      <th>V162</th>
      <th>V163</th>
      <th>V164</th>
      <th>V165</th>
      <th>V166</th>
      <th>V167</th>
      <th>V168</th>
      <th>V169</th>
      <th>V170</th>
      <th>V171</th>
      <th>V172</th>
      <th>V173</th>
      <th>V174</th>
      <th>V175</th>
      <th>V176</th>
      <th>V177</th>
      <th>V178</th>
      <th>V179</th>
      <th>V180</th>
      <th>V181</th>
      <th>V182</th>
      <th>V183</th>
      <th>V184</th>
      <th>V185</th>
      <th>V186</th>
      <th>V187</th>
      <th>V188</th>
      <th>V189</th>
      <th>V190</th>
      <th>V191</th>
      <th>V192</th>
      <th>V193</th>
      <th>V194</th>
      <th>V195</th>
      <th>V196</th>
      <th>V197</th>
      <th>V198</th>
      <th>V199</th>
      <th>V200</th>
      <th>V201</th>
      <th>V202</th>
      <th>V203</th>
      <th>V204</th>
      <th>V205</th>
      <th>V206</th>
      <th>V207</th>
      <th>V208</th>
      <th>V209</th>
      <th>V210</th>
      <th>V211</th>
      <th>V212</th>
      <th>V213</th>
      <th>V214</th>
      <th>V215</th>
      <th>V216</th>
      <th>V217</th>
      <th>V218</th>
      <th>V219</th>
      <th>V220</th>
      <th>V221</th>
      <th>V222</th>
      <th>V223</th>
      <th>V224</th>
      <th>V225</th>
      <th>V226</th>
      <th>V227</th>
      <th>V228</th>
      <th>V229</th>
      <th>V230</th>
      <th>V231</th>
      <th>V232</th>
      <th>V233</th>
      <th>V234</th>
      <th>V235</th>
      <th>V236</th>
      <th>V237</th>
      <th>V238</th>
      <th>V239</th>
      <th>V240</th>
      <th>V241</th>
      <th>V242</th>
      <th>V243</th>
      <th>V244</th>
      <th>V245</th>
      <th>V246</th>
      <th>V247</th>
      <th>V248</th>
      <th>V249</th>
      <th>V250</th>
      <th>V251</th>
      <th>V252</th>
      <th>V253</th>
      <th>V254</th>
      <th>V255</th>
      <th>V256</th>
      <th>V257</th>
      <th>V258</th>
      <th>V259</th>
      <th>V260</th>
      <th>V261</th>
      <th>V262</th>
      <th>V263</th>
      <th>V264</th>
      <th>V265</th>
      <th>V266</th>
      <th>V267</th>
      <th>V268</th>
      <th>V269</th>
      <th>V270</th>
      <th>V271</th>
      <th>V272</th>
      <th>V273</th>
      <th>V274</th>
      <th>V275</th>
      <th>V276</th>
      <th>V277</th>
      <th>V278</th>
      <th>V279</th>
      <th>V280</th>
      <th>V281</th>
      <th>V282</th>
      <th>V283</th>
      <th>V284</th>
      <th>V285</th>
      <th>V286</th>
      <th>V287</th>
      <th>V288</th>
      <th>V289</th>
      <th>V290</th>
      <th>V291</th>
      <th>V292</th>
      <th>V293</th>
      <th>V294</th>
      <th>V295</th>
      <th>V296</th>
      <th>V297</th>
      <th>V298</th>
      <th>V299</th>
      <th>V300</th>
      <th>V301</th>
      <th>V302</th>
      <th>V303</th>
      <th>V304</th>
      <th>V305</th>
      <th>V306</th>
      <th>V307</th>
      <th>V308</th>
      <th>V309</th>
      <th>V310</th>
      <th>V311</th>
      <th>V312</th>
      <th>V313</th>
      <th>V314</th>
      <th>V315</th>
      <th>V316</th>
      <th>V317</th>
      <th>V318</th>
      <th>V319</th>
      <th>V320</th>
      <th>V321</th>
      <th>V322</th>
      <th>V323</th>
      <th>V324</th>
      <th>V325</th>
      <th>V326</th>
      <th>V327</th>
      <th>V328</th>
      <th>V329</th>
      <th>V330</th>
      <th>V331</th>
      <th>V332</th>
      <th>V333</th>
      <th>V334</th>
      <th>V335</th>
      <th>V336</th>
      <th>V337</th>
      <th>V338</th>
      <th>V339</th>
      <th>id_01</th>
      <th>id_02</th>
      <th>id_03</th>
      <th>id_04</th>
      <th>id_05</th>
      <th>id_06</th>
      <th>id_07</th>
      <th>id_08</th>
      <th>id_09</th>
      <th>id_10</th>
      <th>id_11</th>
      <th>id_12</th>
      <th>id_13</th>
      <th>id_14</th>
      <th>id_15</th>
      <th>id_16</th>
      <th>id_17</th>
      <th>id_18</th>
      <th>id_19</th>
      <th>id_20</th>
      <th>id_21</th>
      <th>id_22</th>
      <th>id_23</th>
      <th>id_24</th>
      <th>id_25</th>
      <th>id_26</th>
      <th>id_27</th>
      <th>id_28</th>
      <th>id_29</th>
      <th>id_30</th>
      <th>id_31</th>
      <th>id_32</th>
      <th>id_33</th>
      <th>id_34</th>
      <th>id_35</th>
      <th>id_36</th>
      <th>id_37</th>
      <th>id_38</th>
      <th>DeviceType</th>
      <th>DeviceInfo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>90029</th>
      <td>3077029</td>
      <td>0</td>
      <td>1884373</td>
      <td>17.793</td>
      <td>C</td>
      <td>15257</td>
      <td>375.0</td>
      <td>185.0</td>
      <td>mastercard</td>
      <td>224.0</td>
      <td>debit</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>hotmail.com</td>
      <td>hotmail.com</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>M2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>37.445</td>
      <td>37.445000</td>
      <td>37.445</td>
      <td>19.652399</td>
      <td>19.652399</td>
      <td>19.652399</td>
      <td>19.652399</td>
      <td>19.652399</td>
      <td>19.652399</td>
      <td>19.652399</td>
      <td>17.792601</td>
      <td>17.792601</td>
      <td>17.792601</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-15.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NotFound</td>
      <td>20.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>32546</th>
      <td>3019546</td>
      <td>0</td>
      <td>797857</td>
      <td>166.000</td>
      <td>W</td>
      <td>3100</td>
      <td>555.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>debit</td>
      <td>264.0</td>
      <td>87.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>gmail.com</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>368.0</td>
      <td>368.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>367.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>M1</td>
      <td>T</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>171.000</td>
      <td>171.000000</td>
      <td>171.000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>171.0</td>
      <td>171.0</td>
      <td>171.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>55765</th>
      <td>3042765</td>
      <td>0</td>
      <td>1292419</td>
      <td>41.000</td>
      <td>W</td>
      <td>12570</td>
      <td>462.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>debit</td>
      <td>191.0</td>
      <td>87.0</td>
      <td>194.0</td>
      <td>NaN</td>
      <td>yahoo.com</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>1.0</td>
      <td>36.0</td>
      <td>36.0</td>
      <td>0.0</td>
      <td>36.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>36.0</td>
      <td>36.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>36.0</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>T</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>24.0</td>
      <td>11.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>15.0</td>
      <td>7.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>98.0</td>
      <td>1458.5</td>
      <td>681.0</td>
      <td>49.0</td>
      <td>524.0</td>
      <td>279.0</td>
      <td>49.0</td>
      <td>859.5</td>
      <td>402.0</td>
      <td>0.0</td>
      <td>75.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>11.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>15.0</td>
      <td>7.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>98.000</td>
      <td>1383.500000</td>
      <td>681.000</td>
      <td>49.000000</td>
      <td>524.000000</td>
      <td>0.000000</td>
      <td>279.000000</td>
      <td>78.000000</td>
      <td>422.000000</td>
      <td>78.000000</td>
      <td>49.000000</td>
      <td>859.500000</td>
      <td>402.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>7113</th>
      <td>2994113</td>
      <td>0</td>
      <td>235129</td>
      <td>100.000</td>
      <td>W</td>
      <td>14580</td>
      <td>555.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>debit</td>
      <td>272.0</td>
      <td>87.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>gmail.com</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>122.0</td>
      <td>91.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>477.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>M1</td>
      <td>T</td>
      <td>T</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>450.0</td>
      <td>450.0</td>
      <td>450.0</td>
      <td>450.0</td>
      <td>450.0</td>
      <td>450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>450.000</td>
      <td>450.000000</td>
      <td>450.000</td>
      <td>450.000000</td>
      <td>450.000000</td>
      <td>0.000000</td>
      <td>450.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>393</th>
      <td>2987393</td>
      <td>0</td>
      <td>92753</td>
      <td>59.000</td>
      <td>W</td>
      <td>3189</td>
      <td>555.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>debit</td>
      <td>251.0</td>
      <td>87.0</td>
      <td>372.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>165.0</td>
      <td>165.0</td>
      <td>152.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>164.0</td>
      <td>T</td>
      <td>F</td>
      <td>F</td>
      <td>M0</td>
      <td>T</td>
      <td>F</td>
      <td>F</td>
      <td>F</td>
      <td>F</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4430</th>
      <td>2991430</td>
      <td>0</td>
      <td>165506</td>
      <td>50.000</td>
      <td>W</td>
      <td>13052</td>
      <td>254.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>debit</td>
      <td>325.0</td>
      <td>87.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>3.0</td>
      <td>60.0</td>
      <td>60.0</td>
      <td>15.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>30.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>60.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>F</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>99.949997</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>99.949997</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>50983</th>
      <td>3037983</td>
      <td>0</td>
      <td>1201625</td>
      <td>171.000</td>
      <td>W</td>
      <td>2884</td>
      <td>490.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>debit</td>
      <td>420.0</td>
      <td>87.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>comcast.net</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>36.0</td>
      <td>1.0</td>
      <td>322.0</td>
      <td>322.0</td>
      <td>2.0</td>
      <td>313.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>313.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>322.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>M0</td>
      <td>F</td>
      <td>T</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>237.0</td>
      <td>88.0</td>
      <td>0.0</td>
      <td>237.0</td>
      <td>88.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>237.000000</td>
      <td>88.000</td>
      <td>0.000000</td>
      <td>237.000000</td>
      <td>0.000000</td>
      <td>88.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>35929</th>
      <td>3022929</td>
      <td>0</td>
      <td>870677</td>
      <td>108.950</td>
      <td>W</td>
      <td>13301</td>
      <td>555.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>debit</td>
      <td>299.0</td>
      <td>87.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>226.0</td>
      <td>180.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>137.0</td>
      <td>155.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>119.0</td>
      <td>0.0</td>
      <td>164.0</td>
      <td>0.0</td>
      <td>468.0</td>
      <td>190.0</td>
      <td>198.0</td>
      <td>198.0</td>
      <td>109.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>235.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>235.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>T</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>45319</th>
      <td>3032319</td>
      <td>0</td>
      <td>1096022</td>
      <td>24.194</td>
      <td>C</td>
      <td>15885</td>
      <td>545.0</td>
      <td>185.0</td>
      <td>visa</td>
      <td>138.0</td>
      <td>debit</td>
      <td>511.0</td>
      <td>60.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>yahoo.com.mx</td>
      <td>yahoo.com.mx</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>M2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>60184</th>
      <td>3047184</td>
      <td>0</td>
      <td>1372688</td>
      <td>125.000</td>
      <td>R</td>
      <td>16659</td>
      <td>170.0</td>
      <td>150.0</td>
      <td>visa</td>
      <td>226.0</td>
      <td>credit</td>
      <td>264.0</td>
      <td>87.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>gmail.com</td>
      <td>gmail.com</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.875</td>
      <td>0.875</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-40.0</td>
      <td>80557.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>11.0</td>
      <td>-100.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>93.059998</td>
      <td>NotFound</td>
      <td>52.0</td>
      <td>-360.0</td>
      <td>New</td>
      <td>NotFound</td>
      <td>192.0</td>
      <td>13.0</td>
      <td>410.0</td>
      <td>121.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Found</td>
      <td>Found</td>
      <td>Windows 7</td>
      <td>ie 11.0 for desktop</td>
      <td>24.0</td>
      <td>1600x900</td>
      <td>match_status:2</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>rv:11.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>OBSERVACIONES</strong></p>
<ul class="simple">
<li><p>El df tiene columnas con una importante proporción de <em>datos nulos</em></p></li>
<li><p>Tenemos que trabajar con variables de tipo categóricas y numéricas</p></li>
<li><p>Nuestra <em>variable objetivo</em> o <em>target</em> es <code class="docutils literal notranslate"><span class="pre">isFraud</span></code>, y es de tipo binaria, compuesta por valores 0 y 1.</p></li>
<li><p>Los nombres de las columnas no requieren procesamiento.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Conocer qué tipo de datos tiene cada columna en el df</span>
<span class="n">df</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>float64    399
object      31
int64        4
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<p><strong>OBSERVACIONES</strong></p>
<ul class="simple">
<li><p>Tenemos variables de tipo <em>flotante</em>, <em>Entero</em> y <em>Object</em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Separo la variable objetivo</span>
<span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;isFraud&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;isFraud&#39;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>OBSERVACIONES</strong></p>
<ul class="simple">
<li><p>En la celda anterior, separamos nuestro <code class="docutils literal notranslate"><span class="pre">Target</span></code> del df y lo guardamos en <code class="docutils literal notranslate"><span class="pre">y</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Hagamos una gráfica para conocer el balance de las categorias</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Valor de la Variable Objetivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frecuencia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gráfico de Barras de la Variable Objetivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Rotar las etiquetas del eje x si es necesario</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6bd6b65cc1982ce8fe530be8c994919577f901fa778e043d4cfcc47d9563b5fb.png" src="_images/6bd6b65cc1982ce8fe530be8c994919577f901fa778e043d4cfcc47d9563b5fb.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong></p>
<p>Esta clase tan <strong>fuertemente desbalanceada</strong> nos va a generar problemas en el modelo final, puesto que va a saber reconocer muy bien las transacciones tipo 0 (<em>no fraudulentas</em>), mientras que <strong>no dará buenos resultados</strong> para detectar el fraude, que es lo que finalmente queremos lograr.</p>
<p>Vamos a requerir una tecnica de balance de clases, un <em>oversampling.</em></p>
</section>
<section id="manejo-de-datos-nulos">
<h2>MANEJO DE DATOS NULOS<a class="headerlink" href="#manejo-de-datos-nulos" title="Permalink to this heading">#</a></h2>
<p>Calculemos el porcentaje de datos nulos de cada columna para poder determinar su manejo más conveniente</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">porcentaje_nulos</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span>
<span class="n">porcentaje_nulos</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TransactionID      0.000000
TransactionDT      0.000000
TransactionAmt     0.000000
ProductCD          0.000000
card1              0.000000
card2              1.354014
card3              0.003000
card4              0.007000
card5              0.525005
card6              0.004000
addr1              9.037090
addr2              9.037090
dist1             69.653697
dist2             91.768918
P_emaildomain     15.393154
R_emaildomain     65.453655
C1                 0.000000
C2                 0.000000
C3                 0.000000
C4                 0.000000
C5                 0.000000
C6                 0.000000
C7                 0.000000
C8                 0.000000
C9                 0.000000
C10                0.000000
C11                0.000000
C12                0.000000
C13                0.000000
C14                0.000000
D1                 0.000000
D2                57.632576
D3                56.597566
D4                46.175462
D5                65.327653
D6                87.258873
D7                93.927939
D8                78.288783
D9                78.288783
D10               30.926309
D11               71.208712
D12               89.494895
D13               90.478905
D14               88.846888
D15               34.047340
M1                68.553686
M2                68.553686
M3                68.553686
M4                57.669577
M5                68.923689
M6                45.587456
M7                83.960840
M8                83.960840
M9                83.960840
V1                71.208712
V2                71.208712
V3                71.208712
V4                71.208712
V5                71.208712
V6                71.208712
V7                71.208712
V8                71.208712
V9                71.208712
V10               71.208712
V11               71.208712
V12               30.933309
V13               30.933309
V14               30.933309
V15               30.933309
V16               30.933309
V17               30.933309
V18               30.933309
V19               30.933309
V20               30.933309
V21               30.933309
V22               30.933309
V23               30.933309
V24               30.933309
V25               30.933309
V26               30.933309
V27               30.933309
V28               30.933309
V29               30.933309
V30               30.933309
V31               30.933309
V32               30.933309
V33               30.933309
V34               30.933309
V35               46.178462
V36               46.178462
V37               46.178462
V38               46.178462
V39               46.178462
V40               46.178462
V41               46.178462
V42               46.178462
V43               46.178462
V44               46.178462
V45               46.178462
V46               46.178462
V47               46.178462
V48               46.178462
V49               46.178462
V50               46.178462
V51               46.178462
V52               46.178462
V53               30.239302
V54               30.239302
V55               30.239302
V56               30.239302
V57               30.239302
V58               30.239302
V59               30.239302
V60               30.239302
V61               30.239302
V62               30.239302
V63               30.239302
V64               30.239302
V65               30.239302
V66               30.239302
V67               30.239302
V68               30.239302
V69               30.239302
V70               30.239302
V71               30.239302
V72               30.239302
V73               30.239302
V74               30.239302
V75               34.052341
V76               34.052341
V77               34.052341
V78               34.052341
V79               34.052341
V80               34.052341
V81               34.052341
V82               34.052341
V83               34.052341
V84               34.052341
V85               34.052341
V86               34.052341
V87               34.052341
V88               34.052341
V89               34.052341
V90               34.052341
V91               34.052341
V92               34.052341
V93               34.052341
V94               34.052341
V95                0.000000
V96                0.000000
V97                0.000000
V98                0.000000
V99                0.000000
V100               0.000000
V101               0.000000
V102               0.000000
V103               0.000000
V104               0.000000
V105               0.000000
V106               0.000000
V107               0.000000
V108               0.000000
V109               0.000000
V110               0.000000
V111               0.000000
V112               0.000000
V113               0.000000
V114               0.000000
V115               0.000000
V116               0.000000
V117               0.000000
V118               0.000000
V119               0.000000
V120               0.000000
V121               0.000000
V122               0.000000
V123               0.000000
V124               0.000000
V125               0.000000
V126               0.000000
V127               0.000000
V128               0.000000
V129               0.000000
V130               0.000000
V131               0.000000
V132               0.000000
V133               0.000000
V134               0.000000
V135               0.000000
V136               0.000000
V137               0.000000
V138              68.358684
V139              68.358684
V140              68.358684
V141              68.358684
V142              68.358684
V143              68.358684
V144              68.358684
V145              68.358684
V146              68.358684
V147              68.358684
V148              68.358684
V149              68.358684
V150              68.358684
V151              68.358684
V152              68.358684
V153              68.358684
V154              68.358684
V155              68.358684
V156              68.358684
V157              68.358684
V158              68.358684
V159              68.358684
V160              68.358684
V161              68.358684
V162              68.358684
V163              68.358684
V164              68.358684
V165              68.358684
V166              68.358684
V167              60.416604
V168              60.416604
V169              60.416604
V170              60.416604
V171              60.416604
V172              60.416604
V173              60.416604
V174              60.416604
V175              60.416604
V176              60.416604
V177              60.416604
V178              60.416604
V179              60.416604
V180              60.416604
V181              60.416604
V182              60.416604
V183              60.416604
V184              60.416604
V185              60.416604
V186              60.416604
V187              60.416604
V188              60.416604
V189              60.416604
V190              60.416604
V191              60.416604
V192              60.416604
V193              60.416604
V194              60.416604
V195              60.416604
V196              60.416604
V197              60.416604
V198              60.416604
V199              60.416604
V200              60.416604
V201              60.416604
V202              60.416604
V203              60.416604
V204              60.416604
V205              60.416604
V206              60.416604
V207              60.416604
V208              60.416604
V209              60.416604
V210              60.416604
V211              60.416604
V212              60.416604
V213              60.416604
V214              60.416604
V215              60.416604
V216              60.416604
V217              61.607616
V218              61.607616
V219              61.607616
V220              59.533595
V221              59.533595
V222              59.533595
V223              61.607616
V224              61.607616
V225              61.607616
V226              61.607616
V227              59.533595
V228              61.607616
V229              61.607616
V230              61.607616
V231              61.607616
V232              61.607616
V233              61.607616
V234              59.533595
V235              61.607616
V236              61.607616
V237              61.607616
V238              59.533595
V239              59.533595
V240              61.607616
V241              61.607616
V242              61.607616
V243              61.607616
V244              61.607616
V245              59.533595
V246              61.607616
V247              61.607616
V248              61.607616
V249              61.607616
V250              59.533595
V251              59.533595
V252              61.607616
V253              61.607616
V254              61.607616
V255              59.533595
V256              59.533595
V257              61.607616
V258              61.607616
V259              59.533595
V260              61.607616
V261              61.607616
V262              61.607616
V263              61.607616
V264              61.607616
V265              61.607616
V266              61.607616
V267              61.607616
V268              61.607616
V269              61.607616
V270              59.533595
V271              59.533595
V272              59.533595
V273              61.607616
V274              61.607616
V275              61.607616
V276              61.607616
V277              61.607616
V278              61.607616
V279               0.011000
V280               0.011000
V281               0.000000
V282               0.000000
V283               0.000000
V284               0.011000
V285               0.011000
V286               0.011000
V287               0.011000
V288               0.000000
V289               0.000000
V290               0.011000
V291               0.011000
V292               0.011000
V293               0.011000
V294               0.011000
V295               0.011000
V296               0.000000
V297               0.011000
V298               0.011000
V299               0.011000
V300               0.000000
V301               0.000000
V302               0.011000
V303               0.011000
V304               0.011000
V305               0.011000
V306               0.011000
V307               0.011000
V308               0.011000
V309               0.011000
V310               0.011000
V311               0.011000
V312               0.011000
V313               0.000000
V314               0.000000
V315               0.000000
V316               0.011000
V317               0.011000
V318               0.011000
V319               0.011000
V320               0.011000
V321               0.011000
V322              68.228682
V323              68.228682
V324              68.228682
V325              68.228682
V326              68.228682
V327              68.228682
V328              68.228682
V329              68.228682
V330              68.228682
V331              68.228682
V332              68.228682
V333              68.228682
V334              68.228682
V335              68.228682
V336              68.228682
V337              68.228682
V338              68.228682
V339              68.228682
id_01             58.553586
id_02             59.709597
id_03             81.432814
id_04             81.432814
id_05             60.932609
id_06             60.932609
id_07             98.376984
id_08             98.376984
id_09             78.288783
id_10             78.288783
id_11             59.598596
id_12             58.553586
id_13             66.066661
id_14             69.664697
id_15             59.598596
id_16             61.835618
id_17             60.119601
id_18             87.018870
id_19             60.128601
id_20             60.133601
id_21             98.379984
id_22             98.375984
id_23             98.375984
id_24             98.499985
id_25             98.387984
id_26             98.376984
id_27             98.375984
id_28             59.598596
id_29             59.598596
id_30             70.163702
id_31             59.757598
id_32             70.161702
id_33             72.434724
id_34             70.095701
id_35             59.598596
id_36             59.598596
id_37             59.598596
id_38             59.598596
DeviceType        59.716597
DeviceInfo        63.534635
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Veamos esta información en una gráfica</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">porcentaje_nulos</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Porcentaje de Datos Nulos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Número de Columnas&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Histograma de Porcentaje de Datos Nulos en el DataFrame&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a328a01e56401c195ea259761a69ee7cf287860e015847278225e3bba10b174a.png" src="_images/a328a01e56401c195ea259761a69ee7cf287860e015847278225e3bba10b174a.png" />
</div>
</div>
<p><strong>CONCLUSION</strong></p>
<ul class="simple">
<li><p>La mayoría de columnas tiene un porcentaje de datos nulos superior al 55%, esto muy importante, porque impilica que alrededor del 50% de los datos de nuestro set serán <strong>‘imputados’</strong>.</p></li>
</ul>
<p>A continuación vamos a proceder de la siguiente manera:</p>
<ul class="simple">
<li><p>Encontrando columnas con datos nulos superiores al 70% para <strong>eliminarlas</strong></p></li>
<li><p>Encontrando columnas con datos nulos menores al 70% para <strong>imputarlos por la mediana o moda</strong>, según sea su tipo.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Ciclo para encontrar columnas con porcentaje de nulos &gt;70%</span>
<span class="n">nulos_delete</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">nulos_imputer</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">70</span><span class="p">:</span>
        <span class="n">nulos_delete</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">nulos_imputer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Done!&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
</div>
</div>
<p>Ya encontramos las columnas con porcentaje de nulos **mayor al 70%*, procedemos a su <em>eliminación</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Eliminamos columnas con mas de 70% de nulos</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">nulos_delete</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># nueva dimension del dataframe</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(99999, 392)
</pre></div>
</div>
</div>
</div>
<p>Para este nuevo <code class="docutils literal notranslate"><span class="pre">df</span></code> vamos ahora a encontrar las columnas con variables <strong>categoricas y numericas</strong> y separarlas para darle un manejo diferente a cada una.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#guardo en una lista las variables categóricas y las numericas para facilitar el preprocesamiento y visualizacion</span>
<span class="n">numericas</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span><span class="s1">&#39;int&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">columns</span>
<span class="n">categoricas</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
</div>
<p>Instanciamos los imputadores para los diferentes tipos de variables.</p>
<p>Para las variables numéricas usaremos la <code class="docutils literal notranslate"><span class="pre">mediana</span></code>
Para las variables categoricas usaremos la <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">moda</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Las variables numericas usaremos la mediana para los valores faltantes</span>
<span class="c1">#Para las categóricas, la mas frecuente</span>

<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>

<span class="n">imp_num</span><span class="o">=</span><span class="n">SimpleImputer</span><span class="p">(</span><span class="n">missing_values</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)</span>
<span class="n">imp_cat</span><span class="o">=</span><span class="n">SimpleImputer</span><span class="p">(</span><span class="n">missing_values</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Aplicamos los imputadores</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Aplicamos los imputadores a los diferentes tipos de datos</span>
<span class="n">df</span><span class="p">[</span><span class="n">numericas</span><span class="p">]</span><span class="o">=</span> <span class="n">imp_num</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">numericas</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="n">categoricas</span><span class="p">]</span><span class="o">=</span> <span class="n">imp_cat</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">categoricas</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Verificamos resultados</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Revisamos resultados</span>
<span class="n">df</span><span class="p">[</span><span class="n">numericas</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TransactionID</th>
      <th>TransactionDT</th>
      <th>TransactionAmt</th>
      <th>card1</th>
      <th>card2</th>
      <th>card3</th>
      <th>card5</th>
      <th>addr1</th>
      <th>addr2</th>
      <th>dist1</th>
      <th>C1</th>
      <th>C2</th>
      <th>C3</th>
      <th>C4</th>
      <th>C5</th>
      <th>C6</th>
      <th>C7</th>
      <th>C8</th>
      <th>C9</th>
      <th>C10</th>
      <th>C11</th>
      <th>C12</th>
      <th>C13</th>
      <th>C14</th>
      <th>D1</th>
      <th>D2</th>
      <th>D3</th>
      <th>D4</th>
      <th>D5</th>
      <th>D10</th>
      <th>D15</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>V29</th>
      <th>V30</th>
      <th>V31</th>
      <th>V32</th>
      <th>V33</th>
      <th>V34</th>
      <th>V35</th>
      <th>V36</th>
      <th>V37</th>
      <th>V38</th>
      <th>V39</th>
      <th>V40</th>
      <th>V41</th>
      <th>V42</th>
      <th>V43</th>
      <th>V44</th>
      <th>V45</th>
      <th>V46</th>
      <th>V47</th>
      <th>V48</th>
      <th>V49</th>
      <th>V50</th>
      <th>V51</th>
      <th>V52</th>
      <th>V53</th>
      <th>V54</th>
      <th>V55</th>
      <th>V56</th>
      <th>V57</th>
      <th>V58</th>
      <th>V59</th>
      <th>V60</th>
      <th>V61</th>
      <th>V62</th>
      <th>V63</th>
      <th>V64</th>
      <th>V65</th>
      <th>V66</th>
      <th>V67</th>
      <th>V68</th>
      <th>V69</th>
      <th>V70</th>
      <th>V71</th>
      <th>V72</th>
      <th>V73</th>
      <th>V74</th>
      <th>V75</th>
      <th>V76</th>
      <th>V77</th>
      <th>V78</th>
      <th>V79</th>
      <th>V80</th>
      <th>V81</th>
      <th>V82</th>
      <th>V83</th>
      <th>V84</th>
      <th>V85</th>
      <th>V86</th>
      <th>V87</th>
      <th>V88</th>
      <th>V89</th>
      <th>V90</th>
      <th>V91</th>
      <th>V92</th>
      <th>V93</th>
      <th>V94</th>
      <th>V95</th>
      <th>V96</th>
      <th>V97</th>
      <th>V98</th>
      <th>V99</th>
      <th>V100</th>
      <th>V101</th>
      <th>V102</th>
      <th>V103</th>
      <th>V104</th>
      <th>V105</th>
      <th>V106</th>
      <th>V107</th>
      <th>V108</th>
      <th>V109</th>
      <th>V110</th>
      <th>V111</th>
      <th>V112</th>
      <th>V113</th>
      <th>V114</th>
      <th>V115</th>
      <th>V116</th>
      <th>V117</th>
      <th>V118</th>
      <th>V119</th>
      <th>V120</th>
      <th>V121</th>
      <th>V122</th>
      <th>V123</th>
      <th>V124</th>
      <th>V125</th>
      <th>V126</th>
      <th>V127</th>
      <th>V128</th>
      <th>V129</th>
      <th>V130</th>
      <th>V131</th>
      <th>V132</th>
      <th>V133</th>
      <th>V134</th>
      <th>V135</th>
      <th>V136</th>
      <th>V137</th>
      <th>V138</th>
      <th>V139</th>
      <th>V140</th>
      <th>V141</th>
      <th>V142</th>
      <th>V143</th>
      <th>V144</th>
      <th>V145</th>
      <th>V146</th>
      <th>V147</th>
      <th>V148</th>
      <th>V149</th>
      <th>V150</th>
      <th>V151</th>
      <th>V152</th>
      <th>V153</th>
      <th>V154</th>
      <th>V155</th>
      <th>V156</th>
      <th>V157</th>
      <th>V158</th>
      <th>V159</th>
      <th>V160</th>
      <th>V161</th>
      <th>V162</th>
      <th>V163</th>
      <th>V164</th>
      <th>V165</th>
      <th>V166</th>
      <th>V167</th>
      <th>V168</th>
      <th>V169</th>
      <th>V170</th>
      <th>V171</th>
      <th>V172</th>
      <th>V173</th>
      <th>V174</th>
      <th>V175</th>
      <th>V176</th>
      <th>V177</th>
      <th>V178</th>
      <th>V179</th>
      <th>V180</th>
      <th>V181</th>
      <th>V182</th>
      <th>V183</th>
      <th>V184</th>
      <th>V185</th>
      <th>V186</th>
      <th>V187</th>
      <th>V188</th>
      <th>V189</th>
      <th>V190</th>
      <th>V191</th>
      <th>V192</th>
      <th>V193</th>
      <th>V194</th>
      <th>V195</th>
      <th>V196</th>
      <th>V197</th>
      <th>V198</th>
      <th>V199</th>
      <th>V200</th>
      <th>V201</th>
      <th>V202</th>
      <th>V203</th>
      <th>V204</th>
      <th>V205</th>
      <th>V206</th>
      <th>V207</th>
      <th>V208</th>
      <th>V209</th>
      <th>V210</th>
      <th>V211</th>
      <th>V212</th>
      <th>V213</th>
      <th>V214</th>
      <th>V215</th>
      <th>V216</th>
      <th>V217</th>
      <th>V218</th>
      <th>V219</th>
      <th>V220</th>
      <th>V221</th>
      <th>V222</th>
      <th>V223</th>
      <th>V224</th>
      <th>V225</th>
      <th>V226</th>
      <th>V227</th>
      <th>V228</th>
      <th>V229</th>
      <th>V230</th>
      <th>V231</th>
      <th>V232</th>
      <th>V233</th>
      <th>V234</th>
      <th>V235</th>
      <th>V236</th>
      <th>V237</th>
      <th>V238</th>
      <th>V239</th>
      <th>V240</th>
      <th>V241</th>
      <th>V242</th>
      <th>V243</th>
      <th>V244</th>
      <th>V245</th>
      <th>V246</th>
      <th>V247</th>
      <th>V248</th>
      <th>V249</th>
      <th>V250</th>
      <th>V251</th>
      <th>V252</th>
      <th>V253</th>
      <th>V254</th>
      <th>V255</th>
      <th>V256</th>
      <th>V257</th>
      <th>V258</th>
      <th>V259</th>
      <th>V260</th>
      <th>V261</th>
      <th>V262</th>
      <th>V263</th>
      <th>V264</th>
      <th>V265</th>
      <th>V266</th>
      <th>V267</th>
      <th>V268</th>
      <th>V269</th>
      <th>V270</th>
      <th>V271</th>
      <th>V272</th>
      <th>V273</th>
      <th>V274</th>
      <th>V275</th>
      <th>V276</th>
      <th>V277</th>
      <th>V278</th>
      <th>V279</th>
      <th>V280</th>
      <th>V281</th>
      <th>V282</th>
      <th>V283</th>
      <th>V284</th>
      <th>V285</th>
      <th>V286</th>
      <th>V287</th>
      <th>V288</th>
      <th>V289</th>
      <th>V290</th>
      <th>V291</th>
      <th>V292</th>
      <th>V293</th>
      <th>V294</th>
      <th>V295</th>
      <th>V296</th>
      <th>V297</th>
      <th>V298</th>
      <th>V299</th>
      <th>V300</th>
      <th>V301</th>
      <th>V302</th>
      <th>V303</th>
      <th>V304</th>
      <th>V305</th>
      <th>V306</th>
      <th>V307</th>
      <th>V308</th>
      <th>V309</th>
      <th>V310</th>
      <th>V311</th>
      <th>V312</th>
      <th>V313</th>
      <th>V314</th>
      <th>V315</th>
      <th>V316</th>
      <th>V317</th>
      <th>V318</th>
      <th>V319</th>
      <th>V320</th>
      <th>V321</th>
      <th>V322</th>
      <th>V323</th>
      <th>V324</th>
      <th>V325</th>
      <th>V326</th>
      <th>V327</th>
      <th>V328</th>
      <th>V329</th>
      <th>V330</th>
      <th>V331</th>
      <th>V332</th>
      <th>V333</th>
      <th>V334</th>
      <th>V335</th>
      <th>V336</th>
      <th>V337</th>
      <th>V338</th>
      <th>V339</th>
      <th>id_01</th>
      <th>id_02</th>
      <th>id_05</th>
      <th>id_06</th>
      <th>id_11</th>
      <th>id_13</th>
      <th>id_14</th>
      <th>id_17</th>
      <th>id_19</th>
      <th>id_20</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>71954</th>
      <td>3058954.0</td>
      <td>1615367.0</td>
      <td>77.00</td>
      <td>13597.0</td>
      <td>198.0</td>
      <td>150.0</td>
      <td>226.0</td>
      <td>191.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>44.0</td>
      <td>4.0</td>
      <td>66.0</td>
      <td>66.0</td>
      <td>1.0</td>
      <td>182.0</td>
      <td>1.0</td>
      <td>182.0</td>
      <td>182.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>19.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>18.0</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>77.000000</td>
      <td>1353.000000</td>
      <td>443.000000</td>
      <td>77.0</td>
      <td>1294.000000</td>
      <td>384.0</td>
      <td>0.0</td>
      <td>59.0</td>
      <td>59.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>20.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>77.000000</td>
      <td>1394.000000</td>
      <td>384.000000</td>
      <td>77.0</td>
      <td>1394.000000</td>
      <td>0.0</td>
      <td>384.0</td>
      <td>0.000000</td>
      <td>110.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>102450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>352.0</td>
      <td>391.0</td>
    </tr>
    <tr>
      <th>63588</th>
      <td>3050588.0</td>
      <td>1447363.0</td>
      <td>112.99</td>
      <td>13964.0</td>
      <td>496.0</td>
      <td>150.0</td>
      <td>224.0</td>
      <td>299.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>103.0</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>9.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>102450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>352.0</td>
      <td>391.0</td>
    </tr>
    <tr>
      <th>77177</th>
      <td>3064177.0</td>
      <td>1697464.0</td>
      <td>35.95</td>
      <td>6726.0</td>
      <td>480.0</td>
      <td>150.0</td>
      <td>117.0</td>
      <td>177.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>29.0</td>
      <td>29.0</td>
      <td>0.0</td>
      <td>29.0</td>
      <td>0.0</td>
      <td>29.0</td>
      <td>29.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>97.849998</td>
      <td>205.800003</td>
      <td>97.849998</td>
      <td>0.0</td>
      <td>107.949997</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>97.849998</td>
      <td>97.849998</td>
      <td>97.849998</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>97.849998</td>
      <td>421.700012</td>
      <td>97.849998</td>
      <td>0.0</td>
      <td>107.949997</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>107.949997</td>
      <td>107.949997</td>
      <td>107.949997</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>97.849998</td>
      <td>313.75</td>
      <td>97.849998</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>102450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>352.0</td>
      <td>391.0</td>
    </tr>
    <tr>
      <th>34344</th>
      <td>3021344.0</td>
      <td>850084.0</td>
      <td>34.00</td>
      <td>14858.0</td>
      <td>558.0</td>
      <td>150.0</td>
      <td>226.0</td>
      <td>325.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>21.0</td>
      <td>21.0</td>
      <td>444.0</td>
      <td>10.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>24.500000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>24.500000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>24.500000</td>
      <td>24.500000</td>
      <td>24.500000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>102450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>352.0</td>
      <td>391.0</td>
    </tr>
    <tr>
      <th>28792</th>
      <td>3015792.0</td>
      <td>740354.0</td>
      <td>50.00</td>
      <td>12544.0</td>
      <td>321.0</td>
      <td>150.0</td>
      <td>226.0</td>
      <td>476.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>103.0</td>
      <td>8.0</td>
      <td>20.0</td>
      <td>9.0</td>
      <td>14.0</td>
      <td>45.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>16.0</td>
      <td>28.0</td>
      <td>146.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2410.0</td>
      <td>54.0</td>
      <td>65.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>28414.980469</td>
      <td>335129.62500</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1550.0</td>
      <td>10510.0</td>
      <td>2866.98999</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>88277.0</td>
      <td>6.0</td>
      <td>-14.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>321.0</td>
      <td>600.0</td>
    </tr>
    <tr>
      <th>95221</th>
      <td>3082221.0</td>
      <td>1962368.0</td>
      <td>100.00</td>
      <td>8830.0</td>
      <td>250.0</td>
      <td>150.0</td>
      <td>226.0</td>
      <td>441.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>21.0</td>
      <td>3.0</td>
      <td>176.0</td>
      <td>176.0</td>
      <td>21.0</td>
      <td>20.0</td>
      <td>9.0</td>
      <td>318.0</td>
      <td>318.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>100.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>100.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>100.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>100.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>100.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>49088.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>653.0</td>
      <td>161.0</td>
    </tr>
    <tr>
      <th>37328</th>
      <td>3024328.0</td>
      <td>929780.0</td>
      <td>213.00</td>
      <td>13844.0</td>
      <td>583.0</td>
      <td>150.0</td>
      <td>226.0</td>
      <td>325.0</td>
      <td>87.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>103.0</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>9.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>102450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>352.0</td>
      <td>391.0</td>
    </tr>
    <tr>
      <th>36539</th>
      <td>3023539.0</td>
      <td>912735.0</td>
      <td>50.00</td>
      <td>6140.0</td>
      <td>265.0</td>
      <td>150.0</td>
      <td>226.0</td>
      <td>226.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>103.0</td>
      <td>8.0</td>
      <td>20.0</td>
      <td>9.0</td>
      <td>14.0</td>
      <td>45.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>28.0</td>
      <td>52.0</td>
      <td>180.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2825.0</td>
      <td>53.0</td>
      <td>67.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>36323.988281</td>
      <td>395689.59375</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2160.0</td>
      <td>12800.0</td>
      <td>4890.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>98623.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-360.0</td>
      <td>166.0</td>
      <td>548.0</td>
      <td>299.0</td>
    </tr>
    <tr>
      <th>43436</th>
      <td>3030436.0</td>
      <td>1038863.0</td>
      <td>107.95</td>
      <td>17188.0</td>
      <td>321.0</td>
      <td>150.0</td>
      <td>226.0</td>
      <td>299.0</td>
      <td>87.0</td>
      <td>9.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>1.0</td>
      <td>203.0</td>
      <td>203.0</td>
      <td>24.0</td>
      <td>20.0</td>
      <td>9.0</td>
      <td>182.0</td>
      <td>377.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>87.949997</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>87.949997</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>87.949997</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>87.949997</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>102450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>352.0</td>
      <td>391.0</td>
    </tr>
    <tr>
      <th>68975</th>
      <td>3055975.0</td>
      <td>1551926.0</td>
      <td>159.95</td>
      <td>9885.0</td>
      <td>481.0</td>
      <td>150.0</td>
      <td>117.0</td>
      <td>264.0</td>
      <td>87.0</td>
      <td>47.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>103.0</td>
      <td>8.0</td>
      <td>20.0</td>
      <td>9.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.00000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-5.0</td>
      <td>102450.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>100.0</td>
      <td>52.0</td>
      <td>-300.0</td>
      <td>166.0</td>
      <td>352.0</td>
      <td>391.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Verificamos resultados</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Revisamos resultados</span>
<span class="n">df</span><span class="p">[</span><span class="n">categoricas</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ProductCD</th>
      <th>card4</th>
      <th>card6</th>
      <th>P_emaildomain</th>
      <th>R_emaildomain</th>
      <th>M1</th>
      <th>M2</th>
      <th>M3</th>
      <th>M4</th>
      <th>M5</th>
      <th>M6</th>
      <th>id_12</th>
      <th>id_15</th>
      <th>id_16</th>
      <th>id_28</th>
      <th>id_29</th>
      <th>id_31</th>
      <th>id_35</th>
      <th>id_36</th>
      <th>id_37</th>
      <th>id_38</th>
      <th>DeviceType</th>
      <th>DeviceInfo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>80452</th>
      <td>W</td>
      <td>mastercard</td>
      <td>debit</td>
      <td>anonymous.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>F</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>87512</th>
      <td>W</td>
      <td>mastercard</td>
      <td>debit</td>
      <td>gmail.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>T</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>58135</th>
      <td>W</td>
      <td>visa</td>
      <td>debit</td>
      <td>gmail.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>T</td>
      <td>F</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>19390</th>
      <td>W</td>
      <td>visa</td>
      <td>debit</td>
      <td>gmail.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M2</td>
      <td>T</td>
      <td>T</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>74714</th>
      <td>H</td>
      <td>visa</td>
      <td>credit</td>
      <td>anonymous.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>F</td>
      <td>NotFound</td>
      <td>New</td>
      <td>NotFound</td>
      <td>New</td>
      <td>NotFound</td>
      <td>mobile safari 11.0</td>
      <td>T</td>
      <td>F</td>
      <td>F</td>
      <td>T</td>
      <td>mobile</td>
      <td>iOS Device</td>
    </tr>
    <tr>
      <th>97724</th>
      <td>W</td>
      <td>visa</td>
      <td>credit</td>
      <td>aol.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>T</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>62702</th>
      <td>C</td>
      <td>visa</td>
      <td>debit</td>
      <td>anonymous.com</td>
      <td>anonymous.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M2</td>
      <td>F</td>
      <td>F</td>
      <td>NotFound</td>
      <td>New</td>
      <td>NotFound</td>
      <td>New</td>
      <td>NotFound</td>
      <td>mobile safari 11.0</td>
      <td>F</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>mobile</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>19388</th>
      <td>W</td>
      <td>visa</td>
      <td>debit</td>
      <td>gmail.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>F</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>72250</th>
      <td>W</td>
      <td>visa</td>
      <td>debit</td>
      <td>gmail.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>F</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
    <tr>
      <th>20549</th>
      <td>W</td>
      <td>visa</td>
      <td>debit</td>
      <td>gmail.com</td>
      <td>gmail.com</td>
      <td>T</td>
      <td>T</td>
      <td>T</td>
      <td>M0</td>
      <td>F</td>
      <td>T</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>NotFound</td>
      <td>Found</td>
      <td>Found</td>
      <td>chrome 63.0</td>
      <td>T</td>
      <td>F</td>
      <td>T</td>
      <td>T</td>
      <td>desktop</td>
      <td>Windows</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>De este modo, ya no deberíamos tener valores nulos en nuestro df. Vamos a verificarlo a continuación</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Cantidad de nulos en el dataframe</span>
<span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizaciones-y-estadistica-descriptiva">
<h2>VISUALIZACIONES Y ESTADISTICA DESCRIPTIVA<a class="headerlink" href="#visualizaciones-y-estadistica-descriptiva" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TransactionID</th>
      <th>TransactionDT</th>
      <th>TransactionAmt</th>
      <th>card1</th>
      <th>card2</th>
      <th>card3</th>
      <th>card5</th>
      <th>addr1</th>
      <th>addr2</th>
      <th>dist1</th>
      <th>C1</th>
      <th>C2</th>
      <th>C3</th>
      <th>C4</th>
      <th>C5</th>
      <th>C6</th>
      <th>C7</th>
      <th>C8</th>
      <th>C9</th>
      <th>C10</th>
      <th>C11</th>
      <th>C12</th>
      <th>C13</th>
      <th>C14</th>
      <th>D1</th>
      <th>D2</th>
      <th>D3</th>
      <th>D4</th>
      <th>D5</th>
      <th>D10</th>
      <th>D15</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>V29</th>
      <th>V30</th>
      <th>V31</th>
      <th>V32</th>
      <th>V33</th>
      <th>V34</th>
      <th>V35</th>
      <th>V36</th>
      <th>V37</th>
      <th>V38</th>
      <th>V39</th>
      <th>V40</th>
      <th>V41</th>
      <th>V42</th>
      <th>V43</th>
      <th>V44</th>
      <th>V45</th>
      <th>V46</th>
      <th>V47</th>
      <th>V48</th>
      <th>V49</th>
      <th>V50</th>
      <th>V51</th>
      <th>V52</th>
      <th>V53</th>
      <th>V54</th>
      <th>V55</th>
      <th>V56</th>
      <th>V57</th>
      <th>V58</th>
      <th>V59</th>
      <th>V60</th>
      <th>V61</th>
      <th>V62</th>
      <th>V63</th>
      <th>V64</th>
      <th>V65</th>
      <th>V66</th>
      <th>V67</th>
      <th>V68</th>
      <th>V69</th>
      <th>V70</th>
      <th>V71</th>
      <th>V72</th>
      <th>V73</th>
      <th>V74</th>
      <th>V75</th>
      <th>V76</th>
      <th>V77</th>
      <th>V78</th>
      <th>V79</th>
      <th>V80</th>
      <th>V81</th>
      <th>V82</th>
      <th>V83</th>
      <th>V84</th>
      <th>V85</th>
      <th>V86</th>
      <th>V87</th>
      <th>V88</th>
      <th>V89</th>
      <th>V90</th>
      <th>V91</th>
      <th>V92</th>
      <th>V93</th>
      <th>V94</th>
      <th>V95</th>
      <th>V96</th>
      <th>V97</th>
      <th>V98</th>
      <th>V99</th>
      <th>V100</th>
      <th>V101</th>
      <th>V102</th>
      <th>V103</th>
      <th>V104</th>
      <th>V105</th>
      <th>V106</th>
      <th>V107</th>
      <th>V108</th>
      <th>V109</th>
      <th>V110</th>
      <th>V111</th>
      <th>V112</th>
      <th>V113</th>
      <th>V114</th>
      <th>V115</th>
      <th>V116</th>
      <th>V117</th>
      <th>V118</th>
      <th>V119</th>
      <th>V120</th>
      <th>V121</th>
      <th>V122</th>
      <th>V123</th>
      <th>V124</th>
      <th>V125</th>
      <th>V126</th>
      <th>V127</th>
      <th>V128</th>
      <th>V129</th>
      <th>V130</th>
      <th>V131</th>
      <th>V132</th>
      <th>V133</th>
      <th>V134</th>
      <th>V135</th>
      <th>V136</th>
      <th>V137</th>
      <th>V138</th>
      <th>V139</th>
      <th>V140</th>
      <th>V141</th>
      <th>V142</th>
      <th>V143</th>
      <th>V144</th>
      <th>V145</th>
      <th>V146</th>
      <th>V147</th>
      <th>V148</th>
      <th>V149</th>
      <th>V150</th>
      <th>V151</th>
      <th>V152</th>
      <th>V153</th>
      <th>V154</th>
      <th>V155</th>
      <th>V156</th>
      <th>V157</th>
      <th>V158</th>
      <th>V159</th>
      <th>V160</th>
      <th>V161</th>
      <th>V162</th>
      <th>V163</th>
      <th>V164</th>
      <th>V165</th>
      <th>V166</th>
      <th>V167</th>
      <th>V168</th>
      <th>V169</th>
      <th>V170</th>
      <th>V171</th>
      <th>V172</th>
      <th>V173</th>
      <th>V174</th>
      <th>V175</th>
      <th>V176</th>
      <th>V177</th>
      <th>V178</th>
      <th>V179</th>
      <th>V180</th>
      <th>V181</th>
      <th>V182</th>
      <th>V183</th>
      <th>V184</th>
      <th>V185</th>
      <th>V186</th>
      <th>V187</th>
      <th>V188</th>
      <th>V189</th>
      <th>V190</th>
      <th>V191</th>
      <th>V192</th>
      <th>V193</th>
      <th>V194</th>
      <th>V195</th>
      <th>V196</th>
      <th>V197</th>
      <th>V198</th>
      <th>V199</th>
      <th>V200</th>
      <th>V201</th>
      <th>V202</th>
      <th>V203</th>
      <th>V204</th>
      <th>V205</th>
      <th>V206</th>
      <th>V207</th>
      <th>V208</th>
      <th>V209</th>
      <th>V210</th>
      <th>V211</th>
      <th>V212</th>
      <th>V213</th>
      <th>V214</th>
      <th>V215</th>
      <th>V216</th>
      <th>V217</th>
      <th>V218</th>
      <th>V219</th>
      <th>V220</th>
      <th>V221</th>
      <th>V222</th>
      <th>V223</th>
      <th>V224</th>
      <th>V225</th>
      <th>V226</th>
      <th>V227</th>
      <th>V228</th>
      <th>V229</th>
      <th>V230</th>
      <th>V231</th>
      <th>V232</th>
      <th>V233</th>
      <th>V234</th>
      <th>V235</th>
      <th>V236</th>
      <th>V237</th>
      <th>V238</th>
      <th>V239</th>
      <th>V240</th>
      <th>V241</th>
      <th>V242</th>
      <th>V243</th>
      <th>V244</th>
      <th>V245</th>
      <th>V246</th>
      <th>V247</th>
      <th>V248</th>
      <th>V249</th>
      <th>V250</th>
      <th>V251</th>
      <th>V252</th>
      <th>V253</th>
      <th>V254</th>
      <th>V255</th>
      <th>V256</th>
      <th>V257</th>
      <th>V258</th>
      <th>V259</th>
      <th>V260</th>
      <th>V261</th>
      <th>V262</th>
      <th>V263</th>
      <th>V264</th>
      <th>V265</th>
      <th>V266</th>
      <th>V267</th>
      <th>V268</th>
      <th>V269</th>
      <th>V270</th>
      <th>V271</th>
      <th>V272</th>
      <th>V273</th>
      <th>V274</th>
      <th>V275</th>
      <th>V276</th>
      <th>V277</th>
      <th>V278</th>
      <th>V279</th>
      <th>V280</th>
      <th>V281</th>
      <th>V282</th>
      <th>V283</th>
      <th>V284</th>
      <th>V285</th>
      <th>V286</th>
      <th>V287</th>
      <th>V288</th>
      <th>V289</th>
      <th>V290</th>
      <th>V291</th>
      <th>V292</th>
      <th>V293</th>
      <th>V294</th>
      <th>V295</th>
      <th>V296</th>
      <th>V297</th>
      <th>V298</th>
      <th>V299</th>
      <th>V300</th>
      <th>V301</th>
      <th>V302</th>
      <th>V303</th>
      <th>V304</th>
      <th>V305</th>
      <th>V306</th>
      <th>V307</th>
      <th>V308</th>
      <th>V309</th>
      <th>V310</th>
      <th>V311</th>
      <th>V312</th>
      <th>V313</th>
      <th>V314</th>
      <th>V315</th>
      <th>V316</th>
      <th>V317</th>
      <th>V318</th>
      <th>V319</th>
      <th>V320</th>
      <th>V321</th>
      <th>V322</th>
      <th>V323</th>
      <th>V324</th>
      <th>V325</th>
      <th>V326</th>
      <th>V327</th>
      <th>V328</th>
      <th>V329</th>
      <th>V330</th>
      <th>V331</th>
      <th>V332</th>
      <th>V333</th>
      <th>V334</th>
      <th>V335</th>
      <th>V336</th>
      <th>V337</th>
      <th>V338</th>
      <th>V339</th>
      <th>id_01</th>
      <th>id_02</th>
      <th>id_05</th>
      <th>id_06</th>
      <th>id_11</th>
      <th>id_13</th>
      <th>id_14</th>
      <th>id_17</th>
      <th>id_19</th>
      <th>id_20</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>9.999900e+04</td>
      <td>9.999900e+04</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.0</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.00000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
      <td>99999.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.036999e+06</td>
      <td>1.135115e+06</td>
      <td>130.743579</td>
      <td>9878.453325</td>
      <td>371.106131</td>
      <td>153.236612</td>
      <td>200.208162</td>
      <td>292.099771</td>
      <td>86.310643</td>
      <td>43.966550</td>
      <td>40.123261</td>
      <td>46.713087</td>
      <td>0.012320</td>
      <td>18.716437</td>
      <td>4.110051</td>
      <td>22.679227</td>
      <td>15.434844</td>
      <td>25.488205</td>
      <td>3.257333</td>
      <td>26.058611</td>
      <td>29.044140</td>
      <td>21.616686</td>
      <td>44.700247</td>
      <td>16.665407</td>
      <td>73.678377</td>
      <td>129.204602</td>
      <td>17.191462</td>
      <td>77.690707</td>
      <td>20.415354</td>
      <td>84.229792</td>
      <td>113.087861</td>
      <td>0.339943</td>
      <td>0.676247</td>
      <td>0.999520</td>
      <td>0.089331</td>
      <td>0.094061</td>
      <td>0.103951</td>
      <td>0.107891</td>
      <td>0.850359</td>
      <td>0.879079</td>
      <td>0.100341</td>
      <td>0.104091</td>
      <td>1.025740</td>
      <td>1.044390</td>
      <td>0.968580</td>
      <td>0.980480</td>
      <td>0.001350</td>
      <td>0.001380</td>
      <td>0.257213</td>
      <td>0.268943</td>
      <td>0.113521</td>
      <td>0.119031</td>
      <td>0.089431</td>
      <td>0.094161</td>
      <td>0.244492</td>
      <td>0.261423</td>
      <td>1.059831</td>
      <td>1.085211</td>
      <td>0.124211</td>
      <td>0.129291</td>
      <td>0.99936</td>
      <td>0.118671</td>
      <td>0.125011</td>
      <td>1.041820</td>
      <td>1.061821</td>
      <td>1.016340</td>
      <td>1.025560</td>
      <td>0.189002</td>
      <td>0.195762</td>
      <td>0.128111</td>
      <td>0.110891</td>
      <td>0.114441</td>
      <td>0.346963</td>
      <td>0.676227</td>
      <td>1.042980</td>
      <td>1.067841</td>
      <td>0.107091</td>
      <td>0.108851</td>
      <td>0.111771</td>
      <td>0.115461</td>
      <td>0.856059</td>
      <td>0.882729</td>
      <td>0.108331</td>
      <td>0.113221</td>
      <td>0.999680</td>
      <td>0.96997</td>
      <td>0.981770</td>
      <td>0.000890</td>
      <td>0.257633</td>
      <td>0.268363</td>
      <td>0.122261</td>
      <td>0.124661</td>
      <td>0.110291</td>
      <td>0.113781</td>
      <td>0.310513</td>
      <td>0.337443</td>
      <td>1.052721</td>
      <td>1.077211</td>
      <td>0.108571</td>
      <td>0.126891</td>
      <td>0.130111</td>
      <td>0.893959</td>
      <td>0.918559</td>
      <td>0.121641</td>
      <td>0.126371</td>
      <td>1.040010</td>
      <td>1.059971</td>
      <td>0.999260</td>
      <td>0.001410</td>
      <td>0.251043</td>
      <td>0.261873</td>
      <td>0.135341</td>
      <td>0.137071</td>
      <td>0.104461</td>
      <td>0.241032</td>
      <td>1.112401</td>
      <td>0.482905</td>
      <td>0.053811</td>
      <td>0.597436</td>
      <td>0.187832</td>
      <td>0.120221</td>
      <td>0.395964</td>
      <td>0.211302</td>
      <td>0.064501</td>
      <td>0.116031</td>
      <td>0.081011</td>
      <td>1.0</td>
      <td>1.003860</td>
      <td>1.008610</td>
      <td>1.005370</td>
      <td>1.003280</td>
      <td>1.004320</td>
      <td>1.003600</td>
      <td>1.00679</td>
      <td>1.017090</td>
      <td>1.009810</td>
      <td>1.00106</td>
      <td>1.00133</td>
      <td>1.001140</td>
      <td>1.001470</td>
      <td>1.002630</td>
      <td>1.001710</td>
      <td>1.02867</td>
      <td>1.063481</td>
      <td>1.03884</td>
      <td>46.932665</td>
      <td>135.545621</td>
      <td>75.052896</td>
      <td>8.358164</td>
      <td>60.069257</td>
      <td>22.315164</td>
      <td>23.374937</td>
      <td>53.766797</td>
      <td>34.964653</td>
      <td>14.723684</td>
      <td>21.190317</td>
      <td>17.264200</td>
      <td>0.011710</td>
      <td>0.981610</td>
      <td>0.990040</td>
      <td>0.00865</td>
      <td>0.010150</td>
      <td>2.010760</td>
      <td>2.707667</td>
      <td>16.846618</td>
      <td>0.036130</td>
      <td>0.037180</td>
      <td>0.897699</td>
      <td>0.899139</td>
      <td>222.531185</td>
      <td>5.135591</td>
      <td>6.377304</td>
      <td>0.895999</td>
      <td>0.896469</td>
      <td>0.898739</td>
      <td>0.900259</td>
      <td>0.909589</td>
      <td>0.912179</td>
      <td>2190.707013</td>
      <td>35122.01197</td>
      <td>1.748927</td>
      <td>2.035150</td>
      <td>1.918599</td>
      <td>178.962704</td>
      <td>1030.675506</td>
      <td>239.608740</td>
      <td>0.246602</td>
      <td>0.620416</td>
      <td>0.054881</td>
      <td>1.127291</td>
      <td>1.153542</td>
      <td>0.077661</td>
      <td>0.022900</td>
      <td>0.033330</td>
      <td>0.039270</td>
      <td>1.132891</td>
      <td>0.106381</td>
      <td>0.405224</td>
      <td>0.225212</td>
      <td>0.182772</td>
      <td>0.055671</td>
      <td>0.147181</td>
      <td>0.090051</td>
      <td>0.047590</td>
      <td>0.049150</td>
      <td>1.078471</td>
      <td>1.504685</td>
      <td>0.99428</td>
      <td>0.998800</td>
      <td>1.091351</td>
      <td>1.043600</td>
      <td>1.152492</td>
      <td>1.109171</td>
      <td>0.98295</td>
      <td>0.984440</td>
      <td>1.070041</td>
      <td>0.985670</td>
      <td>0.987990</td>
      <td>1.108571</td>
      <td>1.016960</td>
      <td>1.023840</td>
      <td>49.028409</td>
      <td>280.776956</td>
      <td>131.485317</td>
      <td>14.301725</td>
      <td>3.367692</td>
      <td>58.268613</td>
      <td>3.979714</td>
      <td>12.810369</td>
      <td>4.283465</td>
      <td>20.334587</td>
      <td>117.473988</td>
      <td>47.995277</td>
      <td>13.129137</td>
      <td>42.161537</td>
      <td>20.905464</td>
      <td>0.172882</td>
      <td>0.414794</td>
      <td>0.254363</td>
      <td>0.053941</td>
      <td>1.095331</td>
      <td>1.116831</td>
      <td>0.034210</td>
      <td>0.182082</td>
      <td>0.083321</td>
      <td>0.058761</td>
      <td>0.056361</td>
      <td>1.070561</td>
      <td>1.231512</td>
      <td>1.125491</td>
      <td>0.085541</td>
      <td>0.138071</td>
      <td>0.104941</td>
      <td>0.831488</td>
      <td>0.049150</td>
      <td>0.086271</td>
      <td>0.061411</td>
      <td>0.047380</td>
      <td>0.04937</td>
      <td>1.000360</td>
      <td>1.000130</td>
      <td>1.02594</td>
      <td>1.068181</td>
      <td>1.026180</td>
      <td>0.963280</td>
      <td>1.035070</td>
      <td>1.010030</td>
      <td>1.041520</td>
      <td>1.024090</td>
      <td>0.935719</td>
      <td>0.937759</td>
      <td>1.016400</td>
      <td>1.145481</td>
      <td>1.060171</td>
      <td>0.947249</td>
      <td>0.950750</td>
      <td>1.049420</td>
      <td>1.101251</td>
      <td>0.984590</td>
      <td>0.988530</td>
      <td>1.04338</td>
      <td>1.007960</td>
      <td>33.172280</td>
      <td>92.627157</td>
      <td>52.068747</td>
      <td>4.805262</td>
      <td>26.207911</td>
      <td>12.367047</td>
      <td>3.788713</td>
      <td>4.235546</td>
      <td>4.698912</td>
      <td>4.473063</td>
      <td>15.337425</td>
      <td>39.216864</td>
      <td>22.450335</td>
      <td>12.376203</td>
      <td>23.907857</td>
      <td>16.496148</td>
      <td>0.312583</td>
      <td>0.737757</td>
      <td>0.082141</td>
      <td>0.895499</td>
      <td>1.050891</td>
      <td>0.073401</td>
      <td>0.845228</td>
      <td>0.031020</td>
      <td>0.262493</td>
      <td>0.144651</td>
      <td>0.183612</td>
      <td>1.087321</td>
      <td>1.598516</td>
      <td>1.217562</td>
      <td>0.167482</td>
      <td>0.893239</td>
      <td>0.378284</td>
      <td>0.178542</td>
      <td>0.067431</td>
      <td>0.152112</td>
      <td>0.092071</td>
      <td>0.054071</td>
      <td>0.057591</td>
      <td>0.409384</td>
      <td>0.429204</td>
      <td>0.416534</td>
      <td>1.000020</td>
      <td>55.708930</td>
      <td>208.233712</td>
      <td>103.145874</td>
      <td>9.511276</td>
      <td>83.589593</td>
      <td>4.324433</td>
      <td>29.227626</td>
      <td>16.181607</td>
      <td>32.438700</td>
      <td>20.096434</td>
      <td>29.049286</td>
      <td>97.470667</td>
      <td>53.292785</td>
      <td>16.422558</td>
      <td>26.314174</td>
      <td>19.808378</td>
      <td>0.101471</td>
      <td>0.174802</td>
      <td>0.127301</td>
      <td>0.012670</td>
      <td>0.066551</td>
      <td>0.028970</td>
      <td>0.039570</td>
      <td>0.049810</td>
      <td>0.04253</td>
      <td>27.419432</td>
      <td>33.787499</td>
      <td>30.588292</td>
      <td>3.088486</td>
      <td>5.989324</td>
      <td>4.305647</td>
      <td>9.884791</td>
      <td>11.113859</td>
      <td>10.391476</td>
      <td>-6.383844</td>
      <td>116157.055691</td>
      <td>0.809788</td>
      <td>-2.415164</td>
      <td>99.870563</td>
      <td>50.575016</td>
      <td>-314.505445</td>
      <td>170.872599</td>
      <td>356.206462</td>
      <td>387.965360</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.886737e+04</td>
      <td>5.733446e+05</td>
      <td>206.025702</td>
      <td>4933.557719</td>
      <td>158.173664</td>
      <td>11.151425</td>
      <td>40.840823</td>
      <td>98.333564</td>
      <td>4.827878</td>
      <td>216.090864</td>
      <td>307.777236</td>
      <td>358.773263</td>
      <td>0.133299</td>
      <td>156.074305</td>
      <td>21.332050</td>
      <td>156.846547</td>
      <td>149.239373</td>
      <td>228.389394</td>
      <td>13.966058</td>
      <td>229.174518</td>
      <td>215.377667</td>
      <td>209.419248</td>
      <td>218.386315</td>
      <td>102.565735</td>
      <td>136.296198</td>
      <td>109.762024</td>
      <td>42.164523</td>
      <td>135.654863</td>
      <td>51.977566</td>
      <td>144.440652</td>
      <td>154.032942</td>
      <td>0.483285</td>
      <td>0.496890</td>
      <td>0.021904</td>
      <td>0.306744</td>
      <td>0.357065</td>
      <td>0.340216</td>
      <td>0.365612</td>
      <td>0.402108</td>
      <td>0.451267</td>
      <td>0.310763</td>
      <td>0.336805</td>
      <td>0.224941</td>
      <td>0.299769</td>
      <td>0.214741</td>
      <td>0.261687</td>
      <td>0.038577</td>
      <td>0.039473</td>
      <td>0.454265</td>
      <td>0.485876</td>
      <td>0.341431</td>
      <td>0.391158</td>
      <td>0.303107</td>
      <td>0.348104</td>
      <td>0.442468</td>
      <td>0.464546</td>
      <td>0.411283</td>
      <td>0.529126</td>
      <td>0.369221</td>
      <td>0.394585</td>
      <td>0.02529</td>
      <td>0.337860</td>
      <td>0.369466</td>
      <td>0.281661</td>
      <td>0.402941</td>
      <td>0.143155</td>
      <td>0.189281</td>
      <td>0.405712</td>
      <td>0.427646</td>
      <td>0.343133</td>
      <td>0.336713</td>
      <td>0.356070</td>
      <td>0.484358</td>
      <td>0.493140</td>
      <td>0.324214</td>
      <td>0.406080</td>
      <td>0.320911</td>
      <td>0.328730</td>
      <td>0.343482</td>
      <td>0.359738</td>
      <td>0.391898</td>
      <td>0.418690</td>
      <td>0.324279</td>
      <td>0.345201</td>
      <td>0.017886</td>
      <td>0.22129</td>
      <td>0.242526</td>
      <td>0.030153</td>
      <td>0.456881</td>
      <td>0.485249</td>
      <td>0.342220</td>
      <td>0.353075</td>
      <td>0.336583</td>
      <td>0.354622</td>
      <td>0.473832</td>
      <td>0.500678</td>
      <td>0.395049</td>
      <td>0.456544</td>
      <td>0.327391</td>
      <td>0.367412</td>
      <td>0.383854</td>
      <td>0.358606</td>
      <td>0.386381</td>
      <td>0.338387</td>
      <td>0.359949</td>
      <td>0.297945</td>
      <td>0.339994</td>
      <td>0.027193</td>
      <td>0.038053</td>
      <td>0.452219</td>
      <td>0.484952</td>
      <td>0.358588</td>
      <td>0.366476</td>
      <td>0.305859</td>
      <td>0.884076</td>
      <td>4.630399</td>
      <td>1.828298</td>
      <td>0.252063</td>
      <td>1.848045</td>
      <td>0.672799</td>
      <td>0.655893</td>
      <td>3.278608</td>
      <td>1.398725</td>
      <td>0.386268</td>
      <td>0.806139</td>
      <td>0.524188</td>
      <td>0.0</td>
      <td>0.079405</td>
      <td>0.104958</td>
      <td>0.088438</td>
      <td>0.088597</td>
      <td>0.094348</td>
      <td>0.090483</td>
      <td>0.08800</td>
      <td>0.136522</td>
      <td>0.103894</td>
      <td>0.03315</td>
      <td>0.03699</td>
      <td>0.034333</td>
      <td>0.039343</td>
      <td>0.051992</td>
      <td>0.042274</td>
      <td>0.21603</td>
      <td>0.304257</td>
      <td>0.24148</td>
      <td>390.247597</td>
      <td>659.493197</td>
      <td>465.691688</td>
      <td>73.681197</td>
      <td>207.268525</td>
      <td>109.543990</td>
      <td>231.410145</td>
      <td>444.466440</td>
      <td>303.322638</td>
      <td>235.187794</td>
      <td>254.731946</td>
      <td>243.188792</td>
      <td>0.289196</td>
      <td>0.791091</td>
      <td>0.829708</td>
      <td>0.11007</td>
      <td>0.136482</td>
      <td>7.071986</td>
      <td>9.564871</td>
      <td>58.800522</td>
      <td>0.328766</td>
      <td>0.338378</td>
      <td>0.325356</td>
      <td>0.334050</td>
      <td>757.917343</td>
      <td>13.882846</td>
      <td>17.994202</td>
      <td>0.318443</td>
      <td>0.321549</td>
      <td>0.329770</td>
      <td>0.338724</td>
      <td>0.358523</td>
      <td>0.372009</td>
      <td>7639.398033</td>
      <td>124500.31373</td>
      <td>45.109656</td>
      <td>49.343035</td>
      <td>47.973162</td>
      <td>635.714391</td>
      <td>3561.617559</td>
      <td>914.090729</td>
      <td>1.875446</td>
      <td>7.749119</td>
      <td>0.504315</td>
      <td>0.809024</td>
      <td>0.938554</td>
      <td>0.986969</td>
      <td>0.186913</td>
      <td>0.208279</td>
      <td>0.281015</td>
      <td>1.460799</td>
      <td>0.833449</td>
      <td>5.146866</td>
      <td>2.567010</td>
      <td>1.942179</td>
      <td>0.387161</td>
      <td>1.467052</td>
      <td>0.780995</td>
      <td>0.328979</td>
      <td>0.342486</td>
      <td>1.176843</td>
      <td>7.898372</td>
      <td>0.27009</td>
      <td>0.327537</td>
      <td>1.260054</td>
      <td>0.690093</td>
      <td>2.217128</td>
      <td>1.640044</td>
      <td>0.16248</td>
      <td>0.174524</td>
      <td>1.165625</td>
      <td>0.179625</td>
      <td>0.211013</td>
      <td>1.350718</td>
      <td>0.416504</td>
      <td>0.469187</td>
      <td>596.431835</td>
      <td>4063.647301</td>
      <td>1787.004722</td>
      <td>207.564676</td>
      <td>47.171761</td>
      <td>949.890055</td>
      <td>56.985944</td>
      <td>186.193764</td>
      <td>59.813746</td>
      <td>238.310988</td>
      <td>1703.894788</td>
      <td>624.444567</td>
      <td>391.443629</td>
      <td>602.621681</td>
      <td>421.912626</td>
      <td>0.916291</td>
      <td>5.683622</td>
      <td>2.128208</td>
      <td>0.562900</td>
      <td>2.175182</td>
      <td>2.232411</td>
      <td>0.321996</td>
      <td>3.601723</td>
      <td>1.318390</td>
      <td>0.993905</td>
      <td>1.901188</td>
      <td>0.545717</td>
      <td>4.454082</td>
      <td>1.650744</td>
      <td>0.642177</td>
      <td>1.333597</td>
      <td>0.797371</td>
      <td>7.130255</td>
      <td>0.339877</td>
      <td>0.981421</td>
      <td>0.475608</td>
      <td>0.356536</td>
      <td>0.37075</td>
      <td>0.028282</td>
      <td>0.013784</td>
      <td>0.33783</td>
      <td>1.366495</td>
      <td>0.348105</td>
      <td>1.584652</td>
      <td>0.389542</td>
      <td>0.206326</td>
      <td>0.959903</td>
      <td>0.539459</td>
      <td>0.283918</td>
      <td>0.293578</td>
      <td>0.299254</td>
      <td>4.079381</td>
      <td>1.499451</td>
      <td>0.722771</td>
      <td>0.738428</td>
      <td>0.447305</td>
      <td>1.621262</td>
      <td>1.704884</td>
      <td>0.194677</td>
      <td>1.19387</td>
      <td>0.461888</td>
      <td>516.522875</td>
      <td>1930.499771</td>
      <td>850.439186</td>
      <td>74.740857</td>
      <td>675.646321</td>
      <td>262.553488</td>
      <td>73.997506</td>
      <td>67.135897</td>
      <td>70.913099</td>
      <td>69.485621</td>
      <td>226.880181</td>
      <td>805.429034</td>
      <td>397.911304</td>
      <td>395.671292</td>
      <td>530.969585</td>
      <td>420.237768</td>
      <td>1.277813</td>
      <td>5.036336</td>
      <td>0.518612</td>
      <td>0.975407</td>
      <td>1.838915</td>
      <td>0.292599</td>
      <td>2.148736</td>
      <td>0.186865</td>
      <td>0.769974</td>
      <td>0.382111</td>
      <td>0.518018</td>
      <td>0.838373</td>
      <td>16.277338</td>
      <td>4.246171</td>
      <td>1.086772</td>
      <td>16.492553</td>
      <td>4.775952</td>
      <td>1.512260</td>
      <td>0.410934</td>
      <td>1.168032</td>
      <td>0.593380</td>
      <td>0.349927</td>
      <td>0.361353</td>
      <td>0.521893</td>
      <td>0.596266</td>
      <td>0.539812</td>
      <td>0.004472</td>
      <td>527.341929</td>
      <td>1554.039692</td>
      <td>740.451808</td>
      <td>73.071929</td>
      <td>250.953547</td>
      <td>54.207707</td>
      <td>118.903834</td>
      <td>82.669343</td>
      <td>146.731560</td>
      <td>96.547540</td>
      <td>265.843848</td>
      <td>1359.741029</td>
      <td>549.299608</td>
      <td>402.826559</td>
      <td>422.823000</td>
      <td>408.300443</td>
      <td>0.700745</td>
      <td>1.414950</td>
      <td>0.841860</td>
      <td>0.134573</td>
      <td>0.982497</td>
      <td>0.328562</td>
      <td>0.329099</td>
      <td>0.451966</td>
      <td>0.34679</td>
      <td>364.854546</td>
      <td>409.801920</td>
      <td>384.030122</td>
      <td>54.948600</td>
      <td>73.784166</td>
      <td>61.889853</td>
      <td>168.991974</td>
      <td>175.371268</td>
      <td>172.134927</td>
      <td>8.757560</td>
      <td>78774.103299</td>
      <td>3.575495</td>
      <td>10.744679</td>
      <td>0.808040</td>
      <td>6.274939</td>
      <td>52.846069</td>
      <td>17.271215</td>
      <td>92.641599</td>
      <td>98.036072</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.987000e+06</td>
      <td>8.640000e+04</td>
      <td>0.292000</td>
      <td>1001.000000</td>
      <td>100.000000</td>
      <td>100.000000</td>
      <td>100.000000</td>
      <td>100.000000</td>
      <td>13.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-122.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-83.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-100.000000</td>
      <td>1120.000000</td>
      <td>-34.000000</td>
      <td>-100.000000</td>
      <td>90.000000</td>
      <td>10.000000</td>
      <td>-600.000000</td>
      <td>100.000000</td>
      <td>100.000000</td>
      <td>100.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>3.012000e+06</td>
      <td>6.537475e+05</td>
      <td>45.000000</td>
      <td>6019.000000</td>
      <td>219.000000</td>
      <td>150.000000</td>
      <td>166.000000</td>
      <td>204.000000</td>
      <td>87.000000</td>
      <td>9.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>103.000000</td>
      <td>8.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-5.000000</td>
      <td>102450.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>100.000000</td>
      <td>52.000000</td>
      <td>-300.000000</td>
      <td>166.000000</td>
      <td>352.000000</td>
      <td>391.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.036999e+06</td>
      <td>1.189336e+06</td>
      <td>75.000000</td>
      <td>9653.000000</td>
      <td>387.000000</td>
      <td>150.000000</td>
      <td>226.000000</td>
      <td>299.000000</td>
      <td>87.000000</td>
      <td>9.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>103.000000</td>
      <td>8.000000</td>
      <td>20.000000</td>
      <td>9.000000</td>
      <td>14.000000</td>
      <td>45.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-5.000000</td>
      <td>102450.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>100.000000</td>
      <td>52.000000</td>
      <td>-300.000000</td>
      <td>166.000000</td>
      <td>352.000000</td>
      <td>391.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.061998e+06</td>
      <td>1.643436e+06</td>
      <td>135.950000</td>
      <td>14290.000000</td>
      <td>514.000000</td>
      <td>150.000000</td>
      <td>226.000000</td>
      <td>330.000000</td>
      <td>87.000000</td>
      <td>9.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>9.000000</td>
      <td>2.000000</td>
      <td>77.000000</td>
      <td>103.000000</td>
      <td>8.000000</td>
      <td>34.000000</td>
      <td>9.000000</td>
      <td>84.000000</td>
      <td>145.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.500000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>0.000000</td>
      <td>58.470001</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>105.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>57.950001</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-5.000000</td>
      <td>102450.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>100.000000</td>
      <td>52.000000</td>
      <td>-300.000000</td>
      <td>166.000000</td>
      <td>352.000000</td>
      <td>391.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.086998e+06</td>
      <td>2.006177e+06</td>
      <td>4829.950000</td>
      <td>18395.000000</td>
      <td>600.000000</td>
      <td>229.000000</td>
      <td>237.000000</td>
      <td>540.000000</td>
      <td>102.000000</td>
      <td>7068.000000</td>
      <td>4685.000000</td>
      <td>5691.000000</td>
      <td>16.000000</td>
      <td>2253.000000</td>
      <td>295.000000</td>
      <td>2253.000000</td>
      <td>2255.000000</td>
      <td>3331.000000</td>
      <td>194.000000</td>
      <td>3257.000000</td>
      <td>3188.000000</td>
      <td>3188.000000</td>
      <td>2918.000000</td>
      <td>1429.000000</td>
      <td>639.000000</td>
      <td>639.000000</td>
      <td>674.000000</td>
      <td>721.000000</td>
      <td>720.000000</td>
      <td>721.000000</td>
      <td>721.000000</td>
      <td>3.000000</td>
      <td>5.000000</td>
      <td>1.000000</td>
      <td>7.000000</td>
      <td>15.000000</td>
      <td>15.000000</td>
      <td>15.000000</td>
      <td>7.000000</td>
      <td>15.000000</td>
      <td>5.000000</td>
      <td>8.000000</td>
      <td>13.000000</td>
      <td>13.000000</td>
      <td>7.000000</td>
      <td>13.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>5.000000</td>
      <td>7.000000</td>
      <td>15.000000</td>
      <td>7.000000</td>
      <td>13.000000</td>
      <td>3.000000</td>
      <td>4.000000</td>
      <td>15.000000</td>
      <td>23.000000</td>
      <td>10.000000</td>
      <td>10.000000</td>
      <td>1.00000</td>
      <td>4.000000</td>
      <td>6.000000</td>
      <td>14.000000</td>
      <td>25.000000</td>
      <td>4.000000</td>
      <td>6.000000</td>
      <td>3.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>4.000000</td>
      <td>6.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>14.000000</td>
      <td>15.000000</td>
      <td>6.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
      <td>9.000000</td>
      <td>6.000000</td>
      <td>7.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>1.000000</td>
      <td>5.00000</td>
      <td>8.000000</td>
      <td>2.000000</td>
      <td>4.000000</td>
      <td>5.000000</td>
      <td>6.000000</td>
      <td>7.000000</td>
      <td>5.000000</td>
      <td>8.000000</td>
      <td>3.000000</td>
      <td>4.000000</td>
      <td>17.000000</td>
      <td>17.000000</td>
      <td>7.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
      <td>3.000000</td>
      <td>5.000000</td>
      <td>17.000000</td>
      <td>17.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>4.000000</td>
      <td>5.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
      <td>1.000000</td>
      <td>27.000000</td>
      <td>118.000000</td>
      <td>48.000000</td>
      <td>5.000000</td>
      <td>46.000000</td>
      <td>20.000000</td>
      <td>20.000000</td>
      <td>101.000000</td>
      <td>45.000000</td>
      <td>12.000000</td>
      <td>38.000000</td>
      <td>22.000000</td>
      <td>1.0</td>
      <td>7.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
      <td>5.00000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>3.00000</td>
      <td>3.00000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>13.00000</td>
      <td>13.000000</td>
      <td>13.00000</td>
      <td>50820.000000</td>
      <td>50820.000000</td>
      <td>50820.000000</td>
      <td>3894.010010</td>
      <td>6019.870117</td>
      <td>4674.899902</td>
      <td>10000.000000</td>
      <td>15227.000000</td>
      <td>11260.000000</td>
      <td>50820.000000</td>
      <td>50820.000000</td>
      <td>50820.000000</td>
      <td>22.000000</td>
      <td>33.000000</td>
      <td>33.000000</td>
      <td>5.00000</td>
      <td>6.000000</td>
      <td>49.000000</td>
      <td>62.000000</td>
      <td>297.000000</td>
      <td>11.000000</td>
      <td>11.000000</td>
      <td>8.000000</td>
      <td>8.000000</td>
      <td>3389.000000</td>
      <td>57.000000</td>
      <td>68.000000</td>
      <td>6.000000</td>
      <td>8.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>44186.929688</td>
      <td>641511.43750</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>3000.000000</td>
      <td>12500.000000</td>
      <td>17493.949219</td>
      <td>101640.000000</td>
      <td>58.000000</td>
      <td>209.000000</td>
      <td>15.000000</td>
      <td>29.000000</td>
      <td>29.000000</td>
      <td>31.000000</td>
      <td>7.000000</td>
      <td>5.000000</td>
      <td>8.000000</td>
      <td>48.000000</td>
      <td>29.000000</td>
      <td>124.000000</td>
      <td>68.000000</td>
      <td>50.000000</td>
      <td>15.000000</td>
      <td>43.000000</td>
      <td>28.000000</td>
      <td>11.000000</td>
      <td>11.000000</td>
      <td>38.000000</td>
      <td>203.000000</td>
      <td>17.00000</td>
      <td>17.000000</td>
      <td>40.000000</td>
      <td>21.000000</td>
      <td>41.000000</td>
      <td>37.000000</td>
      <td>6.00000</td>
      <td>8.000000</td>
      <td>38.000000</td>
      <td>7.000000</td>
      <td>11.000000</td>
      <td>43.000000</td>
      <td>28.000000</td>
      <td>28.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>6425.000000</td>
      <td>2250.000000</td>
      <td>25525.000000</td>
      <td>3100.000000</td>
      <td>8050.000000</td>
      <td>3100.000000</td>
      <td>11000.000000</td>
      <td>66000.000000</td>
      <td>15450.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>24.000000</td>
      <td>219.000000</td>
      <td>79.000000</td>
      <td>23.000000</td>
      <td>384.000000</td>
      <td>384.000000</td>
      <td>16.000000</td>
      <td>144.000000</td>
      <td>51.000000</td>
      <td>242.000000</td>
      <td>360.000000</td>
      <td>19.000000</td>
      <td>176.000000</td>
      <td>65.000000</td>
      <td>22.000000</td>
      <td>42.000000</td>
      <td>27.000000</td>
      <td>100.000000</td>
      <td>11.000000</td>
      <td>34.000000</td>
      <td>16.000000</td>
      <td>23.000000</td>
      <td>23.00000</td>
      <td>6.000000</td>
      <td>4.000000</td>
      <td>18.00000</td>
      <td>57.000000</td>
      <td>18.000000</td>
      <td>262.000000</td>
      <td>18.000000</td>
      <td>12.000000</td>
      <td>36.000000</td>
      <td>22.000000</td>
      <td>16.000000</td>
      <td>16.000000</td>
      <td>18.000000</td>
      <td>163.000000</td>
      <td>60.000000</td>
      <td>82.000000</td>
      <td>82.000000</td>
      <td>18.000000</td>
      <td>66.000000</td>
      <td>285.000000</td>
      <td>6.000000</td>
      <td>49.00000</td>
      <td>20.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>4000.000000</td>
      <td>27000.000000</td>
      <td>12550.000000</td>
      <td>4000.000000</td>
      <td>4000.000000</td>
      <td>4000.000000</td>
      <td>4000.000000</td>
      <td>15000.000000</td>
      <td>66000.000000</td>
      <td>20850.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>65.000000</td>
      <td>323.000000</td>
      <td>22.000000</td>
      <td>32.000000</td>
      <td>68.000000</td>
      <td>5.000000</td>
      <td>50.000000</td>
      <td>4.000000</td>
      <td>20.000000</td>
      <td>5.000000</td>
      <td>7.000000</td>
      <td>66.000000</td>
      <td>937.000000</td>
      <td>323.000000</td>
      <td>65.000000</td>
      <td>949.000000</td>
      <td>322.000000</td>
      <td>61.000000</td>
      <td>12.000000</td>
      <td>47.000000</td>
      <td>22.000000</td>
      <td>11.000000</td>
      <td>11.000000</td>
      <td>7.000000</td>
      <td>17.000000</td>
      <td>9.000000</td>
      <td>2.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>3162.949951</td>
      <td>19800.000000</td>
      <td>3162.949951</td>
      <td>4015.899902</td>
      <td>3956.199951</td>
      <td>5021.899902</td>
      <td>3956.199951</td>
      <td>12000.000000</td>
      <td>77454.820312</td>
      <td>26837.498047</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>101640.000000</td>
      <td>32.000000</td>
      <td>45.000000</td>
      <td>33.000000</td>
      <td>5.000000</td>
      <td>41.000000</td>
      <td>12.000000</td>
      <td>11.000000</td>
      <td>18.000000</td>
      <td>11.00000</td>
      <td>20750.000000</td>
      <td>32250.000000</td>
      <td>21250.000000</td>
      <td>3100.000000</td>
      <td>3200.000000</td>
      <td>3100.000000</td>
      <td>8250.000000</td>
      <td>8250.000000</td>
      <td>8250.000000</td>
      <td>0.000000</td>
      <td>999595.000000</td>
      <td>52.000000</td>
      <td>0.000000</td>
      <td>100.000000</td>
      <td>63.000000</td>
      <td>720.000000</td>
      <td>229.000000</td>
      <td>671.000000</td>
      <td>660.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>OBSERVACIONES</strong></p>
<ul class="simple">
<li><p>De la anterior tabla podemos analizar que muchas de las columnas poseen un valor <code class="docutils literal notranslate"><span class="pre">promedio</span></code> inferior a la <code class="docutils literal notranslate"><span class="pre">mediana</span> <span class="pre">o</span> <span class="pre">Q50</span></code>, lo que indica que se encuentran sesgadas hacia la derecha, predominando mucho los valores iguales o cercanos al 0 cero</p></li>
</ul>
<p>Mas informacion sobre los datos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 99999 entries, 0 to 99998
Columns: 392 entries, TransactionID to DeviceInfo
dtypes: float64(369), object(23)
memory usage: 299.1+ MB
</pre></div>
</div>
</div>
</div>
<p>Veamos las distribucionees de algunas de las variables del dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;TransactionAmt&#39;</span><span class="p">],</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lw&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Monto de las transacciones&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Monto&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ac33846691c138bb295d20595fc4ed676e32268b55a83488a196d3f17fc67777.png" src="_images/ac33846691c138bb295d20595fc4ed676e32268b55a83488a196d3f17fc67777.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong>
En relacion a esta variable, se observa una cola larga hacia la derecha, es decir que la distribucion esta sesgada en esta dirección.</p>
<p>Esto significa que la gran mayoría de las transacciones son de bajo monto, mientras que unas pocas superan los 1000.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;TransactionDT&#39;</span><span class="p">],</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lw&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribucion del tiempo de referencia&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tiempo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f621b7f443d5b52d8b32d36db9ef3ae0cf953c03f577162f24b0cc3470eb3659.png" src="_images/f621b7f443d5b52d8b32d36db9ef3ae0cf953c03f577162f24b0cc3470eb3659.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong>
En relacion a esta variable, no se observan colas, sino una distribución un poco mas uniforme entret los diferntes valores de tiempo, siendo mas comunes aquellas con una duración entre 1.5 y 2.0</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">stripplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TransactionAmt&#39;</span><span class="p">],</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">],</span> <span class="n">orient</span> <span class="o">=</span> <span class="s1">&#39;h&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TransactionAmt&#39;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">],</span> <span class="n">fliersize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">orient</span> <span class="o">=</span> <span class="s1">&#39;h&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="p">[</span><span class="s1">&#39;Not Fraud&#39;</span><span class="p">,</span> <span class="s1">&#39;Fraud&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Valor de la transacción por tipo&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tipo de Transacción&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/de268dad3e6ce124874f838300cab9b3ea3d557b815b5a72378405e1b4a0895e.png" src="_images/de268dad3e6ce124874f838300cab9b3ea3d557b815b5a72378405e1b4a0895e.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong>
Las transiciones fraudulentas y no fraudulentas tienen en general valores similares de minimos, maximos y mediana.</p>
<p>Sin embargo, observamos que las Fraudulentas tienen una media menor que las No Fraudulentas.</p>
<p>Las transacciones Fraudulentas suelen ser entonces de bajo monto.</p>
<p>En las transacciones No Fraudulentas podemos observar muchas mas transacciones de alto valor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">stripplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;dist1&#39;</span><span class="p">],</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">],</span> <span class="n">orient</span> <span class="o">=</span> <span class="s1">&#39;h&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;dist1&#39;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">],</span> <span class="n">fliersize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">orient</span> <span class="o">=</span> <span class="s1">&#39;h&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="p">[</span><span class="s1">&#39;Not Fraud&#39;</span><span class="p">,</span> <span class="s1">&#39;Fraud&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distancia&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tipo de Transacción&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dbc3d9f00f8a50e209c14710ae45a76c4e015407545adc1ec1447b56f3bb310e.png" src="_images/dbc3d9f00f8a50e209c14710ae45a76c4e015407545adc1ec1447b56f3bb310e.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong> En cuando a la variable <code class="docutils literal notranslate"><span class="pre">Distancia</span></code>, sucede algo similar a lo anterior.</p>
<p>Mientras que las transacciones no fraudulentas pueden tener muchos valores muy altos, las Fraudulentes son en general de menor valor.</p>
<p>No está muy claro en qué consiste esta variable ni lo que representa. Pero hay una clara diferencia entre las clases.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#agrego la variable respuesta al df para las graficas</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualicemos algunas variables del dataset</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;DeviceType&#39;</span><span class="p">],</span> <span class="n">palette</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#eed4d0&#39;</span><span class="p">,</span> <span class="s1">&#39;#cda0aa&#39;</span><span class="p">,</span> <span class="s1">&#39;#a2708e&#39;</span><span class="p">],</span>
                   <span class="n">order</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;DeviceType&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;DeviceType&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span> <span class="o">=</span> <span class="kc">False</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">horizontalalignment</span> <span class="o">=</span> <span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">fontweight</span> <span class="o">=</span> <span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Transacciones por tipo de dispositivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Numero de transacciones&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;DeviceType&#39;</span><span class="p">],</span> <span class="n">hue</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Clasificacion de trasacciones por tipo de dispositivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Numero de transacciones&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span> <span class="s1">&#39;No Fraude&#39;</span><span class="p">,</span> <span class="s1">&#39;Fraude&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;DeviceType&#39;</span><span class="p">)[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
<span class="n">d</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="s1">&#39;True&#39;</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;proporcion de Fraudes por tipo de dispositivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span> <span class="s1">&#39;No Fraude&#39;</span><span class="p">,</span> <span class="s1">&#39;Fraude&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/387245f69e469fec80f47c6058ec2da1530459277aac8b77a613dec9c865a602.png" src="_images/387245f69e469fec80f47c6058ec2da1530459277aac8b77a613dec9c865a602.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong></p>
<p>De la gráfica que la izquierda, podemos saber que existe una importante diferencia entre los tipos de dispositivos utilizados para hacer transferencias. La gran mayoría de los movimientos de dinero se realizan desde un computador (<code class="docutils literal notranslate"><span class="pre">desktop</span></code>).</p>
<p>En la gráfica del medio distinguimos los tipos de equipo utilizados para hacer transferencias fraudulentas, sin embargo, la proporción se aprecia mejor en la gráfica de la derecha, en donde es mucho más claro que los Fraudes se realizan en mayor proporción desde un dispositivo móvil (<code class="docutils literal notranslate"><span class="pre">mobile</span></code>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualicemos algunas variables del dataset</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;card4&#39;</span><span class="p">],</span> <span class="n">palette</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#eed4d0&#39;</span><span class="p">,</span> <span class="s1">&#39;#cda0aa&#39;</span><span class="p">,</span> <span class="s1">&#39;#a2708e&#39;</span><span class="p">],</span>
                   <span class="n">order</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;card4&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;card4&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span> <span class="o">=</span> <span class="kc">False</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Transacciones por Franquicia de las Tarjetas&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Numero de transacciones&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;card4&#39;</span><span class="p">],</span> <span class="n">hue</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Clasificacion de trasacciones por Franquicia de las Tarjetas&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Numero de transacciones&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span> <span class="s1">&#39;No Fraude&#39;</span><span class="p">,</span> <span class="s1">&#39;Fraude&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

<span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;card4&#39;</span><span class="p">)[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
<span class="n">d</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="s1">&#39;True&#39;</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;proporcion de Fraudes por Franquicia de las Tarjetas&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span> <span class="s1">&#39;No Fraude&#39;</span><span class="p">,</span> <span class="s1">&#39;Fraude&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e2bca3df11c256206ebb15087a468176e5a7fea06e129acce45f1ca3d735f94b.png" src="_images/e2bca3df11c256206ebb15087a468176e5a7fea06e129acce45f1ca3d735f94b.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong></p>
<p>De la gráfica que la izquierda, podemos saber que existe una importante diferencia entre los tipos de tarjetas utilizadas para hacer transferencias. La gran mayoría de los movimientos de dinero se realizan  con una tarjeta (<code class="docutils literal notranslate"><span class="pre">visa</span></code>), pero también una porción importante se realiza a través de <code class="docutils literal notranslate"><span class="pre">mastercard</span></code>.</p>
<p>En la gráfica del medio distinguimos los tipos de tarjetas utilizados para hacer transferencias fraudulentas, sin embargo, la proporción se aprecia mejor en la gráfica de la derecha, en donde es mucho más claro que los Fraudes se realizan en casi que en igual proporción a las tarjetas <code class="docutils literal notranslate"><span class="pre">visa</span></code>, <code class="docutils literal notranslate"><span class="pre">mastercard</span></code> y <code class="docutils literal notranslate"><span class="pre">discover</span></code>, mientras que aparentemente la más segura es <code class="docutils literal notranslate"><span class="pre">american</span> <span class="pre">express</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualicemos algunas variables del dataset</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;ProductCD&#39;</span><span class="p">)[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">unstack</span><span class="p">()</span>
<span class="n">d</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;#3f3e6fd1&quot;</span><span class="p">,</span> <span class="s2">&quot;#85c6a9&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Proporción de Fraudes por tipo de producto&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tipo de Producto&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proporción de transacciones&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s1">&#39;No Fraude&#39;</span><span class="p">,</span> <span class="s1">&#39;Fraude&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5edeebaf1991f726af95a702be2d5f3d6e65fc8831964e163b209b62d950f89b.png" src="_images/5edeebaf1991f726af95a702be2d5f3d6e65fc8831964e163b209b62d950f89b.png" />
</div>
</div>
<p><strong>OBSERVACIONES</strong>
En relación a los tipos de productos, en proporción, la mayoría de los fraudes ocurren en los productos tipo <code class="docutils literal notranslate"><span class="pre">C</span></code> y los que presentan menor proporción son los de tipo <code class="docutils literal notranslate"><span class="pre">R</span></code></p>
<section id="analisis-bivariado">
<h3>Analisis Bivariado<a class="headerlink" href="#analisis-bivariado" title="Permalink to this heading">#</a></h3>
<p>En este punto voy a realizar un muestreo del dataset para facilitar el procesamiento a continuación, ya que no se han podido realizar con el dataset completo. Tomaré 5000 filas escogidas aleatoriamente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_red</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Realizamos una correlación entre todas las variables numericas</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr</span> <span class="o">=</span> <span class="n">df_red</span><span class="p">[</span><span class="n">numericas</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>  <span class="c1">#Realizamos la correlación</span>
<span class="n">corr</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(369, 369)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span> <span class="c1">#Aplicamos una máscara para facilitar la visualización</span>
<span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<p>Visualizamos la matriz de correlación, usamos una escala de colores opuestos que facilite identificar visualmente los valores extremos. Es decir, los que representan correlaciones mas fuertes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.1f&#39;</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c642bcc600134a395bc6abf5c745041a889efeb44e682e2206b0d4b64ad50984.png" src="_images/c642bcc600134a395bc6abf5c745041a889efeb44e682e2206b0d4b64ad50984.png" />
</div>
</div>
<p>Aunque en general predominan las correlaciones débiles y de valor negativo, existe un importante grupo de variables fuertemente correlacionadas (zonas rojas y azules fuertes). En general las variables <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">V</span></code> presentan fuertes correlaciones dentro de sus respectivos grupos, es decir, muchas variables <code class="docutils literal notranslate"><span class="pre">C</span></code> se correlacionan entre ellas y muchas variables V se correlacionan entre ellas. No se observa correlación significativa entre variables <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">V</span></code></p>
</section>
</section>
<section id="feature-engineering">
<h2>FEATURE ENGINEERING<a class="headerlink" href="#feature-engineering" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
</pre></div>
</div>
</div>
</div>
<p>Revisamos ahora las variables categóricas</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categoricas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;ProductCD&#39;, &#39;card4&#39;, &#39;card6&#39;, &#39;P_emaildomain&#39;, &#39;R_emaildomain&#39;, &#39;M1&#39;,
       &#39;M2&#39;, &#39;M3&#39;, &#39;M4&#39;, &#39;M5&#39;, &#39;M6&#39;, &#39;id_12&#39;, &#39;id_15&#39;, &#39;id_16&#39;, &#39;id_28&#39;,
       &#39;id_29&#39;, &#39;id_31&#39;, &#39;id_35&#39;, &#39;id_36&#39;, &#39;id_37&#39;, &#39;id_38&#39;, &#39;DeviceType&#39;,
       &#39;DeviceInfo&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>En este dataset tenemos columnas con gran cantidad de categorías, las cuales al convertirlas con el OHE nos generarían una maldición de dimensionalidad en nuestra data.</p>
<p>Para solucionar esto, identifiqué aquellas categorías que tienen una frecuencia inferior al 1% dentro de sus respectivas columnas. A estas categorías les asigné un valor de <code class="docutils literal notranslate"><span class="pre">Otro</span></code>, para que al procesarse queden todos esos valores agrupados en una sola categoría.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categorias_bajas_frecuencia</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">umbral_frecuencia</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Umbral del 1% de frecuencia relativa</span>

<span class="k">for</span> <span class="n">columna</span> <span class="ow">in</span> <span class="n">categoricas</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;---------------------&#39;</span><span class="p">)</span>
    <span class="n">n_cat</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>  <span class="c1"># Número de categorías únicas en la columna</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total de categorias de esta feature:&#39;</span><span class="p">,</span> <span class="n">n_cat</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;---------------------&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_cat</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="n">freq_rel</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]))</span> <span class="o">*</span> <span class="mi">100</span>  <span class="c1"># Frecuencia relativa en porcentaje</span>
        <span class="n">categorias_bajas_frec</span> <span class="o">=</span> <span class="n">freq_rel</span><span class="p">[</span><span class="n">freq_rel</span> <span class="o">&lt;</span> <span class="n">umbral_frecuencia</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">categorias_bajas_frecuencia</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">categorias_bajas_frec</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">categorias_bajas_frecuencia</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ProductCD
W    56877
H    15521
R    13724
C    11351
S     2526
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 5
---------------------
card4
visa                65608
mastercard          29599
american express     3330
discover             1462
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 4
---------------------
card6
debit              64926
credit             35063
debit or credit        7
charge card            3
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 4
---------------------
P_emaildomain
gmail.com           51682
yahoo.com           15883
anonymous.com        8663
hotmail.com          8119
aol.com              4866
comcast.net          1856
icloud.com            894
msn.com               852
outlook.com           767
att.net               694
sbcglobal.net         671
verizon.net           626
live.com              501
bellsouth.net         440
cox.net               376
me.com                373
ymail.com             369
yahoo.com.mx          292
charter.net           233
optonline.net         212
live.com.mx           133
mac.com               122
rocketmail.com        110
earthlink.net          98
mail.com               76
embarqmail.com         70
roadrunner.com         68
juno.com               66
outlook.es             60
gmail                  60
twc.com                54
windstream.net         54
frontier.com           49
hotmail.es             47
frontiernet.net        42
netzero.com            41
q.com                  41
cfl.rr.com             39
web.de                 39
aim.com                39
prodigy.net.mx         36
hotmail.fr             32
suddenlink.net         29
yahoo.fr               27
netzero.net            26
cableone.net           23
gmx.de                 21
centurylink.net        20
ptd.net                20
yahoo.es               19
yahoo.co.uk            16
sc.rr.com              15
hotmail.co.uk          11
protonmail.com          8
servicios-ta.com        7
yahoo.de                7
hotmail.de              2
live.fr                 2
yahoo.co.jp             1
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 59
---------------------
R_emaildomain
gmail.com           78477
anonymous.com        6954
hotmail.com          5422
yahoo.com            3222
aol.com              1327
comcast.net           783
outlook.com           438
icloud.com            318
msn.com               308
yahoo.com.mx          291
verizon.net           260
sbcglobal.net         235
cox.net               214
bellsouth.net         185
me.com                184
live.com              173
att.net               162
live.com.mx           133
ymail.com              79
optonline.net          72
mac.com                66
outlook.es             59
hotmail.es             47
mail.com               42
charter.net            41
web.de                 38
prodigy.net.mx         36
hotmail.fr             32
earthlink.net          30
embarqmail.com         30
frontier.com           28
juno.com               26
yahoo.fr               24
windstream.net         22
gmx.de                 20
roadrunner.com         19
rocketmail.com         18
cfl.rr.com             18
q.com                  16
twc.com                14
gmail                  14
suddenlink.net         13
yahoo.es               11
ptd.net                11
yahoo.co.uk            10
yahoo.de               10
frontiernet.net         9
hotmail.co.uk           8
aim.com                 8
servicios-ta.com        7
netzero.net             6
cableone.net            6
scranton.edu            5
centurylink.net         5
netzero.com             3
hotmail.de              2
live.fr                 2
yahoo.co.jp             2
protonmail.com          2
sc.rr.com               2
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 60
---------------------
M1
T    99999
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 1
---------------------
M2
T    96851
F     3148
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
M3
T    93152
F     6847
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
M4
M0    83880
M2     9410
M1     6709
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 3
---------------------
M5
F    86121
T    13878
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
M6
F    74842
T    25157
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_12
NotFound    94534
Found        5465
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_15
Found      78923
New        18839
Unknown     2237
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 3
---------------------
id_16
NotFound    81432
Found       18567
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_28
Found    82012
New      17987
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_29
Found       81309
NotFound    18690
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_31
chrome 63.0                   67861
chrome 62.0                    6372
mobile safari 11.0             5191
ie 11.0 for desktop            3867
safari generic                 3292
firefox 57.0                   2003
chrome 62.0 for android        1506
mobile safari 10.0             1382
chrome 63.0 for android        1294
edge 15.0                       962
mobile safari generic           880
edge 16.0                       808
chrome 61.0                     409
chrome generic                  385
samsung browser 6.2             359
mobile safari 9.0               286
ie 11.0 for tablet              273
chrome 49.0                     272
edge 14.0                       226
firefox                         226
chrome 61.0 for android         194
chrome 60.0                     180
firefox 52.0                    155
chrome 60.0 for android         122
chrome                          107
opera 49.0                       99
chrome 59.0 for android          83
firefox 56.0                     82
other                            75
firefox 48.0                     73
chrome 63.0 for ios              73
chrome 59.0                      61
chrome 56.0 for android          53
chrome 55.0 for android          51
chrome 62.0 for ios              46
chrome 58.0                      46
chrome 58.0 for android          45
android webview 4.0              45
mobile safari uiwebview          41
chrome 56.0                      41
chrome 57.0                      38
ie                               34
chrome 51.0                      28
mobile safari 8.0                28
edge                             26
chrome 55.0                      24
chrome 50.0 for android          23
android browser 4.0              22
Generic/Android 7.0              21
Samsung/SM-G532M                 21
edge 13.0                        20
chrome 57.0 for android          15
chrome 53.0 for android          14
chrome 54.0 for android          13
firefox generic                  13
firefox 47.0                     12
Generic/Android                  11
chrome 52.0 for android          10
opera                            10
samsung browser 5.4              10
Microsoft/Windows                10
silk                              8
chrome 46.0 for android           8
chrome 43.0 for android           8
chrome 51.0 for android           6
Samsung/SM-G531H                  6
firefox 55.0                      5
chrome 49.0 for android           4
samsung browser 4.0               4
aol                               4
waterfox                          2
samsung                           2
chrome generic for android        2
safari                            2
mobile                            2
Nokia/Lumia                       1
puffin                            1
Samsung/SCH                       1
cyberfox                          1
opera generic                     1
ZTE/Blade                         1
samsung browser 5.2               1
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 82
---------------------
id_35
T    89442
F    10557
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_36
F    97237
T     2762
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_37
T    91139
F     8860
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_38
T    89562
F    10437
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
DeviceType
desktop    87413
mobile     12586
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
DeviceInfo
Windows                                        79051
iOS Device                                      6635
MacOS                                           4914
Trident/7.0                                     3144
rv:11.0                                          823
rv:57.0                                          526
SM-G950U Build/NRD90M                            121
SM-G930V Build/NRD90M                            121
rv:52.0                                          116
SM-G955U Build/NRD90M                            115
SM-J700M Build/MMB29K                             90
rv:48.0                                           73
SM-N950U Build/NMF26X                             61
rv:56.0                                           61
SAMSUNG SM-G950U Build/NRD90M                     57
SAMSUNG                                           55
SM-G935F Build/NRD90M                             54
SM-G531H Build/LMY48B                             54
SM-G610M Build/MMB29K                             51
ALE-L23 Build/HuaweiALE-L23                       48
SM-G920V Build/NRD90M                             42
Moto G (4) Build/NPJS25.93-14-10                  41
SM-G935V Build/NRD90M                             41
SM-G900V Build/MMB29M                             38
Linux x86_64                                      36
Moto G (4) Build/NPJ25.93-14.5                    35
SM-G950F Build/NRD90M                             34
LG-D693n Build/LRX22G                             32
SAMSUNG SM-G955U Build/NRD90M                     31
SM-G532M Build/MMB29T                             29
SAMSUNG-SM-G930A Build/NRD90M                     28
SM-A300H Build/LRX22G                             27
Windows NT 6.1                                    26
WAS-LX3 Build/HUAWEIWAS-LX3                       26
MDDRJS                                            25
HUAWEI G7-L03 Build/HuaweiG7-L03                  22
F3213 Build/36.1.A.1.86                           22
HUAWEI TAG-L13 Build/HUAWEITAG-L13                22
SM-J320M Build/LMY47V                             21
LG-H500 Build/LRX21Y                              21
LG-K580 Build/MRA58K                              21
SM-G935T Build/NRD90M                             21
Moto G (5) Plus Build/NPNS25.137-15-11            21
rv:31.0                                           20
LG-K410 Build/LRX22G                              20
BLL-L23 Build/HUAWEIBLL-L23                       20
SM-G570M Build/MMB29K                             20
HTC Desire 626s Build/LMY47O                      20
SM-J710MN Build/MMB29K                            19
SM-N920V Build/NRD90M                             19
SM-J700M Build/LMY48B                             19
SM-G955F Build/NRD90M                             18
SAMSUNG SM-G930A Build/NRD90M                     18
SM-G930T Build/NRD90M                             17
PRA-LX3 Build/HUAWEIPRA-LX3                       17
XT1585 Build/NCK25.118-10.5                       17
SM-G930P Build/NRD90M                             17
LGMP260 Build/NRD90U                              17
SM-J510MN Build/MMB29M                            17
Moto X Play Build/NPD26.48-24-1                   16
XT1650 Build/NCLS26.118-23-13-3                   16
SAMSUNG SM-N950U Build/NMF26X                     16
CAM-L03 Build/HUAWEICAM-L03                       16
Moto G Play Build/MPIS24.241-15.3-7               16
HTC Desire 530 Build/MMB29M                       16
Moto E (4) Build/NMA26.42-69                      16
rv:45.0                                           15
rv:54.0                                           15
SM-A720F Build/MMB29K                             15
SAMSUNG SM-G920P Build/NRD90M                     15
VS988 Build/NRD90U                                15
XT1635-02 Build/NPN26.118-22-2                    15
LG-X210 Build/LMY47I                              14
Blade V6 Plus Build/MRA58K                        14
SM-N920T Build/NRD90M                             14
Moto G (5) Plus Build/NPN25.137-72                14
SM-G935P Build/NRD90M                             14
SM-G930F Build/NRD90M                             14
KFFOWI Build/LVY48F                               14
SM-T560 Build/KTU84P                              13
Moto G (5) Build/NPP25.137-82                     13
SAMSUNG SM-G935F Build/NRD90M                     13
F5121 Build/34.3.A.0.228                          13
rv:51.0                                           13
SM-T810 Build/NRD90M                              13
SAMSUNG-SM-G935A Build/NRD90M                     13
C6743 Build/LMY47V                                13
LG-K500 Build/MMB29M                              13
HUAWEI CUN-L03 Build/HUAWEICUN-L03                13
SAMSUNG SM-J700M Build/MMB29K                     13
KFGIWI Build/LVY48F                               12
Z981 Build/MMB29M                                 12
XT1635-01 Build/NDNS26.118-23-12-3                12
SM-G920F Build/NRD90M                             12
SAMSUNG-SM-G891A Build/NRD90M                     12
Pixel XL Build/OPM1.171019.011                    12
Nexus                                             12
Moto Z2 Play Build/NPSS26.118-19-6                12
VS987 Build/NRD90U                                12
CHC-U03 Build/HuaweiCHC-U03                       12
LG-D680 Build/KOT49I                              12
SM-N910V Build/MMB29M                             12
LG-H840 Build/NRD90U                              12
LG-H870 Build/NRD90U                              12
Moto G Play Build/MPIS24.241-15.3-26              11
Android 5.1                                       11
HTC Desire 10 lifestyle Build/MMB29M              11
Moto G (5) Build/NPPS25.137-15-11                 11
Moto G (5) Build/NPP25.137-72                     11
SAMSUNG SM-G930P Build/NRD90M                     11
LG-K530 Build/MMB29M                              11
SM-T377V Build/NMF26X                             11
Pixel                                             11
GT-S7580L Build/JDQ39                             11
ZTE Blade L5 Build/LMY47I                         10
SM-P350 Build/MMB29M                              10
Pixel Build/OPR3.170623.013                       10
Pixel Build/OPM1.171019.011                       10
HUAWEI RIO-L03 Build/HUAWEIRIO-L03                10
Moto                                              10
GT-I9060M Build/KTU84P                            10
M4 SS4453 Build/MMB29M                            10
Moto E (4) Plus Build/NMA26.42-69                 10
Moto Z (2                                         10
Moto E (4) Build/NMA26.42-19                      10
LG-X180g Build/LMY47I                             10
BLADE V8 SE Build/NRD90M                          10
SM-T550 Build/NMF26X                              10
NOKIA                                             10
Z835 Build/NMF26V                                 10
F5121 Build/34.3.A.0.238                          10
Hisense F23 Build/NRD90M                          10
8050G Build/LMY47I                                10
EVA-L09 Build/HUAWEIEVA-L09                        9
HUAWEI VNS-L23 Build/HUAWEIVNS-L23                 9
LG-X240 Build/MRA58K                               9
LG-K200 Build/MXB48T                               9
SAMSUNG SM-G930F Build/NRD90M                      9
SM-T530NU Build/LRX22G                             9
SM-G530H Build/LRX22G                              9
VS995 Build/NRD90M                                 9
XT1254 Build/MCG24.251-5-5                         9
MotoG3 Build/MPIS24.65-33.1-2-16                   9
SAMSUNG SM-G935A Build/NRD90M                      9
Hisense L675 Build/MRA58K                          9
HUAWEI VNS-L53 Build/HUAWEIVNS-L53                 9
LGLS676 Build/MXB48T                               9
5025G Build/LMY47I                                 9
Pixel 2 Build/OPM1.171019.011                      8
Y635-L03 Build/HuaweiY635-L03                      8
SM-A520F Build/NRD90M                              8
SM-J500M Build/LMY48B                              8
MotoE2(4G-LTE                                      8
LGLS775 Build/NRD90U                               8
XT1030 Build/SU6-7.7                               8
SAMSUNG-SGH-I337 Build/KOT49H                      8
SM-T710 Build/NRD90M                               8
Pixel 2 XL Build/OPM1.171019.011                   8
M4 SS4451 Build/LMY47D                             8
SM-G900P Build/MMB29M                              8
LG-M700 Build/NMF26X                               8
F3113 Build/33.3.A.1.97                            8
LG-X220 Build/LMY47I                               8
LG-X230 Build/MRA58K                               8
SAMSUNG SM-G530H Build/LRX22G                      8
SM-A500M Build/KTU84P                              8
SM-A510M Build/NRD90M                              8
SAMSUNG SM-G532M Build/MMB29T                      8
SM-G925T Build/NRD90M                              8
SM-G900M Build/LRX21T                              8
5080A Build/MRA58K                                 8
Ilium LT510 Build/MRA58K                           8
Blade L5 Build/LMY47I                              7
LG-H650 Build/MRA58K                               7
rv:47.0                                            7
SM-T350 Build/NMF26X                               7
SM-G950U1 Build/NRD90M                             7
Moto C Build/NRD90M.063                            7
SM-G900T Build/MMB29M                              7
5010G Build/MRA58K                                 7
SM-J111M Build/LMY47V                              7
XT1563 Build/MPD24.107-52                          7
HUAWEI Y625-U13 Build/HUAWEIY625-U13               7
KFTHWI Build/KTU84M                                7
Ilium L1120 Build/NRD90M                           7
SM-A320Y Build/NRD90M                              7
KFAUWI Build/LVY48F                                7
LG-M250 Build/NRD90U                               7
XT1032 Build/LPBS23.13-56-2                        7
SM-J327P Build/MMB29M                              7
SM-J120H Build/LMY47V                              7
QTASUN1 Build/NRD90M                               7
SM-G550T1 Build/MMB29K                             7
rv:49.0                                            7
SM-T580 Build/NRD90M                               6
LG-TP260 Build/NRD90U                              6
SM-G920V Build/MMB29K                              6
HTC Desire 650 Build/MMB29M                        6
Microsoft                                          6
SM-G925I Build/NRD90M                              6
SM-T350 Build/MMB29M                               6
LGMS550 Build/NRD90U                               6
XT1563 Build/MPDS24.107-52-5                       6
LGMS210 Build/NRD90U                               6
SAMSUNG-SM-G900A Build/LRX21T                      6
SAMSUNG SM-G531H Build/LMY48B                      6
KFAPWI Build/KTU84M                                6
SAMSUNG-SM-G900A Build/MMB29M                      6
Lenovo A2016b30 Build/MRA58K                       6
es-us                                              6
SAMSUNG SM-G850F/G850FXXS2CQD9 Build/LRX22G        6
HTC                                                6
rv:58.0                                            6
SAMSUNG SM-J327T Build/NRD90M                      6
SAMSUNG SM-N950U1 Build/NMF26X                     6
SM-J500M Build/MMB29M                              6
SM-J727U Build/NRD90M                              6
SAMSUNG SM-G950F Build/NRD90M                      6
rv:38.0                                            6
Ilium X710 Build/MRA58K                            6
TRT-L53 Build/HUAWEITRT-L53                        6
KFDOWI Build/LVY48F                                6
Moto C Plus Build/NRD90M.05.022                    6
Moto G (5) Build/NPP25.137-38                      6
Studio                                             5
5049W Build/NRD90M                                 5
SAMSUNG SM-N920A Build/NRD90M                      5
Moto Z2 Play Build/NPS26.74-16-1                   5
Blade V6 Build/LRX22G                              5
SAMSUNG SM-G925T Build/NRD90M                      5
SM-N910T Build/MMB29M                              5
SM-G928G Build/NRD90M                              5
LG-H542 Build/MRA58K                               5
KFASWI Build/LVY48F                                5
K88 Build/MMB29M                                   5
LG-H820 Build/NRD90U                               5
Windows NT 6.2                                     5
SAMSUNG SM-G935T Build/NRD90M                      5
SM-G800F Build/KOT49H                              5
SAMSUNG-SM-G870A Build/MMB29M                      5
SAMSUNG SM-G892A Build/NRD90M                      5
SM-G928V Build/NRD90M                              5
LG-H872 Build/NRD90U                               5
SAMSUNG SM-G890A Build/NRD90M                      5
XT1710-02 Build/NDSS26.118-23-15                   5
SAMSUNG SM-N950F Build/NMF26X                      5
Blade V6 Max Build/MRA58K                          5
Lenovo                                             5
LG-K540 Build/MMB29M                               5
ONEPLUS A5000 Build/NMF26X                         5
SAMSUNG SM-N920P Build/NRD90M                      5
Redmi                                              5
SM-G550T Build/MMB29K                              5
SAMSUNG SM-G891A Build/NRD90M                      5
SAMSUNG-SM-G920A Build/NRD90M                      5
Android 5.1.1                                      5
LG-H840 Build/MMB29M                               5
VS425PP Build/LMY47V                               5
MOT-A6020l37 Build/LMY47V                          5
LGMP450 Build/NRD90U                               5
SM-G920T Build/NRD90M                              5
rv:55.0                                            5
ZTE A2017U Build/NRD90M                            5
Aquaris                                            5
Lenovo K33b36 Build/MMB29M                         5
SM-T813 Build/NRD90M                               5
D5306 Build/19.4.A.0.182                           5
SM-J701M Build/NRD90M                              5
SM-N950F Build/NMF26X                              5
HTC One M9 Build/NRD90M                            4
HTC One_M8 Build/MRA58K                            4
SM-G925V Build/NRD90M                              4
HUAWEI                                             4
QTAIR7 Build/LMY47D                                4
KFSUWI Build/LVY48F                                4
SAMSUNG SM-G920F Build/NRD90M                      4
SAMSUNG SM-G950U1 Build/NRD90M                     4
LG-H420 Build/LRX21Y                               4
LG-H910 Build/NRD90M                               4
XT1650                                             4
D6603 Build/23.5.A.1.291                           4
LG-H918 Build/NRD90M                               4
Moto G (5) Plus Build/NPN25.137-83                 4
SM-T817V Build/NRD90M                              4
F5121 Build/34.3.A.0.252                           4
SM-E500M Build/KTU84P                              4
rv:35.0                                            4
VS501 Build/NRD90U                                 4
SM-N900W8 Build/LRX21V                             4
LG-M320 Build/NRD90U                               4
SAMSUNG-SM-G890A Build/NRD90M                      4
LG-K220 Build/MXB48T                               4
Lenovo-A6020l36 Build/LMY47V                       4
KFTBWI Build/LVY48F                                4
SM-J700T Build/NMF26X                              4
HUAWEI Y560-L03 Build/HUAWEIY560-L03               4
MHA-L09 Build/HUAWEIMHA-L09                        4
SAMSUNG SM-J700T Build/NMF26X                      4
SM-J730GM Build/NRD90M                             4
KFTT Build/IML74K                                  4
SM-J730G Build/NRD90M                              4
M4 SS4456 Build/LMY47V                             4
SM-T230NU Build/KOT49H                             4
BAC-L03 Build/HUAWEIBAC-L03                        4
HUAWEI VNS-L31 Build/HUAWEIVNS-L31                 4
SAMSUNG SM-T810 Build/NRD90M                       4
5011A Build/NRD90M                                 4
en-us                                              4
Moto G (4) Build/NPJ25.93-14.7                     4
Z983 Build/NMF26F                                  4
F3313 Build/37.0.A.2.108                           4
SM-J727V Build/NRD90M                              4
LG-H871                                            4
SAMSUNG SM-G610M Build/MMB29K                      4
BLN-L24 Build/HONORBLN-L24                         3
SM-G360V Build/LMY48B                              3
SAMSUNG SM-J327P Build/MMB29M                      3
SM-T230 Build/KOT49H                               3
BLADE V8 Build/NRD90M                              3
hi6210sft Build/MRA58K                             3
SAMSUNG SM-G900A Build/MMB29M                      3
LG-H901                                            3
SAMSUNG-SM-G900A Build/LMY47X                      3
SAMSUNG SM-G550T1 Build/MMB29K                     3
E6810 Build/5.320VZ.03.r                           3
SM-J105B Build/LMY47V                              3
SAMSUNG-SM-G925A Build/NRD90M                      3
Z798BL Build/MMB29M                                3
SM-T560NU Build/NMF26X                             3
E6553                                              3
5054S Build/LMY47V                                 3
TREKKER-M1                                         3
SM-N900T Build/LRX21V                              3
LG-V521                                            3
Hisense U963 Build/MRA58K                          3
LG-K530 Build/NRD90U                               3
Le X520 Build/IEXCNFN5902303111S                   3
GT-P5210 Build/KOT49H                              3
ONE A2005 Build/MMB29M                             3
SAMSUNG SM-A510M Build/NRD90M                      3
SAMSUNG-SM-N900A                                   3
LG-H830 Build/NRD90U                               3
HUAWEI Y520-U03 Build/HUAWEIY520-U03               3
HTC One Build/LRX22G                               3
SGH-I337M Build/LRX22C                             3
rv:53.0                                            3
XT1528                                             3
SM-A310M Build/LMY47X                              3
LG-LS997 Build/NRD90M                              3
rv:39.0                                            3
GT-I9500                                           3
2PS64 Build/NRD90M                                 3
SAMSUNG SM-G935P Build/NRD90M                      3
SAMSUNG SM-A300H Build/LRX22G                      3
SAMSUNG-SM-J320A Build/MMB29K                      3
SM-T713 Build/NRD90M                               3
SM-N910C Build/MMB29K                              3
SM-P900                                            3
rv:44.0                                            3
rv:50.0                                            3
SM-G920T1                                          3
SM-T820 Build/NRD90M                               3
XT1033                                             3
SM-T827V Build/NRD90M                              3
SAMSUNG SM-G920T Build/NRD90M                      3
ZTE-Z835                                           3
LG-K550 Build/NRD90U                               3
TA-1039 Build/NMF26F                               3
Moto G (5S                                         3
SAMSUNG SM-G920A Build/NRD90M                      3
SM-G530T                                           3
Ilium LT500 Build/LMY47O                           3
AX920                                              3
LG-H320 Build/LRX21Y                               3
SM-G935F Build/MMB29K                              3
LG-K371                                            3
Touch                                              3
SM-S903VL                                          3
SM-J327V Build/NRD90M                              3
Hisense F20 Build/MMB29M                           3
SAMSUNG SM-T580 Build/NRD90M                       3
Blade V580 Build/LMY47D                            3
LGLS991                                            3
M4 SS4450 Build/MRA58K                             3
XT1565                                             3
QTAQZ3 Build/LMY47V                                3
SAMSUNG-SM-N920A Build/NRD90M                      3
SM-T113NU Build/KTU84P                             3
5012G Build/MRA58K                                 3
SAMSUNG SM-N910A Build/MMB29M                      3
E5606 Build/30.2.A.1.21                            3
LG-D331 Build/LRX22G                               3
Ilium L910 Build/MRA58K                            3
Nexus 6P Build/OPR5.170623.011                     3
F5321                                              3
VS835                                              3
SAMSUNG SM-G930T Build/NRD90M                      3
SM-G920P Build/NRD90M                              3
KFJWI                                              3
Redmi 4A Build/MMB29M                              3
SAMSUNG-SM-J327A Build/NRD90M                      3
SM-P550 Build/MMB29M                               3
SAMSUNG SM-J730GM Build/NRD90M                     3
SM-G930U Build/NRD90M                              3
F3113 Build/33.2.A.4.70                            3
TA-1039 Build/N2G47H                               3
Redmi Note 4 Build/MMB29M                          3
SM-T520                                            3
E2306 Build/26.1.A.3.111                           2
SAMSUNG SM-N920T Build/NRD90M                      2
Blade A510 Build/MRA58K                            2
LGL62VL                                            2
BBB100-3                                           2
LG-K428 Build/MMB29M                               2
REX                                                2
VS996                                              2
E6853                                              2
LGMS631 Build/MRA58K                               2
SAMSUNG SM-G925P Build/NRD90M                      2
SAMSUNG SM-G570M Build/MMB29K                      2
XT1040                                             2
P4526A Build/NRD90M                                2
SAMSUNG-SM-G890A Build/MMB29K                      2
SM-G900F Build/MMB29M                              2
GT-P5113                                           2
Edison                                             2
HTC 10 Build/NRD90M                                2
LG-V410                                            2
SM-J727T Build/NRD90M                              2
SM-S920L                                           2
ATT-IE11                                           2
SM-J700T1 Build/NMF26X                             2
SM-G950W                                           2
SM-J100VPP Build/LMY48B                            2
SAMSUNG SM-J701M Build/NRD90M                      2
SM-G900I                                           2
rv:46.0                                            2
SM-J200M Build/LMY47X                              2
Alcatel_4060A                                      2
LGMS550 Build/MXB48T                               2
MotoG3 Build/MPI24.65-33.1-2                       2
H1711 Build/HUAWEIH1711                            2
Build/OPR6.170623.013                              2
Z982 Build/NMF26V                                  2
SM-A710M Build/LMY47X                              2
Moto E (4) Build/NDQS26.69-23-2-3                  2
XT1575                                             2
SM-A500FU Build/MMB29M                             2
Mi A1 Build/N2G47H                                 2
LG-M322                                            2
MotoG3 Build/MPIS24.65-25.1-19                     2
SM-T800 Build/MMB29K                               2
SM-J100MU                                          2
SM-G900H Build/MMB29K                              2
SM-G930VL Build/NRD90M                             2
SM-G920I Build/NRD90M                              2
SM-G355M Build/KOT49H                              2
BLU                                                2
SH-04F                                             2
Android 7.0                                        2
MAMI                                               2
XT1635-01                                          2
SGH-I317M                                          2
M4 SS4457 Build/MRA58K                             2
VFD                                                2
LG-H443/H44312g                                    2
Lenovo TB2-X30F Build/LenovoTB2-X30F               2
2PYB2                                              2
SM-N950U1 Build/NMF26X                             2
KYOCERA-C6742A Build/LMY47V                        2
LG-K430 Build/MRA58K                               2
G8141 Build/47.1.A.5.51                            2
Z956 Build/MMB29M                                  2
BLU LIFE XL Build/L050U                            2
2PZC5                                              2
orbis                                              2
LGL58VL                                            2
LG-M400 Build/NRD90U                               2
SAMSUNG SM-N900T Build/LRX21V                      2
LG-D850                                            2
Nexus 6P Build/OPR5.170623.014                     2
HUAWEI NXT-L09 Build/HUAWEINXT-L09                 2
Lenovo TB-X103F Build/LenovoTB-X103F               2
5056A Build/MMB29M                                 2
D6708                                              2
LG-H900/H90022b                                    2
ONE TOUCH 4033A Build/JDQ39                        2
SM-G925I Build/LMY47X                              2
WOW64                                              2
SAMSUNG SM-J327T1 Build/NRD90M                     2
SM-A710M                                           2
Redmi Note 4 Build/NRD90M                          2
LG-K373                                            2
SM-J320FN Build/LMY47V                             2
moto x4 Build/NPW26.83-18-2-0-4                    2
HTC6545LVW                                         2
E5803 Build/32.4.A.1.54                            2
SM-J327T1 Build/NRD90M                             2
SAMSUNG SM-S727VL Build/MMB29M                     2
ONE TOUCH 4016A Build/JDQ39                        2
BLADE A520 Build/NRD90M                            2
FP2                                                2
m3                                                 2
G3313 Build/43.0.A.5.79                            2
SM-G955U1 Build/NRD90M                             2
7055A Build/KVT49L                                 2
Blade L2 Plus Build/KOT49H                         2
SAMSUNG SM-G925F Build/NRD90M                      2
SM-G925W8                                          2
MotoG3-TE Build/MPDS24.65-33-1-30                  2
SM-T700 Build/MMB29K                               2
SM-G920W8                                          2
LG-H810                                            2
Android 4.4.2                                      2
SM-A310M                                           2
ILIUM                                              2
Z971                                               2
XT1580                                             2
SM-A510F Build/NRD90M                              2
LG-P714                                            2
Linux i686                                         2
F8331                                              2
SM-T280 Build/LMY47V                               2
Moto E (4) Build/NMA26.42-11-3                     2
GT-I8190L Build/JZO54K                             2
es-mx                                              2
Fractal                                            2
Redmi 4X Build/N2G47H                              2
rv:42.0                                            2
SM-T550                                            2
HUAWEI VNS-L21 Build/HUAWEIVNS-L21                 2
SM-N920P Build/NRD90M                              2
SAMSUNG-SM-T337A Build/LMY47X                      2
LG-H811 Build/MRA58K                               2
LG-LS998                                           2
E5506 Build/29.1.A.0.101                           2
ZEIA8                                              2
SM-G360T1 Build/LMY47X                             2
STV100-2 Build/MMB29M                              2
5054N                                              2
SM-J320V Build/MMB29M                              2
LG-M210 Build/NRD90U                               2
SM-J510FN                                          2
HTC Desire 510 Build/KOT49H                        2
SM-J320V Build/NMF26X                              2
SM-T560NU Build/MMB29M                             2
SAMSUNG SM-J727T1 Build/NRD90M                     2
SAMSUNG SM-A520F Build/NRD90M                      2
XT1032 Build/KXB21.14-L1.40                        2
VS820                                              2
SAMSUNG SM-N920V Build/NRD90M                      2
XT1080 Build/SU6-7.7                               2
SM-P600 Build/LMY47X                               2
Moto Z2 Play Build/NPS26.118-19                    2
LG-H542 Build/LRX22G                               2
SM-G610F                                           2
SM-G900F Build/LRX21T                              2
LGLS770                                            2
D5803 Build/23.5.A.1.291                           2
SAMSUNG SM-T530NU Build/LRX22G                     2
Lenovo K33b36 Build/NRD90N                         2
SM-G930R4 Build/NRD90M                             2
XT1064 Build/MPB24.65-34-3                         2
SM-G930V Build/MMB29M                              1
SM-A510M Build/MMB29K                              1
SM-G900W8                                          1
LG-V496                                            1
SCH-I535                                           1
LG-K450 Build/MXB48T                               1
LG-H540                                            1
Turbo C5 Build/LMY47I                              1
HTC One A9s Build/MRA58K                           1
E5506 Build/29.2.A.0.166                           1
LG-D855                                            1
Z963VL                                             1
rv:41.0                                            1
5010S Build/MRA58K                                 1
SM-J730F                                           1
GT-P5210 Build/JDQ39                               1
PRA-LX1 Build/HUAWEIPRA-LX1                        1
SM-S906L                                           1
MotoE2 Build/LPCS23.13-56-5                        1
VS500                                              1
SM-G935T                                           1
SM-N9005 Build/LRX21V                              1
MALC                                               1
V.40R                                              1
SM-G360M                                           1
AX820 Build/MRA58K                                 1
SM-G925F Build/NRD90M                              1
SM-G360V                                           1
GT-I9300                                           1
NXA116QC164                                        1
ALCATEL                                            1
QMV7A                                              1
ME173X                                             1
SAMSUNG SM-A720F Build/NRD90M                      1
SM-A320Y                                           1
SM-J327VPP Build/NRD90M                            1
STV100-3                                           1
G3313                                              1
PSPC550 Build/LMY47D                               1
HTC U11 Build/NMF26X                               1
SM-J500FN                                          1
SM-G928V Build/MMB29K                              1
M4                                                 1
ASUS_Z00ED                                         1
RCT6303W87M7 Build/MRA58K                          1
E2306 Build/26.3.A.1.33                            1
SAMSUNG SM-G900T Build/MMB29M                      1
SM-J727T1 Build/NRD90M                             1
S.N.O.W.4                                          1
VS880PP                                            1
Android                                            1
Moto G (4) Build/NPJS25.93-14-8                    1
SM-A310F Build/MMB29K                              1
SM-G935V                                           1
SM-T310 Build/KOT49H                               1
SAMSUNG SM-J327A Build/NRD90M                      1
Venue                                              1
Nexus 5 Build/M4B30Z                               1
BLADE L7 Build/MRA58K                              1
TREKKER-X3 Build/MMB29M                            1
SAMSUNG-SM-T677A                                   1
Moto E (4) Plus Build/NMA26.42-11-3                1
SM-G930T1                                          1
SM-G900R4                                          1
XT1094                                             1
G3223 Build/42.0.A.4.101                           1
SM-N920A Build/MMB29K                              1
LGL52VL Build/LMY47V                               1
XT1063 Build/MPB24.65-34-3                         1
H1611                                              1
SGH-M919N                                          1
Z970                                               1
LG-H810/H81022f                                    1
NX785QC8G                                          1
A621R                                              1
SM-S550TL                                          1
SM-P550 Build/NMF26X                               1
SM-N920R4                                          1
KFSOWI                                             1
verykoolS5525                                      1
SM-G928F                                           1
LG-M255                                            1
LG-LK460                                           1
P5026A                                             1
ASUS                                               1
SAMSUNG-SM-G530AZ Build/LMY48B                     1
Lenovo TAB 2 A7-30GC Build/KOT49H                  1
SAMSUNG SM-G928G Build/NRD90M                      1
rv:37.0                                            1
SM-P605V                                           1
XT1063 Build/MPB24.65-34                           1
SAMSUNG SM-J710MN Build/MMB29K                     1
GT-N7100                                           1
BLADE A602 Build/MRA58K                            1
Moto C Build/NRD90M.046                            1
SAMSUNG SM-J530GM Build/NRD90M                     1
SM-A720F Build/NRD90M                              1
D6503                                              1
XT1003                                             1
Z833                                               1
SM-G610M Build/NRD90M                              1
HTC One A9 Build/NRD90M                            1
LGLS665 Build/LMY47V                               1
LG-D331                                            1
SAMSUNG-SM-T817A                                   1
XT1053 Build/LPAS23.12-21.7-1                      1
SM-J327T Build/NRD90M                              1
MotoG3 Build/MPI24.65-25                           1
HTC6535LVW                                         1
ZTE BLADE A321 Build/NMF26F                        1
Z959 Build/LMY47V                                  1
LT22i Build/6.2.A.1.100                            1
ATT                                                1
SM-T113 Build/KTU84P                               1
Vivo                                               1
Coolpad                                            1
LGMS330 Build/LMY47V                               1
Blade A460 Build/LMY47O                            1
K88                                                1
5057M                                              1
BLA-L29 Build/HUAWEIBLA-L29                        1
moto                                               1
VS880                                              1
SAMSUNG SM-G955F Build/NRD90M                      1
LG-X165g Build/LRX21M                              1
SLAY                                               1
QwestIE8                                           1
SAMSUNG SM-G925I Build/NRD90M                      1
XT1096                                             1
FRD-L14 Build/HUAWEIFRD-L14                        1
HTC6525LVW                                         1
XT1058                                             1
Moto G (5) Plus Build/NPN25.137-82                 1
9003A Build/MRA58K                                 1
SAMSUNG SM-P580 Build/NRD90M                       1
LGL33L/V100                                        1
SM-J727VPP Build/NRD90M                            1
SAMSUNG-SM-G870A                                   1
SM-S907VL                                          1
LG-H345                                            1
SCH-I545 Build/LRX22C                              1
SAMSUNG SM-J111M Build/LMY47V                      1
SM-A500M Build/LRX22G                              1
Lenovo PB1-750M Build/S100                         1
S57 Build/KTU84P                                   1
LG-M327 Build/NRD90U                               1
ALE-L21 Build/HuaweiALE-L21                        1
Android 6.0.1                                      1
LG-V930                                            1
G3123 Build/40.0.A.6.135                           1
SM-G935W8                                          1
Moto E (4) Build/NCQ26.69-56                       1
XT1055                                             1
SM-P580 Build/NRD90M                               1
LG-LS777 Build/NRD90U                              1
LG-K240 Build/MXB48T                               1
SAMSUNG-SM-J727A Build/NRD90M                      1
LG-D693n Build/KOT49I.V10a                         1
VerykoolS5030                                      1
SM-J320P Build/LMY47X                              1
LGLS751                                            1
XT1063                                             1
F8331 Build/41.2.A.7.76                            1
SM-A520F Build/MMB29K                              1
SM-A500H                                           1
SM-T377V                                           1
SAMSUNG-SM-G930A                                   1
KFMEWI                                             1
XT1058 Build/LPAS23.12-21.7-1                      1
hp2015                                             1
2PQ93                                              1
SM-S320VL                                          1
Z410                                               1
SM-T377P Build/NMF26X                              1
Le                                                 1
SM-S120VL                                          1
LG-M150                                            1
BNTV400                                            1
ZTE                                                1
FRD-L04 Build/HUAWEIFRD-L04                        1
4027A Build/KOT49H                                 1
SM-N950W                                           1
MotoG3-TE                                          1
SM-N900V Build/LRX21V                              1
SKY_5.0LM                                          1
LGLS990                                            1
TOMMY2                                             1
SM-G930W8 Build/NRD90M                             1
LG-M154                                            1
BLADE V7 Build/MRA58K                              1
HELIO                                              1
SAMSUNG-SM-T377A Build/MMB29K                      1
SM-T337V                                           1
SM-T330NU Build/LMY47X                             1
SM-G920F Build/MMB29K                              1
SAMSUNG SM-J500M Build/LMY48B                      1
KFSAWI                                             1
TA-1038                                            1
Blade                                              1
SM-T807V                                           1
verykoolS5019                                      1
SM-A320FL Build/MMB29K                             1
XT1008 Build/LPBS23.13-56-2                        1
LG-D725                                            1
E6603 Build/32.4.A.1.54                            1
SAMSUNG SM-J700M Build/LMY48B                      1
SM-J320H                                           1
SM-T377W                                           1
XT1031                                             1
SM-T237P                                           1
LGUS215 Build/NRD90U                               1
SM-G930R7                                          1
SLA-L03 Build/HUAWEISLA-L03                        1
SAMSUNG SM-T587P Build/NRD90M                      1
SAMSUNG SM-G900F Build/MMB29M                      1
Z837VL                                             1
SM-N900T                                           1
Hisense L675 PRO Build/NRD90M                      1
LG-TP450 Build/NRD90U                              1
Moto G (4) Build/NPJ25.93-14                       1
LT30p                                              1
LG-LS993 Build/NRD90U                              1
Lenovo TB-7703X Build/S100                         1
SAMSUNG SM-T710 Build/NRD90M                       1
LG-M153 Build/MXB48T                               1
SAMSUNG SM-G903F Build/MMB29K                      1
E6833                                              1
SAMSUNG-SM-G890A                                   1
XT1563                                             1
SM-J530GM Build/NRD90M                             1
5051A Build/MMB29M                                 1
GT-N5110                                           1
SAMSUNG SM-J320F Build/LMY47V                      1
LG-H631                                            1
LG-D855 Build/LRX21R                               1
XT1609 Build/MPIS24.241-2.35-1-17                  1
SM-N920G Build/NRD90M                              1
VS986 Build/MRA58K                                 1
X10                                                1
Ilium X510 Build/MRA58K                            1
SM-P355M Build/MMB29M                              1
SM-G530H Build/KTU84P                              1
SAMSUNG SM-G530T Build/LMY47X                      1
F3113 Build/33.2.A.3.81                            1
SM-G900P Build/LRX21T                              1
R1                                                 1
SM-N910H                                           1
XT1635-02                                          1
LenovoA3300-GV Build/JDQ39                         1
XT1060                                             1
LG-M430 Build/NRD90U                               1
REVVLPLUS                                          1
SGP521                                             1
SAMSUNG SM-G935F Build/MMB29K                      1
P00C                                               1
XT1064                                             1
LG-H810/H81021z                                    1
SM-G925P Build/NRD90M                              1
P027                                               1
SM-G928T Build/NRD90M                              1
SCH-I435                                           1
TA-1038 Build/NMF26O                               1
Redmi Note 3 Build/MMB29M                          1
moto x4 Build/NPW26.83-42                          1
G3423                                              1
BV6000                                             1
XT1032 Build/LPBS23.13-57-2                        1
LG-V495/V49520l                                    1
HUAWEI CAN-L01 Build/HUAWEICAN-L01                 1
NetHelper70                                        1
R8106                                              1
LG-H850                                            1
SM-G925I Build/MMB29K                              1
SM-G920V                                           1
SM-S820L                                           1
PH-1                                               1
HP                                                 1
MYA-L23                                            1
TA-1003                                            1
VK810                                              1
SM-G386T                                           1
A3_mini                                            1
MotoG3 Build/MPIS24.107-55-2-17                    1
LG-H990 Build/NRD90M                               1
CRO-L03 Build/HUAWEICRO-L03                        1
LG-D851                                            1
Moto C Plus Build/NRD90M.05.034                    1
SAMSUNG-SM-G928A Build/NRD90M                      1
Lenovo A6020l37 Build/LMY47V                       1
SM-G900V                                           1
SM-N920V                                           1
VS990 Build/MRA58K                                 1
SAMSUNG-SM-T537A                                   1
C2104                                              1
SM-S902L                                           1
P5526A Build/NRD90M                                1
Ilium X210 Build/LMY47I                            1
LG-D373 Build/KOT49I.V10a                          1
Z836BL                                             1
SM-T818V                                           1
SM-G530P                                           1
SM-A510M Build/LMY47X                              1
LG-K428 Build/NRD90U                               1
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 866
---------------------
[&#39;icloud.com&#39;, &#39;msn.com&#39;, &#39;outlook.com&#39;, &#39;att.net&#39;, &#39;sbcglobal.net&#39;, &#39;verizon.net&#39;, &#39;live.com&#39;, &#39;bellsouth.net&#39;, &#39;cox.net&#39;, &#39;me.com&#39;, &#39;ymail.com&#39;, &#39;yahoo.com.mx&#39;, &#39;charter.net&#39;, &#39;optonline.net&#39;, &#39;live.com.mx&#39;, &#39;mac.com&#39;, &#39;rocketmail.com&#39;, &#39;earthlink.net&#39;, &#39;mail.com&#39;, &#39;embarqmail.com&#39;, &#39;roadrunner.com&#39;, &#39;juno.com&#39;, &#39;outlook.es&#39;, &#39;gmail&#39;, &#39;twc.com&#39;, &#39;windstream.net&#39;, &#39;frontier.com&#39;, &#39;hotmail.es&#39;, &#39;frontiernet.net&#39;, &#39;netzero.com&#39;, &#39;q.com&#39;, &#39;cfl.rr.com&#39;, &#39;web.de&#39;, &#39;aim.com&#39;, &#39;prodigy.net.mx&#39;, &#39;hotmail.fr&#39;, &#39;suddenlink.net&#39;, &#39;yahoo.fr&#39;, &#39;netzero.net&#39;, &#39;cableone.net&#39;, &#39;gmx.de&#39;, &#39;centurylink.net&#39;, &#39;ptd.net&#39;, &#39;yahoo.es&#39;, &#39;yahoo.co.uk&#39;, &#39;sc.rr.com&#39;, &#39;hotmail.co.uk&#39;, &#39;protonmail.com&#39;, &#39;servicios-ta.com&#39;, &#39;yahoo.de&#39;, &#39;hotmail.de&#39;, &#39;live.fr&#39;, &#39;yahoo.co.jp&#39;, &#39;comcast.net&#39;, &#39;outlook.com&#39;, &#39;icloud.com&#39;, &#39;msn.com&#39;, &#39;yahoo.com.mx&#39;, &#39;verizon.net&#39;, &#39;sbcglobal.net&#39;, &#39;cox.net&#39;, &#39;bellsouth.net&#39;, &#39;me.com&#39;, &#39;live.com&#39;, &#39;att.net&#39;, &#39;live.com.mx&#39;, &#39;ymail.com&#39;, &#39;optonline.net&#39;, &#39;mac.com&#39;, &#39;outlook.es&#39;, &#39;hotmail.es&#39;, &#39;mail.com&#39;, &#39;charter.net&#39;, &#39;web.de&#39;, &#39;prodigy.net.mx&#39;, &#39;hotmail.fr&#39;, &#39;earthlink.net&#39;, &#39;embarqmail.com&#39;, &#39;frontier.com&#39;, &#39;juno.com&#39;, &#39;yahoo.fr&#39;, &#39;windstream.net&#39;, &#39;gmx.de&#39;, &#39;roadrunner.com&#39;, &#39;rocketmail.com&#39;, &#39;cfl.rr.com&#39;, &#39;q.com&#39;, &#39;twc.com&#39;, &#39;gmail&#39;, &#39;suddenlink.net&#39;, &#39;yahoo.es&#39;, &#39;ptd.net&#39;, &#39;yahoo.co.uk&#39;, &#39;yahoo.de&#39;, &#39;frontiernet.net&#39;, &#39;hotmail.co.uk&#39;, &#39;aim.com&#39;, &#39;servicios-ta.com&#39;, &#39;netzero.net&#39;, &#39;cableone.net&#39;, &#39;scranton.edu&#39;, &#39;centurylink.net&#39;, &#39;netzero.com&#39;, &#39;hotmail.de&#39;, &#39;live.fr&#39;, &#39;yahoo.co.jp&#39;, &#39;protonmail.com&#39;, &#39;sc.rr.com&#39;, &#39;edge 15.0&#39;, &#39;mobile safari generic&#39;, &#39;edge 16.0&#39;, &#39;chrome 61.0&#39;, &#39;chrome generic&#39;, &#39;samsung browser 6.2&#39;, &#39;mobile safari 9.0&#39;, &#39;ie 11.0 for tablet&#39;, &#39;chrome 49.0&#39;, &#39;edge 14.0&#39;, &#39;firefox&#39;, &#39;chrome 61.0 for android&#39;, &#39;chrome 60.0&#39;, &#39;firefox 52.0&#39;, &#39;chrome 60.0 for android&#39;, &#39;chrome&#39;, &#39;opera 49.0&#39;, &#39;chrome 59.0 for android&#39;, &#39;firefox 56.0&#39;, &#39;other&#39;, &#39;firefox 48.0&#39;, &#39;chrome 63.0 for ios&#39;, &#39;chrome 59.0&#39;, &#39;chrome 56.0 for android&#39;, &#39;chrome 55.0 for android&#39;, &#39;chrome 62.0 for ios&#39;, &#39;chrome 58.0&#39;, &#39;chrome 58.0 for android&#39;, &#39;android webview 4.0&#39;, &#39;mobile safari uiwebview&#39;, &#39;chrome 56.0&#39;, &#39;chrome 57.0&#39;, &#39;ie&#39;, &#39;chrome 51.0&#39;, &#39;mobile safari 8.0&#39;, &#39;edge&#39;, &#39;chrome 55.0&#39;, &#39;chrome 50.0 for android&#39;, &#39;android browser 4.0&#39;, &#39;Generic/Android 7.0&#39;, &#39;Samsung/SM-G532M&#39;, &#39;edge 13.0&#39;, &#39;chrome 57.0 for android&#39;, &#39;chrome 53.0 for android&#39;, &#39;chrome 54.0 for android&#39;, &#39;firefox generic&#39;, &#39;firefox 47.0&#39;, &#39;Generic/Android&#39;, &#39;chrome 52.0 for android&#39;, &#39;opera&#39;, &#39;samsung browser 5.4&#39;, &#39;Microsoft/Windows&#39;, &#39;silk&#39;, &#39;chrome 46.0 for android&#39;, &#39;chrome 43.0 for android&#39;, &#39;chrome 51.0 for android&#39;, &#39;Samsung/SM-G531H&#39;, &#39;firefox 55.0&#39;, &#39;chrome 49.0 for android&#39;, &#39;samsung browser 4.0&#39;, &#39;aol&#39;, &#39;waterfox&#39;, &#39;samsung&#39;, &#39;chrome generic for android&#39;, &#39;safari&#39;, &#39;mobile&#39;, &#39;Nokia/Lumia&#39;, &#39;puffin&#39;, &#39;Samsung/SCH&#39;, &#39;cyberfox&#39;, &#39;opera generic&#39;, &#39;ZTE/Blade&#39;, &#39;samsung browser 5.2&#39;, &#39;rv:11.0&#39;, &#39;rv:57.0&#39;, &#39;SM-G950U Build/NRD90M&#39;, &#39;SM-G930V Build/NRD90M&#39;, &#39;rv:52.0&#39;, &#39;SM-G955U Build/NRD90M&#39;, &#39;SM-J700M Build/MMB29K&#39;, &#39;rv:48.0&#39;, &#39;SM-N950U Build/NMF26X&#39;, &#39;rv:56.0&#39;, &#39;SAMSUNG SM-G950U Build/NRD90M&#39;, &#39;SAMSUNG&#39;, &#39;SM-G935F Build/NRD90M&#39;, &#39;SM-G531H Build/LMY48B&#39;, &#39;SM-G610M Build/MMB29K&#39;, &#39;ALE-L23 Build/HuaweiALE-L23&#39;, &#39;SM-G920V Build/NRD90M&#39;, &#39;Moto G (4) Build/NPJS25.93-14-10&#39;, &#39;SM-G935V Build/NRD90M&#39;, &#39;SM-G900V Build/MMB29M&#39;, &#39;Linux x86_64&#39;, &#39;Moto G (4) Build/NPJ25.93-14.5&#39;, &#39;SM-G950F Build/NRD90M&#39;, &#39;LG-D693n Build/LRX22G&#39;, &#39;SAMSUNG SM-G955U Build/NRD90M&#39;, &#39;SM-G532M Build/MMB29T&#39;, &#39;SAMSUNG-SM-G930A Build/NRD90M&#39;, &#39;SM-A300H Build/LRX22G&#39;, &#39;Windows NT 6.1&#39;, &#39;WAS-LX3 Build/HUAWEIWAS-LX3&#39;, &#39;MDDRJS&#39;, &#39;HUAWEI G7-L03 Build/HuaweiG7-L03&#39;, &#39;F3213 Build/36.1.A.1.86&#39;, &#39;HUAWEI TAG-L13 Build/HUAWEITAG-L13&#39;, &#39;SM-J320M Build/LMY47V&#39;, &#39;LG-H500 Build/LRX21Y&#39;, &#39;LG-K580 Build/MRA58K&#39;, &#39;SM-G935T Build/NRD90M&#39;, &#39;Moto G (5) Plus Build/NPNS25.137-15-11&#39;, &#39;rv:31.0&#39;, &#39;LG-K410 Build/LRX22G&#39;, &#39;BLL-L23 Build/HUAWEIBLL-L23&#39;, &#39;SM-G570M Build/MMB29K&#39;, &#39;HTC Desire 626s Build/LMY47O&#39;, &#39;SM-J710MN Build/MMB29K&#39;, &#39;SM-N920V Build/NRD90M&#39;, &#39;SM-J700M Build/LMY48B&#39;, &#39;SM-G955F Build/NRD90M&#39;, &#39;SAMSUNG SM-G930A Build/NRD90M&#39;, &#39;SM-G930T Build/NRD90M&#39;, &#39;PRA-LX3 Build/HUAWEIPRA-LX3&#39;, &#39;XT1585 Build/NCK25.118-10.5&#39;, &#39;SM-G930P Build/NRD90M&#39;, &#39;LGMP260 Build/NRD90U&#39;, &#39;SM-J510MN Build/MMB29M&#39;, &#39;Moto X Play Build/NPD26.48-24-1&#39;, &#39;XT1650 Build/NCLS26.118-23-13-3&#39;, &#39;SAMSUNG SM-N950U Build/NMF26X&#39;, &#39;CAM-L03 Build/HUAWEICAM-L03&#39;, &#39;Moto G Play Build/MPIS24.241-15.3-7&#39;, &#39;HTC Desire 530 Build/MMB29M&#39;, &#39;Moto E (4) Build/NMA26.42-69&#39;, &#39;rv:45.0&#39;, &#39;rv:54.0&#39;, &#39;SM-A720F Build/MMB29K&#39;, &#39;SAMSUNG SM-G920P Build/NRD90M&#39;, &#39;VS988 Build/NRD90U&#39;, &#39;XT1635-02 Build/NPN26.118-22-2&#39;, &#39;LG-X210 Build/LMY47I&#39;, &#39;Blade V6 Plus Build/MRA58K&#39;, &#39;SM-N920T Build/NRD90M&#39;, &#39;Moto G (5) Plus Build/NPN25.137-72&#39;, &#39;SM-G935P Build/NRD90M&#39;, &#39;SM-G930F Build/NRD90M&#39;, &#39;KFFOWI Build/LVY48F&#39;, &#39;SM-T560 Build/KTU84P&#39;, &#39;Moto G (5) Build/NPP25.137-82&#39;, &#39;SAMSUNG SM-G935F Build/NRD90M&#39;, &#39;F5121 Build/34.3.A.0.228&#39;, &#39;rv:51.0&#39;, &#39;SM-T810 Build/NRD90M&#39;, &#39;SAMSUNG-SM-G935A Build/NRD90M&#39;, &#39;C6743 Build/LMY47V&#39;, &#39;LG-K500 Build/MMB29M&#39;, &#39;HUAWEI CUN-L03 Build/HUAWEICUN-L03&#39;, &#39;SAMSUNG SM-J700M Build/MMB29K&#39;, &#39;KFGIWI Build/LVY48F&#39;, &#39;Z981 Build/MMB29M&#39;, &#39;XT1635-01 Build/NDNS26.118-23-12-3&#39;, &#39;SM-G920F Build/NRD90M&#39;, &#39;SAMSUNG-SM-G891A Build/NRD90M&#39;, &#39;Pixel XL Build/OPM1.171019.011&#39;, &#39;Nexus&#39;, &#39;Moto Z2 Play Build/NPSS26.118-19-6&#39;, &#39;VS987 Build/NRD90U&#39;, &#39;CHC-U03 Build/HuaweiCHC-U03&#39;, &#39;LG-D680 Build/KOT49I&#39;, &#39;SM-N910V Build/MMB29M&#39;, &#39;LG-H840 Build/NRD90U&#39;, &#39;LG-H870 Build/NRD90U&#39;, &#39;Moto G Play Build/MPIS24.241-15.3-26&#39;, &#39;Android 5.1&#39;, &#39;HTC Desire 10 lifestyle Build/MMB29M&#39;, &#39;Moto G (5) Build/NPPS25.137-15-11&#39;, &#39;Moto G (5) Build/NPP25.137-72&#39;, &#39;SAMSUNG SM-G930P Build/NRD90M&#39;, &#39;LG-K530 Build/MMB29M&#39;, &#39;SM-T377V Build/NMF26X&#39;, &#39;Pixel&#39;, &#39;GT-S7580L Build/JDQ39&#39;, &#39;ZTE Blade L5 Build/LMY47I&#39;, &#39;SM-P350 Build/MMB29M&#39;, &#39;Pixel Build/OPR3.170623.013&#39;, &#39;Pixel Build/OPM1.171019.011&#39;, &#39;HUAWEI RIO-L03 Build/HUAWEIRIO-L03&#39;, &#39;Moto&#39;, &#39;GT-I9060M Build/KTU84P&#39;, &#39;M4 SS4453 Build/MMB29M&#39;, &#39;Moto E (4) Plus Build/NMA26.42-69&#39;, &#39;Moto Z (2&#39;, &#39;Moto E (4) Build/NMA26.42-19&#39;, &#39;LG-X180g Build/LMY47I&#39;, &#39;BLADE V8 SE Build/NRD90M&#39;, &#39;SM-T550 Build/NMF26X&#39;, &#39;NOKIA&#39;, &#39;Z835 Build/NMF26V&#39;, &#39;F5121 Build/34.3.A.0.238&#39;, &#39;Hisense F23 Build/NRD90M&#39;, &#39;8050G Build/LMY47I&#39;, &#39;EVA-L09 Build/HUAWEIEVA-L09&#39;, &#39;HUAWEI VNS-L23 Build/HUAWEIVNS-L23&#39;, &#39;LG-X240 Build/MRA58K&#39;, &#39;LG-K200 Build/MXB48T&#39;, &#39;SAMSUNG SM-G930F Build/NRD90M&#39;, &#39;SM-T530NU Build/LRX22G&#39;, &#39;SM-G530H Build/LRX22G&#39;, &#39;VS995 Build/NRD90M&#39;, &#39;XT1254 Build/MCG24.251-5-5&#39;, &#39;MotoG3 Build/MPIS24.65-33.1-2-16&#39;, &#39;SAMSUNG SM-G935A Build/NRD90M&#39;, &#39;Hisense L675 Build/MRA58K&#39;, &#39;HUAWEI VNS-L53 Build/HUAWEIVNS-L53&#39;, &#39;LGLS676 Build/MXB48T&#39;, &#39;5025G Build/LMY47I&#39;, &#39;Pixel 2 Build/OPM1.171019.011&#39;, &#39;Y635-L03 Build/HuaweiY635-L03&#39;, &#39;SM-A520F Build/NRD90M&#39;, &#39;SM-J500M Build/LMY48B&#39;, &#39;MotoE2(4G-LTE&#39;, &#39;LGLS775 Build/NRD90U&#39;, &#39;XT1030 Build/SU6-7.7&#39;, &#39;SAMSUNG-SGH-I337 Build/KOT49H&#39;, &#39;SM-T710 Build/NRD90M&#39;, &#39;Pixel 2 XL Build/OPM1.171019.011&#39;, &#39;M4 SS4451 Build/LMY47D&#39;, &#39;SM-G900P Build/MMB29M&#39;, &#39;LG-M700 Build/NMF26X&#39;, &#39;F3113 Build/33.3.A.1.97&#39;, &#39;LG-X220 Build/LMY47I&#39;, &#39;LG-X230 Build/MRA58K&#39;, &#39;SAMSUNG SM-G530H Build/LRX22G&#39;, &#39;SM-A500M Build/KTU84P&#39;, &#39;SM-A510M Build/NRD90M&#39;, &#39;SAMSUNG SM-G532M Build/MMB29T&#39;, &#39;SM-G925T Build/NRD90M&#39;, &#39;SM-G900M Build/LRX21T&#39;, &#39;5080A Build/MRA58K&#39;, &#39;Ilium LT510 Build/MRA58K&#39;, &#39;Blade L5 Build/LMY47I&#39;, &#39;LG-H650 Build/MRA58K&#39;, &#39;rv:47.0&#39;, &#39;SM-T350 Build/NMF26X&#39;, &#39;SM-G950U1 Build/NRD90M&#39;, &#39;Moto C Build/NRD90M.063&#39;, &#39;SM-G900T Build/MMB29M&#39;, &#39;5010G Build/MRA58K&#39;, &#39;SM-J111M Build/LMY47V&#39;, &#39;XT1563 Build/MPD24.107-52&#39;, &#39;HUAWEI Y625-U13 Build/HUAWEIY625-U13&#39;, &#39;KFTHWI Build/KTU84M&#39;, &#39;Ilium L1120 Build/NRD90M&#39;, &#39;SM-A320Y Build/NRD90M&#39;, &#39;KFAUWI Build/LVY48F&#39;, &#39;LG-M250 Build/NRD90U&#39;, &#39;XT1032 Build/LPBS23.13-56-2&#39;, &#39;SM-J327P Build/MMB29M&#39;, &#39;SM-J120H Build/LMY47V&#39;, &#39;QTASUN1 Build/NRD90M&#39;, &#39;SM-G550T1 Build/MMB29K&#39;, &#39;rv:49.0&#39;, &#39;SM-T580 Build/NRD90M&#39;, &#39;LG-TP260 Build/NRD90U&#39;, &#39;SM-G920V Build/MMB29K&#39;, &#39;HTC Desire 650 Build/MMB29M&#39;, &#39;Microsoft&#39;, &#39;SM-G925I Build/NRD90M&#39;, &#39;SM-T350 Build/MMB29M&#39;, &#39;LGMS550 Build/NRD90U&#39;, &#39;XT1563 Build/MPDS24.107-52-5&#39;, &#39;LGMS210 Build/NRD90U&#39;, &#39;SAMSUNG-SM-G900A Build/LRX21T&#39;, &#39;SAMSUNG SM-G531H Build/LMY48B&#39;, &#39;KFAPWI Build/KTU84M&#39;, &#39;SAMSUNG-SM-G900A Build/MMB29M&#39;, &#39;Lenovo A2016b30 Build/MRA58K&#39;, &#39;es-us&#39;, &#39;SAMSUNG SM-G850F/G850FXXS2CQD9 Build/LRX22G&#39;, &#39;HTC&#39;, &#39;rv:58.0&#39;, &#39;SAMSUNG SM-J327T Build/NRD90M&#39;, &#39;SAMSUNG SM-N950U1 Build/NMF26X&#39;, &#39;SM-J500M Build/MMB29M&#39;, &#39;SM-J727U Build/NRD90M&#39;, &#39;SAMSUNG SM-G950F Build/NRD90M&#39;, &#39;rv:38.0&#39;, &#39;Ilium X710 Build/MRA58K&#39;, &#39;TRT-L53 Build/HUAWEITRT-L53&#39;, &#39;KFDOWI Build/LVY48F&#39;, &#39;Moto C Plus Build/NRD90M.05.022&#39;, &#39;Moto G (5) Build/NPP25.137-38&#39;, &#39;Studio&#39;, &#39;5049W Build/NRD90M&#39;, &#39;SAMSUNG SM-N920A Build/NRD90M&#39;, &#39;Moto Z2 Play Build/NPS26.74-16-1&#39;, &#39;Blade V6 Build/LRX22G&#39;, &#39;SAMSUNG SM-G925T Build/NRD90M&#39;, &#39;SM-N910T Build/MMB29M&#39;, &#39;SM-G928G Build/NRD90M&#39;, &#39;LG-H542 Build/MRA58K&#39;, &#39;KFASWI Build/LVY48F&#39;, &#39;K88 Build/MMB29M&#39;, &#39;LG-H820 Build/NRD90U&#39;, &#39;Windows NT 6.2&#39;, &#39;SAMSUNG SM-G935T Build/NRD90M&#39;, &#39;SM-G800F Build/KOT49H&#39;, &#39;SAMSUNG-SM-G870A Build/MMB29M&#39;, &#39;SAMSUNG SM-G892A Build/NRD90M&#39;, &#39;SM-G928V Build/NRD90M&#39;, &#39;LG-H872 Build/NRD90U&#39;, &#39;SAMSUNG SM-G890A Build/NRD90M&#39;, &#39;XT1710-02 Build/NDSS26.118-23-15&#39;, &#39;SAMSUNG SM-N950F Build/NMF26X&#39;, &#39;Blade V6 Max Build/MRA58K&#39;, &#39;Lenovo&#39;, &#39;LG-K540 Build/MMB29M&#39;, &#39;ONEPLUS A5000 Build/NMF26X&#39;, &#39;SAMSUNG SM-N920P Build/NRD90M&#39;, &#39;Redmi&#39;, &#39;SM-G550T Build/MMB29K&#39;, &#39;SAMSUNG SM-G891A Build/NRD90M&#39;, &#39;SAMSUNG-SM-G920A Build/NRD90M&#39;, &#39;Android 5.1.1&#39;, &#39;LG-H840 Build/MMB29M&#39;, &#39;VS425PP Build/LMY47V&#39;, &#39;MOT-A6020l37 Build/LMY47V&#39;, &#39;LGMP450 Build/NRD90U&#39;, &#39;SM-G920T Build/NRD90M&#39;, &#39;rv:55.0&#39;, &#39;ZTE A2017U Build/NRD90M&#39;, &#39;Aquaris&#39;, &#39;Lenovo K33b36 Build/MMB29M&#39;, &#39;SM-T813 Build/NRD90M&#39;, &#39;D5306 Build/19.4.A.0.182&#39;, &#39;SM-J701M Build/NRD90M&#39;, &#39;SM-N950F Build/NMF26X&#39;, &#39;HTC One M9 Build/NRD90M&#39;, &#39;HTC One_M8 Build/MRA58K&#39;, &#39;SM-G925V Build/NRD90M&#39;, &#39;HUAWEI&#39;, &#39;QTAIR7 Build/LMY47D&#39;, &#39;KFSUWI Build/LVY48F&#39;, &#39;SAMSUNG SM-G920F Build/NRD90M&#39;, &#39;SAMSUNG SM-G950U1 Build/NRD90M&#39;, &#39;LG-H420 Build/LRX21Y&#39;, &#39;LG-H910 Build/NRD90M&#39;, &#39;XT1650&#39;, &#39;D6603 Build/23.5.A.1.291&#39;, &#39;LG-H918 Build/NRD90M&#39;, &#39;Moto G (5) Plus Build/NPN25.137-83&#39;, &#39;SM-T817V Build/NRD90M&#39;, &#39;F5121 Build/34.3.A.0.252&#39;, &#39;SM-E500M Build/KTU84P&#39;, &#39;rv:35.0&#39;, &#39;VS501 Build/NRD90U&#39;, &#39;SM-N900W8 Build/LRX21V&#39;, &#39;LG-M320 Build/NRD90U&#39;, &#39;SAMSUNG-SM-G890A Build/NRD90M&#39;, &#39;LG-K220 Build/MXB48T&#39;, &#39;Lenovo-A6020l36 Build/LMY47V&#39;, &#39;KFTBWI Build/LVY48F&#39;, &#39;SM-J700T Build/NMF26X&#39;, &#39;HUAWEI Y560-L03 Build/HUAWEIY560-L03&#39;, &#39;MHA-L09 Build/HUAWEIMHA-L09&#39;, &#39;SAMSUNG SM-J700T Build/NMF26X&#39;, &#39;SM-J730GM Build/NRD90M&#39;, &#39;KFTT Build/IML74K&#39;, &#39;SM-J730G Build/NRD90M&#39;, &#39;M4 SS4456 Build/LMY47V&#39;, &#39;SM-T230NU Build/KOT49H&#39;, &#39;BAC-L03 Build/HUAWEIBAC-L03&#39;, &#39;HUAWEI VNS-L31 Build/HUAWEIVNS-L31&#39;, &#39;SAMSUNG SM-T810 Build/NRD90M&#39;, &#39;5011A Build/NRD90M&#39;, &#39;en-us&#39;, &#39;Moto G (4) Build/NPJ25.93-14.7&#39;, &#39;Z983 Build/NMF26F&#39;, &#39;F3313 Build/37.0.A.2.108&#39;, &#39;SM-J727V Build/NRD90M&#39;, &#39;LG-H871&#39;, &#39;SAMSUNG SM-G610M Build/MMB29K&#39;, &#39;BLN-L24 Build/HONORBLN-L24&#39;, &#39;SM-G360V Build/LMY48B&#39;, &#39;SAMSUNG SM-J327P Build/MMB29M&#39;, &#39;SM-T230 Build/KOT49H&#39;, &#39;BLADE V8 Build/NRD90M&#39;, &#39;hi6210sft Build/MRA58K&#39;, &#39;SAMSUNG SM-G900A Build/MMB29M&#39;, &#39;LG-H901&#39;, &#39;SAMSUNG-SM-G900A Build/LMY47X&#39;, &#39;SAMSUNG SM-G550T1 Build/MMB29K&#39;, &#39;E6810 Build/5.320VZ.03.r&#39;, &#39;SM-J105B Build/LMY47V&#39;, &#39;SAMSUNG-SM-G925A Build/NRD90M&#39;, &#39;Z798BL Build/MMB29M&#39;, &#39;SM-T560NU Build/NMF26X&#39;, &#39;E6553&#39;, &#39;5054S Build/LMY47V&#39;, &#39;TREKKER-M1&#39;, &#39;SM-N900T Build/LRX21V&#39;, &#39;LG-V521&#39;, &#39;Hisense U963 Build/MRA58K&#39;, &#39;LG-K530 Build/NRD90U&#39;, &#39;Le X520 Build/IEXCNFN5902303111S&#39;, &#39;GT-P5210 Build/KOT49H&#39;, &#39;ONE A2005 Build/MMB29M&#39;, &#39;SAMSUNG SM-A510M Build/NRD90M&#39;, &#39;SAMSUNG-SM-N900A&#39;, &#39;LG-H830 Build/NRD90U&#39;, &#39;HUAWEI Y520-U03 Build/HUAWEIY520-U03&#39;, &#39;HTC One Build/LRX22G&#39;, &#39;SGH-I337M Build/LRX22C&#39;, &#39;rv:53.0&#39;, &#39;XT1528&#39;, &#39;SM-A310M Build/LMY47X&#39;, &#39;LG-LS997 Build/NRD90M&#39;, &#39;rv:39.0&#39;, &#39;GT-I9500&#39;, &#39;2PS64 Build/NRD90M&#39;, &#39;SAMSUNG SM-G935P Build/NRD90M&#39;, &#39;SAMSUNG SM-A300H Build/LRX22G&#39;, &#39;SAMSUNG-SM-J320A Build/MMB29K&#39;, &#39;SM-T713 Build/NRD90M&#39;, &#39;SM-N910C Build/MMB29K&#39;, &#39;SM-P900&#39;, &#39;rv:44.0&#39;, &#39;rv:50.0&#39;, &#39;SM-G920T1&#39;, &#39;SM-T820 Build/NRD90M&#39;, &#39;XT1033&#39;, &#39;SM-T827V Build/NRD90M&#39;, &#39;SAMSUNG SM-G920T Build/NRD90M&#39;, &#39;ZTE-Z835&#39;, &#39;LG-K550 Build/NRD90U&#39;, &#39;TA-1039 Build/NMF26F&#39;, &#39;Moto G (5S&#39;, &#39;SAMSUNG SM-G920A Build/NRD90M&#39;, &#39;SM-G530T&#39;, &#39;Ilium LT500 Build/LMY47O&#39;, &#39;AX920&#39;, &#39;LG-H320 Build/LRX21Y&#39;, &#39;SM-G935F Build/MMB29K&#39;, &#39;LG-K371&#39;, &#39;Touch&#39;, &#39;SM-S903VL&#39;, &#39;SM-J327V Build/NRD90M&#39;, &#39;Hisense F20 Build/MMB29M&#39;, &#39;SAMSUNG SM-T580 Build/NRD90M&#39;, &#39;Blade V580 Build/LMY47D&#39;, &#39;LGLS991&#39;, &#39;M4 SS4450 Build/MRA58K&#39;, &#39;XT1565&#39;, &#39;QTAQZ3 Build/LMY47V&#39;, &#39;SAMSUNG-SM-N920A Build/NRD90M&#39;, &#39;SM-T113NU Build/KTU84P&#39;, &#39;5012G Build/MRA58K&#39;, &#39;SAMSUNG SM-N910A Build/MMB29M&#39;, &#39;E5606 Build/30.2.A.1.21&#39;, &#39;LG-D331 Build/LRX22G&#39;, &#39;Ilium L910 Build/MRA58K&#39;, &#39;Nexus 6P Build/OPR5.170623.011&#39;, &#39;F5321&#39;, &#39;VS835&#39;, &#39;SAMSUNG SM-G930T Build/NRD90M&#39;, &#39;SM-G920P Build/NRD90M&#39;, &#39;KFJWI&#39;, &#39;Redmi 4A Build/MMB29M&#39;, &#39;SAMSUNG-SM-J327A Build/NRD90M&#39;, &#39;SM-P550 Build/MMB29M&#39;, &#39;SAMSUNG SM-J730GM Build/NRD90M&#39;, &#39;SM-G930U Build/NRD90M&#39;, &#39;F3113 Build/33.2.A.4.70&#39;, &#39;TA-1039 Build/N2G47H&#39;, &#39;Redmi Note 4 Build/MMB29M&#39;, &#39;SM-T520&#39;, &#39;E2306 Build/26.1.A.3.111&#39;, &#39;SAMSUNG SM-N920T Build/NRD90M&#39;, &#39;Blade A510 Build/MRA58K&#39;, &#39;LGL62VL&#39;, &#39;BBB100-3&#39;, &#39;LG-K428 Build/MMB29M&#39;, &#39;REX&#39;, &#39;VS996&#39;, &#39;E6853&#39;, &#39;LGMS631 Build/MRA58K&#39;, &#39;SAMSUNG SM-G925P Build/NRD90M&#39;, &#39;SAMSUNG SM-G570M Build/MMB29K&#39;, &#39;XT1040&#39;, &#39;P4526A Build/NRD90M&#39;, &#39;SAMSUNG-SM-G890A Build/MMB29K&#39;, &#39;SM-G900F Build/MMB29M&#39;, &#39;GT-P5113&#39;, &#39;Edison&#39;, &#39;HTC 10 Build/NRD90M&#39;, &#39;LG-V410&#39;, &#39;SM-J727T Build/NRD90M&#39;, &#39;SM-S920L&#39;, &#39;ATT-IE11&#39;, &#39;SM-J700T1 Build/NMF26X&#39;, &#39;SM-G950W&#39;, &#39;SM-J100VPP Build/LMY48B&#39;, &#39;SAMSUNG SM-J701M Build/NRD90M&#39;, &#39;SM-G900I&#39;, &#39;rv:46.0&#39;, &#39;SM-J200M Build/LMY47X&#39;, &#39;Alcatel_4060A&#39;, &#39;LGMS550 Build/MXB48T&#39;, &#39;MotoG3 Build/MPI24.65-33.1-2&#39;, &#39;H1711 Build/HUAWEIH1711&#39;, &#39;Build/OPR6.170623.013&#39;, &#39;Z982 Build/NMF26V&#39;, &#39;SM-A710M Build/LMY47X&#39;, &#39;Moto E (4) Build/NDQS26.69-23-2-3&#39;, &#39;XT1575&#39;, &#39;SM-A500FU Build/MMB29M&#39;, &#39;Mi A1 Build/N2G47H&#39;, &#39;LG-M322&#39;, &#39;MotoG3 Build/MPIS24.65-25.1-19&#39;, &#39;SM-T800 Build/MMB29K&#39;, &#39;SM-J100MU&#39;, &#39;SM-G900H Build/MMB29K&#39;, &#39;SM-G930VL Build/NRD90M&#39;, &#39;SM-G920I Build/NRD90M&#39;, &#39;SM-G355M Build/KOT49H&#39;, &#39;BLU&#39;, &#39;SH-04F&#39;, &#39;Android 7.0&#39;, &#39;MAMI&#39;, &#39;XT1635-01&#39;, &#39;SGH-I317M&#39;, &#39;M4 SS4457 Build/MRA58K&#39;, &#39;VFD&#39;, &#39;LG-H443/H44312g&#39;, &#39;Lenovo TB2-X30F Build/LenovoTB2-X30F&#39;, &#39;2PYB2&#39;, &#39;SM-N950U1 Build/NMF26X&#39;, &#39;KYOCERA-C6742A Build/LMY47V&#39;, &#39;LG-K430 Build/MRA58K&#39;, &#39;G8141 Build/47.1.A.5.51&#39;, &#39;Z956 Build/MMB29M&#39;, &#39;BLU LIFE XL Build/L050U&#39;, &#39;2PZC5&#39;, &#39;orbis&#39;, &#39;LGL58VL&#39;, &#39;LG-M400 Build/NRD90U&#39;, &#39;SAMSUNG SM-N900T Build/LRX21V&#39;, &#39;LG-D850&#39;, &#39;Nexus 6P Build/OPR5.170623.014&#39;, &#39;HUAWEI NXT-L09 Build/HUAWEINXT-L09&#39;, &#39;Lenovo TB-X103F Build/LenovoTB-X103F&#39;, &#39;5056A Build/MMB29M&#39;, &#39;D6708&#39;, &#39;LG-H900/H90022b&#39;, &#39;ONE TOUCH 4033A Build/JDQ39&#39;, &#39;SM-G925I Build/LMY47X&#39;, &#39;WOW64&#39;, &#39;SAMSUNG SM-J327T1 Build/NRD90M&#39;, &#39;SM-A710M&#39;, &#39;Redmi Note 4 Build/NRD90M&#39;, &#39;LG-K373&#39;, &#39;SM-J320FN Build/LMY47V&#39;, &#39;moto x4 Build/NPW26.83-18-2-0-4&#39;, &#39;HTC6545LVW&#39;, &#39;E5803 Build/32.4.A.1.54&#39;, &#39;SM-J327T1 Build/NRD90M&#39;, &#39;SAMSUNG SM-S727VL Build/MMB29M&#39;, &#39;ONE TOUCH 4016A Build/JDQ39&#39;, &#39;BLADE A520 Build/NRD90M&#39;, &#39;FP2&#39;, &#39;m3&#39;, &#39;G3313 Build/43.0.A.5.79&#39;, &#39;SM-G955U1 Build/NRD90M&#39;, &#39;7055A Build/KVT49L&#39;, &#39;Blade L2 Plus Build/KOT49H&#39;, &#39;SAMSUNG SM-G925F Build/NRD90M&#39;, &#39;SM-G925W8&#39;, &#39;MotoG3-TE Build/MPDS24.65-33-1-30&#39;, &#39;SM-T700 Build/MMB29K&#39;, &#39;SM-G920W8&#39;, &#39;LG-H810&#39;, &#39;Android 4.4.2&#39;, &#39;SM-A310M&#39;, &#39;ILIUM&#39;, &#39;Z971&#39;, &#39;XT1580&#39;, &#39;SM-A510F Build/NRD90M&#39;, &#39;LG-P714&#39;, &#39;Linux i686&#39;, &#39;F8331&#39;, &#39;SM-T280 Build/LMY47V&#39;, &#39;Moto E (4) Build/NMA26.42-11-3&#39;, &#39;GT-I8190L Build/JZO54K&#39;, &#39;es-mx&#39;, &#39;Fractal&#39;, &#39;Redmi 4X Build/N2G47H&#39;, &#39;rv:42.0&#39;, &#39;SM-T550&#39;, &#39;HUAWEI VNS-L21 Build/HUAWEIVNS-L21&#39;, &#39;SM-N920P Build/NRD90M&#39;, &#39;SAMSUNG-SM-T337A Build/LMY47X&#39;, &#39;LG-H811 Build/MRA58K&#39;, &#39;LG-LS998&#39;, &#39;E5506 Build/29.1.A.0.101&#39;, &#39;ZEIA8&#39;, &#39;SM-G360T1 Build/LMY47X&#39;, &#39;STV100-2 Build/MMB29M&#39;, &#39;5054N&#39;, &#39;SM-J320V Build/MMB29M&#39;, &#39;LG-M210 Build/NRD90U&#39;, &#39;SM-J510FN&#39;, &#39;HTC Desire 510 Build/KOT49H&#39;, &#39;SM-J320V Build/NMF26X&#39;, &#39;SM-T560NU Build/MMB29M&#39;, &#39;SAMSUNG SM-J727T1 Build/NRD90M&#39;, &#39;SAMSUNG SM-A520F Build/NRD90M&#39;, &#39;XT1032 Build/KXB21.14-L1.40&#39;, &#39;VS820&#39;, &#39;SAMSUNG SM-N920V Build/NRD90M&#39;, &#39;XT1080 Build/SU6-7.7&#39;, &#39;SM-P600 Build/LMY47X&#39;, &#39;Moto Z2 Play Build/NPS26.118-19&#39;, &#39;LG-H542 Build/LRX22G&#39;, &#39;SM-G610F&#39;, &#39;SM-G900F Build/LRX21T&#39;, &#39;LGLS770&#39;, &#39;D5803 Build/23.5.A.1.291&#39;, &#39;SAMSUNG SM-T530NU Build/LRX22G&#39;, &#39;Lenovo K33b36 Build/NRD90N&#39;, &#39;SM-G930R4 Build/NRD90M&#39;, &#39;XT1064 Build/MPB24.65-34-3&#39;, &#39;SM-G930V Build/MMB29M&#39;, &#39;SM-A510M Build/MMB29K&#39;, &#39;SM-G900W8&#39;, &#39;LG-V496&#39;, &#39;SCH-I535&#39;, &#39;LG-K450 Build/MXB48T&#39;, &#39;LG-H540&#39;, &#39;Turbo C5 Build/LMY47I&#39;, &#39;HTC One A9s Build/MRA58K&#39;, &#39;E5506 Build/29.2.A.0.166&#39;, &#39;LG-D855&#39;, &#39;Z963VL&#39;, &#39;rv:41.0&#39;, &#39;5010S Build/MRA58K&#39;, &#39;SM-J730F&#39;, &#39;GT-P5210 Build/JDQ39&#39;, &#39;PRA-LX1 Build/HUAWEIPRA-LX1&#39;, &#39;SM-S906L&#39;, &#39;MotoE2 Build/LPCS23.13-56-5&#39;, &#39;VS500&#39;, &#39;SM-G935T&#39;, &#39;SM-N9005 Build/LRX21V&#39;, &#39;MALC&#39;, &#39;V.40R&#39;, &#39;SM-G360M&#39;, &#39;AX820 Build/MRA58K&#39;, &#39;SM-G925F Build/NRD90M&#39;, &#39;SM-G360V&#39;, &#39;GT-I9300&#39;, &#39;NXA116QC164&#39;, &#39;ALCATEL&#39;, &#39;QMV7A&#39;, &#39;ME173X&#39;, &#39;SAMSUNG SM-A720F Build/NRD90M&#39;, &#39;SM-A320Y&#39;, &#39;SM-J327VPP Build/NRD90M&#39;, &#39;STV100-3&#39;, &#39;G3313&#39;, &#39;PSPC550 Build/LMY47D&#39;, &#39;HTC U11 Build/NMF26X&#39;, &#39;SM-J500FN&#39;, &#39;SM-G928V Build/MMB29K&#39;, &#39;M4&#39;, &#39;ASUS_Z00ED&#39;, &#39;RCT6303W87M7 Build/MRA58K&#39;, &#39;E2306 Build/26.3.A.1.33&#39;, &#39;SAMSUNG SM-G900T Build/MMB29M&#39;, &#39;SM-J727T1 Build/NRD90M&#39;, &#39;S.N.O.W.4&#39;, &#39;VS880PP&#39;, &#39;Android&#39;, &#39;Moto G (4) Build/NPJS25.93-14-8&#39;, &#39;SM-A310F Build/MMB29K&#39;, &#39;SM-G935V&#39;, &#39;SM-T310 Build/KOT49H&#39;, &#39;SAMSUNG SM-J327A Build/NRD90M&#39;, &#39;Venue&#39;, &#39;Nexus 5 Build/M4B30Z&#39;, &#39;BLADE L7 Build/MRA58K&#39;, &#39;TREKKER-X3 Build/MMB29M&#39;, &#39;SAMSUNG-SM-T677A&#39;, &#39;Moto E (4) Plus Build/NMA26.42-11-3&#39;, &#39;SM-G930T1&#39;, &#39;SM-G900R4&#39;, &#39;XT1094&#39;, &#39;G3223 Build/42.0.A.4.101&#39;, &#39;SM-N920A Build/MMB29K&#39;, &#39;LGL52VL Build/LMY47V&#39;, &#39;XT1063 Build/MPB24.65-34-3&#39;, &#39;H1611&#39;, &#39;SGH-M919N&#39;, &#39;Z970&#39;, &#39;LG-H810/H81022f&#39;, &#39;NX785QC8G&#39;, &#39;A621R&#39;, &#39;SM-S550TL&#39;, &#39;SM-P550 Build/NMF26X&#39;, &#39;SM-N920R4&#39;, &#39;KFSOWI&#39;, &#39;verykoolS5525&#39;, &#39;SM-G928F&#39;, &#39;LG-M255&#39;, &#39;LG-LK460&#39;, &#39;P5026A&#39;, &#39;ASUS&#39;, &#39;SAMSUNG-SM-G530AZ Build/LMY48B&#39;, &#39;Lenovo TAB 2 A7-30GC Build/KOT49H&#39;, &#39;SAMSUNG SM-G928G Build/NRD90M&#39;, &#39;rv:37.0&#39;, &#39;SM-P605V&#39;, &#39;XT1063 Build/MPB24.65-34&#39;, &#39;SAMSUNG SM-J710MN Build/MMB29K&#39;, &#39;GT-N7100&#39;, &#39;BLADE A602 Build/MRA58K&#39;, &#39;Moto C Build/NRD90M.046&#39;, &#39;SAMSUNG SM-J530GM Build/NRD90M&#39;, &#39;SM-A720F Build/NRD90M&#39;, &#39;D6503&#39;, &#39;XT1003&#39;, &#39;Z833&#39;, &#39;SM-G610M Build/NRD90M&#39;, &#39;HTC One A9 Build/NRD90M&#39;, &#39;LGLS665 Build/LMY47V&#39;, &#39;LG-D331&#39;, &#39;SAMSUNG-SM-T817A&#39;, &#39;XT1053 Build/LPAS23.12-21.7-1&#39;, &#39;SM-J327T Build/NRD90M&#39;, &#39;MotoG3 Build/MPI24.65-25&#39;, &#39;HTC6535LVW&#39;, &#39;ZTE BLADE A321 Build/NMF26F&#39;, &#39;Z959 Build/LMY47V&#39;, &#39;LT22i Build/6.2.A.1.100&#39;, &#39;ATT&#39;, &#39;SM-T113 Build/KTU84P&#39;, &#39;Vivo&#39;, &#39;Coolpad&#39;, &#39;LGMS330 Build/LMY47V&#39;, &#39;Blade A460 Build/LMY47O&#39;, &#39;K88&#39;, &#39;5057M&#39;, &#39;BLA-L29 Build/HUAWEIBLA-L29&#39;, &#39;moto&#39;, &#39;VS880&#39;, &#39;SAMSUNG SM-G955F Build/NRD90M&#39;, &#39;LG-X165g Build/LRX21M&#39;, &#39;SLAY&#39;, &#39;QwestIE8&#39;, &#39;SAMSUNG SM-G925I Build/NRD90M&#39;, &#39;XT1096&#39;, &#39;FRD-L14 Build/HUAWEIFRD-L14&#39;, &#39;HTC6525LVW&#39;, &#39;XT1058&#39;, &#39;Moto G (5) Plus Build/NPN25.137-82&#39;, &#39;9003A Build/MRA58K&#39;, &#39;SAMSUNG SM-P580 Build/NRD90M&#39;, &#39;LGL33L/V100&#39;, &#39;SM-J727VPP Build/NRD90M&#39;, &#39;SAMSUNG-SM-G870A&#39;, &#39;SM-S907VL&#39;, &#39;LG-H345&#39;, &#39;SCH-I545 Build/LRX22C&#39;, &#39;SAMSUNG SM-J111M Build/LMY47V&#39;, &#39;SM-A500M Build/LRX22G&#39;, &#39;Lenovo PB1-750M Build/S100&#39;, &#39;S57 Build/KTU84P&#39;, &#39;LG-M327 Build/NRD90U&#39;, &#39;ALE-L21 Build/HuaweiALE-L21&#39;, &#39;Android 6.0.1&#39;, &#39;LG-V930&#39;, &#39;G3123 Build/40.0.A.6.135&#39;, &#39;SM-G935W8&#39;, &#39;Moto E (4) Build/NCQ26.69-56&#39;, &#39;XT1055&#39;, &#39;SM-P580 Build/NRD90M&#39;, &#39;LG-LS777 Build/NRD90U&#39;, &#39;LG-K240 Build/MXB48T&#39;, &#39;SAMSUNG-SM-J727A Build/NRD90M&#39;, &#39;LG-D693n Build/KOT49I.V10a&#39;, &#39;VerykoolS5030&#39;, &#39;SM-J320P Build/LMY47X&#39;, &#39;LGLS751&#39;, &#39;XT1063&#39;, &#39;F8331 Build/41.2.A.7.76&#39;, &#39;SM-A520F Build/MMB29K&#39;, &#39;SM-A500H&#39;, &#39;SM-T377V&#39;, &#39;SAMSUNG-SM-G930A&#39;, &#39;KFMEWI&#39;, &#39;XT1058 Build/LPAS23.12-21.7-1&#39;, &#39;hp2015&#39;, &#39;2PQ93&#39;, &#39;SM-S320VL&#39;, &#39;Z410&#39;, &#39;SM-T377P Build/NMF26X&#39;, &#39;Le&#39;, &#39;SM-S120VL&#39;, &#39;LG-M150&#39;, &#39;BNTV400&#39;, &#39;ZTE&#39;, &#39;FRD-L04 Build/HUAWEIFRD-L04&#39;, &#39;4027A Build/KOT49H&#39;, &#39;SM-N950W&#39;, &#39;MotoG3-TE&#39;, &#39;SM-N900V Build/LRX21V&#39;, &#39;SKY_5.0LM&#39;, &#39;LGLS990&#39;, &#39;TOMMY2&#39;, &#39;SM-G930W8 Build/NRD90M&#39;, &#39;LG-M154&#39;, &#39;BLADE V7 Build/MRA58K&#39;, &#39;HELIO&#39;, &#39;SAMSUNG-SM-T377A Build/MMB29K&#39;, &#39;SM-T337V&#39;, &#39;SM-T330NU Build/LMY47X&#39;, &#39;SM-G920F Build/MMB29K&#39;, &#39;SAMSUNG SM-J500M Build/LMY48B&#39;, &#39;KFSAWI&#39;, &#39;TA-1038&#39;, &#39;Blade&#39;, &#39;SM-T807V&#39;, &#39;verykoolS5019&#39;, &#39;SM-A320FL Build/MMB29K&#39;, &#39;XT1008 Build/LPBS23.13-56-2&#39;, &#39;LG-D725&#39;, &#39;E6603 Build/32.4.A.1.54&#39;, &#39;SAMSUNG SM-J700M Build/LMY48B&#39;, &#39;SM-J320H&#39;, &#39;SM-T377W&#39;, &#39;XT1031&#39;, &#39;SM-T237P&#39;, &#39;LGUS215 Build/NRD90U&#39;, &#39;SM-G930R7&#39;, &#39;SLA-L03 Build/HUAWEISLA-L03&#39;, &#39;SAMSUNG SM-T587P Build/NRD90M&#39;, &#39;SAMSUNG SM-G900F Build/MMB29M&#39;, &#39;Z837VL&#39;, &#39;SM-N900T&#39;, &#39;Hisense L675 PRO Build/NRD90M&#39;, &#39;LG-TP450 Build/NRD90U&#39;, &#39;Moto G (4) Build/NPJ25.93-14&#39;, &#39;LT30p&#39;, &#39;LG-LS993 Build/NRD90U&#39;, &#39;Lenovo TB-7703X Build/S100&#39;, &#39;SAMSUNG SM-T710 Build/NRD90M&#39;, &#39;LG-M153 Build/MXB48T&#39;, &#39;SAMSUNG SM-G903F Build/MMB29K&#39;, &#39;E6833&#39;, &#39;SAMSUNG-SM-G890A&#39;, &#39;XT1563&#39;, &#39;SM-J530GM Build/NRD90M&#39;, &#39;5051A Build/MMB29M&#39;, &#39;GT-N5110&#39;, &#39;SAMSUNG SM-J320F Build/LMY47V&#39;, &#39;LG-H631&#39;, &#39;LG-D855 Build/LRX21R&#39;, &#39;XT1609 Build/MPIS24.241-2.35-1-17&#39;, &#39;SM-N920G Build/NRD90M&#39;, &#39;VS986 Build/MRA58K&#39;, &#39;X10&#39;, &#39;Ilium X510 Build/MRA58K&#39;, &#39;SM-P355M Build/MMB29M&#39;, &#39;SM-G530H Build/KTU84P&#39;, &#39;SAMSUNG SM-G530T Build/LMY47X&#39;, &#39;F3113 Build/33.2.A.3.81&#39;, &#39;SM-G900P Build/LRX21T&#39;, &#39;R1&#39;, &#39;SM-N910H&#39;, &#39;XT1635-02&#39;, &#39;LenovoA3300-GV Build/JDQ39&#39;, &#39;XT1060&#39;, &#39;LG-M430 Build/NRD90U&#39;, &#39;REVVLPLUS&#39;, &#39;SGP521&#39;, &#39;SAMSUNG SM-G935F Build/MMB29K&#39;, &#39;P00C&#39;, &#39;XT1064&#39;, &#39;LG-H810/H81021z&#39;, &#39;SM-G925P Build/NRD90M&#39;, &#39;P027&#39;, &#39;SM-G928T Build/NRD90M&#39;, &#39;SCH-I435&#39;, &#39;TA-1038 Build/NMF26O&#39;, &#39;Redmi Note 3 Build/MMB29M&#39;, &#39;moto x4 Build/NPW26.83-42&#39;, &#39;G3423&#39;, &#39;BV6000&#39;, &#39;XT1032 Build/LPBS23.13-57-2&#39;, &#39;LG-V495/V49520l&#39;, &#39;HUAWEI CAN-L01 Build/HUAWEICAN-L01&#39;, &#39;NetHelper70&#39;, &#39;R8106&#39;, &#39;LG-H850&#39;, &#39;SM-G925I Build/MMB29K&#39;, &#39;SM-G920V&#39;, &#39;SM-S820L&#39;, &#39;PH-1&#39;, &#39;HP&#39;, &#39;MYA-L23&#39;, &#39;TA-1003&#39;, &#39;VK810&#39;, &#39;SM-G386T&#39;, &#39;A3_mini&#39;, &#39;MotoG3 Build/MPIS24.107-55-2-17&#39;, &#39;LG-H990 Build/NRD90M&#39;, &#39;CRO-L03 Build/HUAWEICRO-L03&#39;, &#39;LG-D851&#39;, &#39;Moto C Plus Build/NRD90M.05.034&#39;, &#39;SAMSUNG-SM-G928A Build/NRD90M&#39;, &#39;Lenovo A6020l37 Build/LMY47V&#39;, &#39;SM-G900V&#39;, &#39;SM-N920V&#39;, &#39;VS990 Build/MRA58K&#39;, &#39;SAMSUNG-SM-T537A&#39;, &#39;C2104&#39;, &#39;SM-S902L&#39;, &#39;P5526A Build/NRD90M&#39;, &#39;Ilium X210 Build/LMY47I&#39;, &#39;LG-D373 Build/KOT49I.V10a&#39;, &#39;Z836BL&#39;, &#39;SM-T818V&#39;, &#39;SM-G530P&#39;, &#39;SM-A510M Build/LMY47X&#39;, &#39;LG-K428 Build/NRD90U&#39;]
</pre></div>
</div>
</div>
</div>
<p>En la siguiente línea, hacemos la imputación de la palabra <code class="docutils literal notranslate"><span class="pre">otro</span></code> en todas esos valores que tenían una frecuencia inferior a 1%</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">columna</span> <span class="ow">in</span> <span class="n">categoricas</span><span class="p">:</span>
    <span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;otro&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">categorias_bajas_frecuencia</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Revisamos ahora como nos quedaron nuestras categorías por columna</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39;Agrupando bajo la categoria &#39;Otro&#39; aquellas categorías con frecuencia relativa del 1% o menor,</span>
<span class="sd">logramos reducir considerablemente la cantidad de columnas que generará el OHE&#39;&#39;&#39;</span>
<span class="k">for</span> <span class="n">columna</span> <span class="ow">in</span> <span class="n">categoricas</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;---------------------&#39;</span><span class="p">)</span>
    <span class="n">n_cat</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columna</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>  <span class="c1"># Número de categorías únicas en la columna</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total de categorias de esta feature:&#39;</span><span class="p">,</span> <span class="n">n_cat</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;---------------------&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ProductCD
W    56877
H    15521
R    13724
C    11351
S     2526
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 5
---------------------
card4
visa                65608
mastercard          29599
american express     3330
discover             1462
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 4
---------------------
card6
debit              64926
credit             35063
debit or credit        7
charge card            3
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 4
---------------------
P_emaildomain
gmail.com        51682
yahoo.com        15883
otro             10786
anonymous.com     8663
hotmail.com       8119
aol.com           4866
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 6
---------------------
R_emaildomain
gmail.com        78477
anonymous.com     6954
hotmail.com       5422
otro              4597
yahoo.com         3222
aol.com           1327
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 6
---------------------
M1
T    99999
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 1
---------------------
M2
T    96851
F     3148
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
M3
T    93152
F     6847
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
M4
M0    83880
M2     9410
M1     6709
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 3
---------------------
M5
F    86121
T    13878
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
M6
F    74842
T    25157
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_12
NotFound    94534
Found        5465
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_15
Found      78923
New        18839
Unknown     2237
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 3
---------------------
id_16
NotFound    81432
Found       18567
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_28
Found    82012
New      17987
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_29
Found       81309
NotFound    18690
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_31
chrome 63.0                67861
otro                        7231
chrome 62.0                 6372
mobile safari 11.0          5191
ie 11.0 for desktop         3867
safari generic              3292
firefox 57.0                2003
chrome 62.0 for android     1506
mobile safari 10.0          1382
chrome 63.0 for android     1294
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 10
---------------------
id_35
T    89442
F    10557
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_36
F    97237
T     2762
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_37
T    91139
F     8860
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
id_38
T    89562
F    10437
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
DeviceType
desktop    87413
otro       12586
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 2
---------------------
DeviceInfo
Windows        79051
iOS Device      6635
otro            6255
MacOS           4914
Trident/7.0     3144
Name: count, dtype: int64
---------------------
Total de categorias de esta feature: 5
---------------------
</pre></div>
</div>
</div>
</div>
<p>Creamos ahora un df que contenga solo las variables categoricas, este es el que pasaremos por el OHE</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_cat</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">categoricas</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Aplicamos el OHE, asegurandonos de configurar la opción <code class="docutils literal notranslate"><span class="pre">drop=first</span></code>, para evitar problemas de <em>multicolinearidad</em> entre las nuevas variables</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">encoded_features</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_cat</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">input_features</span><span class="o">=</span><span class="n">df_cat</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Convertir las características codificadas a un DataFrame</span>
<span class="n">encoded_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">encoded_features</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Ahora, encoded_df es tu DataFrame con características codificadas</span>
<span class="n">encoded_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ProductCD_H</th>
      <th>ProductCD_R</th>
      <th>ProductCD_S</th>
      <th>ProductCD_W</th>
      <th>card4_discover</th>
      <th>card4_mastercard</th>
      <th>card4_visa</th>
      <th>card6_credit</th>
      <th>card6_debit</th>
      <th>card6_debit or credit</th>
      <th>P_emaildomain_aol.com</th>
      <th>P_emaildomain_gmail.com</th>
      <th>P_emaildomain_hotmail.com</th>
      <th>P_emaildomain_otro</th>
      <th>P_emaildomain_yahoo.com</th>
      <th>R_emaildomain_aol.com</th>
      <th>R_emaildomain_gmail.com</th>
      <th>R_emaildomain_hotmail.com</th>
      <th>R_emaildomain_otro</th>
      <th>R_emaildomain_yahoo.com</th>
      <th>M2_T</th>
      <th>M3_T</th>
      <th>M4_M1</th>
      <th>M4_M2</th>
      <th>M5_T</th>
      <th>M6_T</th>
      <th>id_12_NotFound</th>
      <th>id_15_New</th>
      <th>id_15_Unknown</th>
      <th>id_16_NotFound</th>
      <th>id_28_New</th>
      <th>id_29_NotFound</th>
      <th>id_31_chrome 62.0 for android</th>
      <th>id_31_chrome 63.0</th>
      <th>id_31_chrome 63.0 for android</th>
      <th>id_31_firefox 57.0</th>
      <th>id_31_ie 11.0 for desktop</th>
      <th>id_31_mobile safari 10.0</th>
      <th>id_31_mobile safari 11.0</th>
      <th>id_31_otro</th>
      <th>id_31_safari generic</th>
      <th>id_35_T</th>
      <th>id_36_T</th>
      <th>id_37_T</th>
      <th>id_38_T</th>
      <th>DeviceType_otro</th>
      <th>DeviceInfo_Trident/7.0</th>
      <th>DeviceInfo_Windows</th>
      <th>DeviceInfo_iOS Device</th>
      <th>DeviceInfo_otro</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>45230</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>44550</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>29581</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>26656</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>886</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3588</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>19536</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>9373</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>17107</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>73605</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Una vez realizado lo anterior, procedemos a armar de nuevo nuestra data, uniendo las variables numéricas y las categoricas ya codificadas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">[</span><span class="n">numericas</span><span class="p">],</span><span class="n">encoded_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(99999, 419)
</pre></div>
</div>
</div>
</div>
<p>confirmamos entonces que ahora nuestro dataset solo contiene variables numéricas tipo flotantes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span> <span class="c1">#Confirmado, todas son tipo float</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>float64    419
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<section id="identificando-columnas-altamente-correlacionadas-con-vif">
<h3>IDENTIFICANDO COLUMNAS ALTAMENTE CORRELACIONADAS CON VIF<a class="headerlink" href="#identificando-columnas-altamente-correlacionadas-con-vif" title="Permalink to this heading">#</a></h3>
<p>La multicolinearidad puede afectar gravemente el desempeño de los modelos lineales, pues uno de sus supuestos es que todas sus variables son independientes entre sí.</p>
<p>Para garantizar esto, utilizamos la estrategia variance inflation factor(VIF), que consiste en calcular este indicador para cada columna. Si el VIF de una columna es superior a 5, significa que existe multicolinearidad entre esa columna y algunas otras del data set. Entre más alto el valor, mayor es la multicolinearidad de esa columna.</p>
<p>El siguiente codigo, calcula el VIF del dataset, identifica y elimina la columna con el mayor valor VIf y luego recalcula nuevamente los valores para todo el dataset. Este proceso se repite hasta que ninguna columna tenga valor VIF mayor a 5.</p>
<p><strong>NOTA</strong></p>
<p>Este proceso para todas las filas del dataset, supera la memoria disponible del equipo, por lo que se hizo necesario ejecutarlo con un data reducido. Para este ejercicio usamos 2000 filas del dataset. Asumiendo que la <strong>multicolinealidad entre las columnas debería manifestarse de forma independiente a la cantidad de filas que se revisen</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
</pre></div>
</div>
</div>
</div>
<p>Funcion para calcular el VIF</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_vif</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">vif</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">vif</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">vif</span><span class="p">[</span><span class="s1">&#39;VIF_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
    <span class="k">return</span> <span class="n">vif</span>
</pre></div>
</div>
</div>
</div>
<p>Funcion para eliminar la columna con mayor VIF siempre que sea mayor de 5</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">eliminacion_vif</span><span class="p">(</span><span class="n">vif</span><span class="p">,</span><span class="n">df</span><span class="p">):</span>
  <span class="n">max_vif</span><span class="o">=</span> <span class="n">vif</span><span class="p">[</span><span class="s1">&#39;VIF_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">max_vif</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------------------------&#39;</span><span class="p">)</span>
    <span class="n">idxmax</span><span class="o">=</span><span class="n">vif</span><span class="p">[</span><span class="s1">&#39;VIF_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span> <span class="c1">#Hallar el valor maximo de la columna VIF_Value y traer el indice</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;eliminamos &#39;</span><span class="p">,</span><span class="n">vif</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idxmax</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span><span class="s1">&#39; con VIF de: &#39;</span><span class="p">,</span> <span class="n">max_vif</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">((</span><span class="n">vif</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idxmax</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="c1"># Con ese indice obtener el &quot;feature&quot; y eliminarlo de dataset</span>
    <span class="k">return</span> <span class="kc">True</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------------------------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Ya no hay valores vif mayores a 5&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(99999, 419)
</pre></div>
</div>
</div>
</div>
<p>Data reducida para poder ejecutar el bucle. Se intentó realizar con la data completa y con submuestras de 10000 y 5000 filas, pero el procesamiento tardaba demasiado. Finalmente se usaron 2000 filas para el calculo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_red</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1">#reduzco filas para agilizar el metodo</span>
</pre></div>
</div>
</div>
</div>
<p>Ciclo <code class="docutils literal notranslate"><span class="pre">while</span></code> para hacer la eliminación de columnas con alto VIF en todo el dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elimina</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">while</span> <span class="n">elimina</span><span class="p">:</span>
    <span class="n">vif</span> <span class="o">=</span> <span class="n">calculate_vif</span><span class="p">(</span><span class="n">data_red</span><span class="p">)</span>
    <span class="n">elimina</span> <span class="o">=</span> <span class="n">eliminacion_vif</span><span class="p">(</span><span class="n">vif</span><span class="p">,</span> <span class="n">data_red</span><span class="p">)</span>
    <span class="n">features</span><span class="o">=</span><span class="n">vif</span><span class="o">.</span><span class="n">features</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">vif</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-------------------------
eliminamos  V27  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.070251
1   TransactionDT  36.822772
2  TransactionAmt   1.457012
3           card1   1.328546
4           card2   1.402610
5           card3  23.498541
6           card5   1.736892
7           addr1   1.252065
8           addr2   2.345609
9           dist1   1.238861
-------------------------
eliminamos  V28  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.086822
1   TransactionDT  36.822772
2  TransactionAmt   1.457012
3           card1   1.328546
4           card2   1.402610
5           card3  23.498541
6           card5   1.736892
7           addr1   1.252065
8           addr2   2.345609
9           dist1   1.238861
-------------------------
eliminamos  V68  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.086503
1   TransactionDT  36.822772
2  TransactionAmt   1.457012
3           card1   1.328546
4           card2   1.402610
5           card3  23.498541
6           card5   1.736892
7           addr1   1.252065
8           addr2   2.345609
9           dist1   1.238861
-------------------------
eliminamos  V129  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.070243
1   TransactionDT  36.822771
2  TransactionAmt   1.457012
3           card1   1.328546
4           card2   1.402610
5           card3  23.498541
6           card5   1.736892
7           addr1   1.252065
8           addr2   2.345609
9           dist1   1.238861
-------------------------
eliminamos  V102  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.056698
1   TransactionDT  36.798320
2  TransactionAmt   1.456810
3           card1   1.323985
4           card2   1.401827
5           card3  23.498537
6           card5   1.734332
7           addr1   1.249671
8           addr2   2.345587
9           dist1   1.238853
-------------------------
eliminamos  V137  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.058001
1   TransactionDT  36.798320
2  TransactionAmt   1.456810
3           card1   1.323985
4           card2   1.401827
5           card3  23.498537
6           card5   1.734332
7           addr1   1.249671
8           addr2   2.345587
9           dist1   1.238853
-------------------------
eliminamos  V106  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.066943
1   TransactionDT  36.798283
2  TransactionAmt   1.456696
3           card1   1.323810
4           card2   1.401759
5           card3  23.495897
6           card5   1.732329
7           addr1   1.249665
8           addr2   2.345516
9           dist1   1.238689
-------------------------
eliminamos  V101  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.023064
1   TransactionDT  36.798283
2  TransactionAmt   1.456696
3           card1   1.323810
4           card2   1.401759
5           card3  23.495897
6           card5   1.732329
7           addr1   1.249665
8           addr2   2.345516
9           dist1   1.238689
-------------------------
eliminamos  V130  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.993939
1   TransactionDT  36.798283
2  TransactionAmt   1.456696
3           card1   1.323810
4           card2   1.401759
5           card3  23.495897
6           card5   1.732329
7           addr1   1.249665
8           addr2   2.345516
9           dist1   1.238689
-------------------------
eliminamos  V138  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.050699
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V141  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.072069
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V146  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.071957
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V161  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.072064
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V162  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.064836
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V178  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.063398
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V177  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.069461
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V179  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.047992
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V203  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.036303
1   TransactionDT  36.797409
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V204  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.066605
1   TransactionDT  36.797410
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V212  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.063942
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V180  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.064755
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V211  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.022855
1   TransactionDT  36.797413
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V213  con VIF de:  inf
         features  VIF_value
0   TransactionID  36.002185
1   TransactionDT  36.797411
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V207  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.989189
1   TransactionDT  36.797399
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488144
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V215  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997087
1   TransactionDT  36.797399
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V216  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996814
1   TransactionDT  36.797400
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V232  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996423
1   TransactionDT  36.797400
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V233  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996423
1   TransactionDT  36.797400
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V225  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.993364
1   TransactionDT  36.797400
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V231  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996955
1   TransactionDT  36.797401
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V264  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.994294
1   TransactionDT  36.797401
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V218  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996695
1   TransactionDT  36.797404
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V265  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996789
1   TransactionDT  36.797405
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V208  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997068
1   TransactionDT  36.797402
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V205  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997073
1   TransactionDT  36.797402
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V182  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996737
1   TransactionDT  36.797404
2  TransactionAmt   1.456684
3           card1   1.323805
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V202  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997041
1   TransactionDT  36.797412
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V214  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996921
1   TransactionDT  36.797412
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V219  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997049
1   TransactionDT  36.797413
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V206  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997079
1   TransactionDT  36.797413
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V224  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997085
1   TransactionDT  36.797417
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V183  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997067
1   TransactionDT  36.797417
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V17  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997036
1   TransactionDT  36.797417
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V236  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.997038
1   TransactionDT  36.797417
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V263  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.996836
1   TransactionDT  36.797417
2  TransactionAmt   1.456684
3           card1   1.323804
4           card2   1.401245
5           card3  23.488145
6           card5   1.731888
7           addr1   1.249659
8           addr2   2.345507
9           dist1   1.238680
-------------------------
eliminamos  V21  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.980793
1   TransactionDT  36.782205
2  TransactionAmt   1.456670
3           card1   1.323792
4           card2   1.401157
5           card3  23.487360
6           card5   1.731844
7           addr1   1.249561
8           addr2   2.345244
9           dist1   1.238679
-------------------------
eliminamos  V18  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.980678
1   TransactionDT  36.782205
2  TransactionAmt   1.456670
3           card1   1.323792
4           card2   1.401157
5           card3  23.487360
6           card5   1.731844
7           addr1   1.249561
8           addr2   2.345244
9           dist1   1.238679
-------------------------
eliminamos  V167  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.980531
1   TransactionDT  36.782205
2  TransactionAmt   1.456670
3           card1   1.323792
4           card2   1.401157
5           card3  23.487360
6           card5   1.731844
7           addr1   1.249561
8           addr2   2.345244
9           dist1   1.238679
-------------------------
eliminamos  V271  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.980775
1   TransactionDT  36.782205
2  TransactionAmt   1.456670
3           card1   1.323792
4           card2   1.401157
5           card3  23.487360
6           card5   1.731844
7           addr1   1.249561
8           addr2   2.345244
9           dist1   1.238679
-------------------------
eliminamos  V51  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.980560
1   TransactionDT  36.782205
2  TransactionAmt   1.456670
3           card1   1.323792
4           card2   1.401157
5           card3  23.487360
6           card5   1.731844
7           addr1   1.249561
8           addr2   2.345244
9           dist1   1.238679
-------------------------
eliminamos  V295  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.980789
1   TransactionDT  36.782205
2  TransactionAmt   1.456670
3           card1   1.323792
4           card2   1.401157
5           card3  23.487360
6           card5   1.731844
7           addr1   1.249561
8           addr2   2.345244
9           dist1   1.238679
-------------------------
eliminamos  V306  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.980694
1   TransactionDT  36.779561
2  TransactionAmt   1.456670
3           card1   1.323792
4           card2   1.401157
5           card3  23.487360
6           card5   1.731844
7           addr1   1.249561
8           addr2   2.345244
9           dist1   1.238679
-------------------------
eliminamos  V15  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936875
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323226
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237621
-------------------------
eliminamos  V31  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936864
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323225
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237620
-------------------------
eliminamos  V33  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936865
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323226
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237620
-------------------------
eliminamos  V34  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936856
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323226
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237619
-------------------------
eliminamos  V16  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936859
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323227
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237619
-------------------------
eliminamos  V57  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936863
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323226
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249110
8           addr2   2.345105
9           dist1   1.237621
-------------------------
eliminamos  V71  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936867
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323228
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237621
-------------------------
eliminamos  V73  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936867
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323224
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237620
-------------------------
eliminamos  V94  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936822
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323226
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237620
-------------------------
eliminamos  V307  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.936837
1   TransactionDT  36.726501
2  TransactionAmt   1.456667
3           card1   1.323226
4           card2   1.400356
5           card3  23.482323
6           card5   1.731815
7           addr1   1.249111
8           addr2   2.345105
9           dist1   1.237619
-------------------------
eliminamos  V308  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726397
2  TransactionAmt   1.456161
3           card1   1.320911
4           card2   1.400300
5           card3  23.481173
6           card5   1.730737
7           addr1   1.248141
8           addr2   2.345105
9           dist1   1.237368
-------------------------
eliminamos  V14  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V108  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V118  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V148  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V120  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V149  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V153  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V154  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V155  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V186  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V188  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V194  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V197  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V242  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V250  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V322  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V323  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V328  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V332  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  card6_credit  con VIF de:  inf
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V258  con VIF de:  22919082073132.297
         features  VIF_value
0   TransactionID  35.933731
1   TransactionDT  36.726242
2  TransactionAmt   1.455754
3           card1   1.320475
4           card2   1.400268
5           card3  23.481159
6           card5   1.728767
7           addr1   1.246790
8           addr2   2.345094
9           dist1   1.233198
-------------------------
eliminamos  V268  con VIF de:  8690038904.831362
         features  VIF_value
0   TransactionID  35.933183
1   TransactionDT  36.725651
2  TransactionAmt   1.455631
3           card1   1.319453
4           card2   1.400258
5           card3  23.472099
6           card5   1.711890
7           addr1   1.246703
8           addr2   2.334723
9           dist1   1.233186
-------------------------
eliminamos  V230  con VIF de:  1866425037.9184427
         features  VIF_value
0   TransactionID  35.933135
1   TransactionDT  36.725648
2  TransactionAmt   1.455630
3           card1   1.318669
4           card2   1.400250
5           card3  23.472015
6           card5   1.709487
7           addr1   1.246700
8           addr2   2.326998
9           dist1   1.233181
-------------------------
eliminamos  V274  con VIF de:  144060915.1429286
         features  VIF_value
0   TransactionID  35.932092
1   TransactionDT  36.724316
2  TransactionAmt   1.455290
3           card1   1.317919
4           card2   1.400147
5           card3  23.455021
6           card5   1.699854
7           addr1   1.246347
8           addr2   2.321815
9           dist1   1.233181
-------------------------
eliminamos  V278  con VIF de:  87144260.00211738
         features  VIF_value
0   TransactionID  35.931986
1   TransactionDT  36.724278
2  TransactionAmt   1.454987
3           card1   1.316932
4           card2   1.398675
5           card3  23.450191
6           card5   1.695028
7           addr1   1.246174
8           addr2   2.315135
9           dist1   1.233130
-------------------------
eliminamos  V339  con VIF de:  11334270.853739755
         features  VIF_value
0   TransactionID  35.931878
1   TransactionDT  36.724278
2  TransactionAmt   1.454973
3           card1   1.316675
4           card2   1.396448
5           card3  23.446583
6           card5   1.694668
7           addr1   1.245537
8           addr2   2.311243
9           dist1   1.233090
-------------------------
eliminamos  V201  con VIF de:  2835007.468008687
         features  VIF_value
0   TransactionID  35.928993
1   TransactionDT  36.723256
2  TransactionAmt   1.454845
3           card1   1.316309
4           card2   1.396442
5           card3  23.432033
6           card5   1.694365
7           addr1   1.245533
8           addr2   2.311083
9           dist1   1.233090
-------------------------
eliminamos  V267  con VIF de:  1741531.071669691
         features  VIF_value
0   TransactionID  35.886019
1   TransactionDT  36.693546
2  TransactionAmt   1.454508
3           card1   1.316228
4           card2   1.396025
5           card3  23.423704
6           card5   1.694355
7           addr1   1.244729
8           addr2   2.310641
9           dist1   1.232969
-------------------------
eliminamos  V275  con VIF de:  1078100.5472232327
         features  VIF_value
0   TransactionID  35.870657
1   TransactionDT  36.677343
2  TransactionAmt   1.454338
3           card1   1.315552
4           card2   1.395668
5           card3  23.416719
6           card5   1.694284
7           addr1   1.241993
8           addr2   2.308167
9           dist1   1.232944
-------------------------
eliminamos  V150  con VIF de:  567101.0665229973
         features  VIF_value
0   TransactionID  35.790099
1   TransactionDT  36.570645
2  TransactionAmt   1.453117
3           card1   1.313441
4           card2   1.391658
5           card3  23.410141
6           card5   1.689464
7           addr1   1.241628
8           addr2   2.304767
9           dist1   1.232886
-------------------------
eliminamos  V253  con VIF de:  514624.9726696872
         features  VIF_value
0   TransactionID  35.766907
1   TransactionDT  36.538326
2  TransactionAmt   1.453091
3           card1   1.312118
4           card2   1.390222
5           card3  23.382896
6           card5   1.688059
7           addr1   1.240151
8           addr2   2.250360
9           dist1   1.232886
-------------------------
eliminamos  V160  con VIF de:  372622.1420019065
         features  VIF_value
0   TransactionID  35.762186
1   TransactionDT  36.535575
2  TransactionAmt   1.452959
3           card1   1.311139
4           card2   1.388041
5           card3  23.350353
6           card5   1.684228
7           addr1   1.239539
8           addr2   2.249546
9           dist1   1.232885
-------------------------
eliminamos  V254  con VIF de:  338146.89948583354
         features  VIF_value
0   TransactionID  35.665154
1   TransactionDT  36.461860
2  TransactionAmt   1.452943
3           card1   1.310870
4           card2   1.384631
5           card3  23.333162
6           card5   1.683799
7           addr1   1.239060
8           addr2   2.247133
9           dist1   1.232880
-------------------------
eliminamos  V152  con VIF de:  169438.0936203748
         features  VIF_value
0   TransactionID  35.663149
1   TransactionDT  36.461074
2  TransactionAmt   1.452943
3           card1   1.310868
4           card2   1.383680
5           card3  23.306777
6           card5   1.682893
7           addr1   1.239059
8           addr2   2.246729
9           dist1   1.232872
-------------------------
eliminamos  V243  con VIF de:  103618.98472234675
         features  VIF_value
0   TransactionID  35.652526
1   TransactionDT  36.452678
2  TransactionAmt   1.452363
3           card1   1.309082
4           card2   1.383680
5           card3  23.298797
6           card5   1.680870
7           addr1   1.236227
8           addr2   2.222767
9           dist1   1.232842
-------------------------
eliminamos  V304  con VIF de:  89206.74162330035
         features  VIF_value
0   TransactionID  35.650391
1   TransactionDT  36.452356
2  TransactionAmt   1.452242
3           card1   1.308820
4           card2   1.378553
5           card3  23.298791
6           card5   1.679671
7           addr1   1.235915
8           addr2   2.213125
9           dist1   1.232809
-------------------------
eliminamos  V187  con VIF de:  60936.581113108165
         features  VIF_value
0   TransactionID  35.638307
1   TransactionDT  36.450378
2  TransactionAmt   1.452125
3           card1   1.308804
4           card2   1.374213
5           card3  23.280616
6           card5   1.674139
7           addr1   1.235419
8           addr2   2.183630
9           dist1   1.232795
-------------------------
eliminamos  V272  con VIF de:  33028.07647349345
         features  VIF_value
0   TransactionID  35.602945
1   TransactionDT  36.403742
2  TransactionAmt   1.450812
3           card1   1.305665
4           card2   1.373698
5           card3  23.220705
6           card5   1.673890
7           addr1   1.235238
8           addr2   2.179912
9           dist1   1.232774
-------------------------
eliminamos  V145  con VIF de:  30515.861975220196
         features  VIF_value
0   TransactionID  35.597221
1   TransactionDT  36.401316
2  TransactionAmt   1.450808
3           card1   1.305630
4           card2   1.373673
5           card3  23.220369
6           card5   1.673802
7           addr1   1.235105
8           addr2   2.179854
9           dist1   1.232773
-------------------------
eliminamos  V223  con VIF de:  23233.616743336974
         features  VIF_value
0   TransactionID  35.555686
1   TransactionDT  36.353016
2  TransactionAmt   1.450787
3           card1   1.305010
4           card2   1.373444
5           card3  23.219798
6           card5   1.673799
7           addr1   1.234392
8           addr2   2.171951
9           dist1   1.232772
-------------------------
eliminamos  V246  con VIF de:  20964.29435687606
         features  VIF_value
0   TransactionID  35.546871
1   TransactionDT  36.348106
2  TransactionAmt   1.450782
3           card1   1.304337
4           card2   1.373436
5           card3  23.017698
6           card5   1.673664
7           addr1   1.234253
8           addr2   2.165292
9           dist1   1.232747
-------------------------
eliminamos  V277  con VIF de:  13899.381840197455
         features  VIF_value
0   TransactionID  35.510133
1   TransactionDT  36.309928
2  TransactionAmt   1.450782
3           card1   1.304335
4           card2   1.373376
5           card3  22.787302
6           card5   1.673659
7           addr1   1.234252
8           addr2   2.165185
9           dist1   1.232732
-------------------------
eliminamos  V238  con VIF de:  11176.662841944346
         features  VIF_value
0   TransactionID  35.467412
1   TransactionDT  36.268263
2  TransactionAmt   1.450752
3           card1   1.304159
4           card2   1.373351
5           card3  22.706988
6           card5   1.672852
7           addr1   1.233609
8           addr2   2.160210
9           dist1   1.232681
-------------------------
eliminamos  V229  con VIF de:  7400.411329678313
         features  VIF_value
0   TransactionID  35.467267
1   TransactionDT  36.267385
2  TransactionAmt   1.450752
3           card1   1.300517
4           card2   1.372034
5           card3  22.702605
6           card5   1.670100
7           addr1   1.231948
8           addr2   2.159280
9           dist1   1.232656
-------------------------
eliminamos  V165  con VIF de:  4759.387864295934
         features  VIF_value
0   TransactionID  35.446804
1   TransactionDT  36.237806
2  TransactionAmt   1.450285
3           card1   1.300139
4           card2   1.371001
5           card3  22.690407
6           card5   1.659573
7           addr1   1.230892
8           addr2   2.154472
9           dist1   1.232640
-------------------------
eliminamos  V249  con VIF de:  4570.110622629712
         features  VIF_value
0   TransactionID  35.395895
1   TransactionDT  36.160048
2  TransactionAmt   1.450234
3           card1   1.299910
4           card2   1.370963
5           card3  22.681987
6           card5   1.659487
7           addr1   1.228171
8           addr2   2.134583
9           dist1   1.232631
-------------------------
eliminamos  V128  con VIF de:  4515.748827943062
         features  VIF_value
0   TransactionID  35.384698
1   TransactionDT  36.150249
2  TransactionAmt   1.450234
3           card1   1.299305
4           card2   1.370655
5           card3  22.680438
6           card5   1.659441
7           addr1   1.228141
8           addr2   2.131133
9           dist1   1.232598
-------------------------
eliminamos  V139  con VIF de:  4373.375133390635
         features  VIF_value
0   TransactionID  35.384353
1   TransactionDT  36.150032
2  TransactionAmt   1.449818
3           card1   1.299049
4           card2   1.370273
5           card3  22.659161
6           card5   1.658506
7           addr1   1.226811
8           addr2   2.130972
9           dist1   1.232391
-------------------------
eliminamos  V244  con VIF de:  4092.9506635476146
         features  VIF_value
0   TransactionID  35.381382
1   TransactionDT  36.143639
2  TransactionAmt   1.449745
3           card1   1.298497
4           card2   1.368105
5           card3  22.647872
6           card5   1.657815
7           addr1   1.226707
8           addr2   2.130547
9           dist1   1.232390
-------------------------
eliminamos  V92  con VIF de:  3235.654250167393
         features  VIF_value
0   TransactionID  35.381103
1   TransactionDT  36.143318
2  TransactionAmt   1.449402
3           card1   1.295896
4           card2   1.366750
5           card3  22.601490
6           card5   1.656728
7           addr1   1.226289
8           addr2   2.129710
9           dist1   1.232390
-------------------------
eliminamos  V157  con VIF de:  2925.8173742642116
         features  VIF_value
0   TransactionID  35.358505
1   TransactionDT  36.116507
2  TransactionAmt   1.449340
3           card1   1.294917
4           card2   1.366703
5           card3  22.162372
6           card5   1.656366
7           addr1   1.225909
8           addr2   2.110063
9           dist1   1.232377
-------------------------
eliminamos  C8  con VIF de:  2910.8620128256152
         features  VIF_value
0   TransactionID  35.358484
1   TransactionDT  36.113919
2  TransactionAmt   1.449338
3           card1   1.293779
4           card2   1.366065
5           card3  22.111487
6           card5   1.656301
7           addr1   1.225892
8           addr2   2.109490
9           dist1   1.232370
-------------------------
eliminamos  V151  con VIF de:  2830.7336744869963
         features  VIF_value
0   TransactionID  35.352532
1   TransactionDT  36.106649
2  TransactionAmt   1.449096
3           card1   1.293773
4           card2   1.365435
5           card3  22.104632
6           card5   1.654917
7           addr1   1.225878
8           addr2   2.100639
9           dist1   1.232270
-------------------------
eliminamos  V59  con VIF de:  2601.408545099304
         features  VIF_value
0   TransactionID  34.801879
1   TransactionDT  35.489261
2  TransactionAmt   1.448954
3           card1   1.293328
4           card2   1.365432
5           card3  22.101431
6           card5   1.652184
7           addr1   1.225302
8           addr2   2.086712
9           dist1   1.232268
-------------------------
eliminamos  V192  con VIF de:  2123.9259406261485
         features  VIF_value
0   TransactionID  34.787222
1   TransactionDT  35.476043
2  TransactionAmt   1.448856
3           card1   1.292714
4           card2   1.363284
5           card3  22.082675
6           card5   1.651486
7           addr1   1.224651
8           addr2   2.074827
9           dist1   1.232256
-------------------------
eliminamos  V191  con VIF de:  2098.66828638256
         features  VIF_value
0   TransactionID  34.782910
1   TransactionDT  35.475253
2  TransactionAmt   1.448198
3           card1   1.292711
4           card2   1.359591
5           card3  22.078177
6           card5   1.651449
7           addr1   1.224610
8           addr2   2.074365
9           dist1   1.232246
-------------------------
eliminamos  V97  con VIF de:  2070.4889305843863
         features  VIF_value
0   TransactionID  34.776619
1   TransactionDT  35.461166
2  TransactionAmt   1.447758
3           card1   1.292506
4           card2   1.357112
5           card3  22.063587
6           card5   1.651416
7           addr1   1.223498
8           addr2   2.074275
9           dist1   1.232200
-------------------------
eliminamos  V279  con VIF de:  1937.190406510206
         features  VIF_value
0   TransactionID  34.774408
1   TransactionDT  35.457174
2  TransactionAmt   1.447724
3           card1   1.292263
4           card2   1.353907
5           card3  22.063360
6           card5   1.649413
7           addr1   1.221930
8           addr2   2.074254
9           dist1   1.231489
-------------------------
eliminamos  V228  con VIF de:  1764.9921895854263
         features  VIF_value
0   TransactionID  34.706710
1   TransactionDT  35.414938
2  TransactionAmt   1.447677
3           card1   1.292054
4           card2   1.353801
5           card3  22.061094
6           card5   1.649132
7           addr1   1.221827
8           addr2   2.071267
9           dist1   1.231486
-------------------------
eliminamos  V166  con VIF de:  1576.8030089728923
         features  VIF_value
0   TransactionID  34.678839
1   TransactionDT  35.390087
2  TransactionAmt   1.447605
3           card1   1.291189
4           card2   1.353731
5           card3  21.942142
6           card5   1.649006
7           addr1   1.221810
8           addr2   2.070801
9           dist1   1.231469
-------------------------
eliminamos  V252  con VIF de:  1572.4070261497884
         features  VIF_value
0   TransactionID  34.515717
1   TransactionDT  35.230815
2  TransactionAmt   1.447604
3           card1   1.289580
4           card2   1.352988
5           card3  21.941612
6           card5   1.643784
7           addr1   1.220931
8           addr2   2.056704
9           dist1   1.231467
-------------------------
eliminamos  V40  con VIF de:  1305.1988021849668
         features  VIF_value
0   TransactionID  34.365349
1   TransactionDT  35.072539
2  TransactionAmt   1.447557
3           card1   1.287811
4           card2   1.352533
5           card3  21.933181
6           card5   1.638528
7           addr1   1.220778
8           addr2   2.055791
9           dist1   1.231462
-------------------------
eliminamos  V262  con VIF de:  1276.411030540797
         features  VIF_value
0   TransactionID  34.361911
1   TransactionDT  35.069069
2  TransactionAmt   1.447410
3           card1   1.281229
4           card2   1.352518
5           card3  20.836338
6           card5   1.638169
7           addr1   1.220655
8           addr2   2.055188
9           dist1   1.231424
-------------------------
eliminamos  V266  con VIF de:  1222.5840262263314
         features  VIF_value
0   TransactionID  34.336833
1   TransactionDT  35.051887
2  TransactionAmt   1.447160
3           card1   1.280884
4           card2   1.352474
5           card3  20.831057
6           card5   1.638161
7           addr1   1.219373
8           addr2   2.051110
9           dist1   1.231415
-------------------------
eliminamos  C1  con VIF de:  1210.0780724250103
         features  VIF_value
0   TransactionID  34.290418
1   TransactionDT  35.021898
2  TransactionAmt   1.446095
3           card1   1.280770
4           card2   1.351699
5           card3  20.827013
6           card5   1.638157
7           addr1   1.219313
8           addr2   2.047694
9           dist1   1.231234
-------------------------
eliminamos  V164  con VIF de:  1009.8847190020324
         features  VIF_value
0   TransactionID  34.288116
1   TransactionDT  35.018798
2  TransactionAmt   1.445927
3           card1   1.278689
4           card2   1.351421
5           card3  20.825902
6           card5   1.637475
7           addr1   1.219268
8           addr2   2.047693
9           dist1   1.231229
-------------------------
eliminamos  C2  con VIF de:  923.137948173918
         features  VIF_value
0   TransactionID  34.110581
1   TransactionDT  34.863663
2  TransactionAmt   1.445927
3           card1   1.278484
4           card2   1.351283
5           card3  20.819401
6           card5   1.636520
7           addr1   1.216112
8           addr2   2.028286
9           dist1   1.231221
-------------------------
eliminamos  ProductCD_W  con VIF de:  783.7793830690906
         features  VIF_value
0   TransactionID  34.085762
1   TransactionDT  34.840730
2  TransactionAmt   1.445637
3           card1   1.277978
4           card2   1.350436
5           card3  20.795442
6           card5   1.636428
7           addr1   1.215215
8           addr2   2.027630
9           dist1   1.228129
-------------------------
eliminamos  V168  con VIF de:  729.7067876807547
         features  VIF_value
0   TransactionID  34.069036
1   TransactionDT  34.819202
2  TransactionAmt   1.445530
3           card1   1.273876
4           card2   1.348529
5           card3  19.684664
6           card5   1.633969
7           addr1   1.215048
8           addr2   2.027105
9           dist1   1.228073
-------------------------
eliminamos  V255  con VIF de:  655.4088903266307
         features  VIF_value
0   TransactionID  34.066110
1   TransactionDT  34.818363
2  TransactionAmt   1.445515
3           card1   1.273841
4           card2   1.346867
5           card3  19.558816
6           card5   1.633295
7           addr1   1.215008
8           addr2   2.027076
9           dist1   1.228065
-------------------------
eliminamos  V257  con VIF de:  607.4379826416331
         features  VIF_value
0   TransactionID  34.065256
1   TransactionDT  34.817568
2  TransactionAmt   1.445291
3           card1   1.272321
4           card2   1.346458
5           card3  19.526719
6           card5   1.633266
7           addr1   1.214856
8           addr2   2.027073
9           dist1   1.227993
-------------------------
eliminamos  V237  con VIF de:  552.7880544192751
         features  VIF_value
0   TransactionID  34.051591
1   TransactionDT  34.793870
2  TransactionAmt   1.445196
3           card1   1.271245
4           card2   1.346458
5           card3  19.525737
6           card5   1.632883
7           addr1   1.214504
8           addr2   2.027065
9           dist1   1.227978
-------------------------
eliminamos  id_31_chrome 63.0  con VIF de:  536.8527499962859
         features  VIF_value
0   TransactionID  34.041672
1   TransactionDT  34.784851
2  TransactionAmt   1.444815
3           card1   1.270825
4           card2   1.344598
5           card3  19.516906
6           card5   1.632219
7           addr1   1.214451
8           addr2   2.020659
9           dist1   1.227974
-------------------------
eliminamos  C11  con VIF de:  490.03625740768985
         features  VIF_value
0   TransactionID  34.002426
1   TransactionDT  34.758735
2  TransactionAmt   1.444801
3           card1   1.269637
4           card2   1.342950
5           card3  19.493157
6           card5   1.627407
7           addr1   1.214219
8           addr2   2.013103
9           dist1   1.227943
-------------------------
eliminamos  V144  con VIF de:  478.69293668115796
         features  VIF_value
0   TransactionID  33.994248
1   TransactionDT  34.746217
2  TransactionAmt   1.444797
3           card1   1.268748
4           card2   1.342798
5           card3  19.471800
6           card5   1.625807
7           addr1   1.209243
8           addr2   2.012999
9           dist1   1.225999
-------------------------
eliminamos  V248  con VIF de:  470.90620901116944
         features  VIF_value
0   TransactionID  33.955483
1   TransactionDT  34.735733
2  TransactionAmt   1.444770
3           card1   1.268685
4           card2   1.342785
5           card3  19.449352
6           card5   1.625793
7           addr1   1.209234
8           addr2   2.008245
9           dist1   1.225996
-------------------------
eliminamos  V337  con VIF de:  435.94920409984906
         features  VIF_value
0   TransactionID  33.943775
1   TransactionDT  34.726331
2  TransactionAmt   1.443899
3           card1   1.268120
4           card2   1.342765
5           card3  19.446152
6           card5   1.624842
7           addr1   1.208179
8           addr2   2.005974
9           dist1   1.225962
-------------------------
eliminamos  V133  con VIF de:  384.19614981986723
         features  VIF_value
0   TransactionID  33.942030
1   TransactionDT  34.723937
2  TransactionAmt   1.443769
3           card1   1.267762
4           card2   1.342553
5           card3  19.365404
6           card5   1.621992
7           addr1   1.208091
8           addr2   1.987128
9           dist1   1.225949
-------------------------
eliminamos  V126  con VIF de:  374.4774976773198
         features  VIF_value
0   TransactionID  33.871124
1   TransactionDT  34.693746
2  TransactionAmt   1.440536
3           card1   1.267744
4           card2   1.341215
5           card3  19.363539
6           card5   1.621942
7           addr1   1.208074
8           addr2   1.987085
9           dist1   1.225943
-------------------------
eliminamos  V80  con VIF de:  361.7595267652778
         features  VIF_value
0   TransactionID  33.811167
1   TransactionDT  34.622066
2  TransactionAmt   1.438097
3           card1   1.266896
4           card2   1.341215
5           card3  19.358912
6           card5   1.621870
7           addr1   1.205852
8           addr2   1.987062
9           dist1   1.225912
-------------------------
eliminamos  V185  con VIF de:  339.9348394393187
         features  VIF_value
0   TransactionID  33.803646
1   TransactionDT  34.602595
2  TransactionAmt   1.438090
3           card1   1.265277
4           card2   1.340050
5           card3  19.343954
6           card5   1.619471
7           addr1   1.205813
8           addr2   1.953751
9           dist1   1.225911
-------------------------
eliminamos  V85  con VIF de:  282.97721773995477
         features  VIF_value
0   TransactionID  33.803646
1   TransactionDT  34.602360
2  TransactionAmt   1.437882
3           card1   1.265249
4           card2   1.340049
5           card3  19.343838
6           card5   1.618838
7           addr1   1.205731
8           addr2   1.948397
9           dist1   1.225911
-------------------------
eliminamos  V200  con VIF de:  276.6158782113935
         features  VIF_value
0   TransactionID  33.800269
1   TransactionDT  34.599011
2  TransactionAmt   1.437880
3           card1   1.265196
4           card2   1.339941
5           card3  18.447860
6           card5   1.618580
7           addr1   1.205588
8           addr2   1.946664
9           dist1   1.225903
-------------------------
eliminamos  V327  con VIF de:  270.50398926818264
         features  VIF_value
0   TransactionID  33.777538
1   TransactionDT  34.564569
2  TransactionAmt   1.436727
3           card1   1.264934
4           card2   1.338610
5           card3  18.385641
6           card5   1.610481
7           addr1   1.204551
8           addr2   1.946612
9           dist1   1.225832
-------------------------
eliminamos  V42  con VIF de:  239.12754060482942
         features  VIF_value
0   TransactionID  33.763200
1   TransactionDT  34.539371
2  TransactionAmt   1.436323
3           card1   1.262919
4           card2   1.336607
5           card3  18.384520
6           card5   1.610370
7           addr1   1.203899
8           addr2   1.944743
9           dist1   1.225806
-------------------------
eliminamos  V217  con VIF de:  227.85080487006164
         features  VIF_value
0   TransactionID  33.761287
1   TransactionDT  34.538386
2  TransactionAmt   1.436209
3           card1   1.262798
4           card2   1.335596
5           card3  17.581252
6           card5   1.608243
7           addr1   1.203514
8           addr2   1.941289
9           dist1   1.225795
-------------------------
eliminamos  V63  con VIF de:  216.82035939465743
         features  VIF_value
0   TransactionID  33.734070
1   TransactionDT  34.517762
2  TransactionAmt   1.435457
3           card1   1.262798
4           card2   1.334910
5           card3  17.566398
6           card5   1.607873
7           addr1   1.203481
8           addr2   1.938295
9           dist1   1.225783
-------------------------
eliminamos  C4  con VIF de:  213.63070713703732
         features  VIF_value
0   TransactionID  33.732718
1   TransactionDT  34.514070
2  TransactionAmt   1.435175
3           card1   1.262616
4           card2   1.333632
5           card3  17.245104
6           card5   1.607779
7           addr1   1.203471
8           addr2   1.928904
9           dist1   1.225783
-------------------------
eliminamos  V156  con VIF de:  199.46405745643534
         features  VIF_value
0   TransactionID  33.727831
1   TransactionDT  34.511927
2  TransactionAmt   1.435143
3           card1   1.262256
4           card2   1.333086
5           card3  17.237909
6           card5   1.607755
7           addr1   1.203334
8           addr2   1.920576
9           dist1   1.225537
-------------------------
eliminamos  V79  con VIF de:  184.60401471080155
         features  VIF_value
0   TransactionID  33.727699
1   TransactionDT  34.511757
2  TransactionAmt   1.435142
3           card1   1.262179
4           card2   1.333072
5           card3  17.236053
6           card5   1.605425
7           addr1   1.202970
8           addr2   1.894232
9           dist1   1.225490
-------------------------
eliminamos  V96  con VIF de:  178.40230429146
         features  VIF_value
0   TransactionID  33.717051
1   TransactionDT  34.497215
2  TransactionAmt   1.434805
3           card1   1.261766
4           card2   1.332591
5           card3  16.736796
6           card5   1.604954
7           addr1   1.202883
8           addr2   1.891212
9           dist1   1.225460
-------------------------
eliminamos  V189  con VIF de:  163.77156064684758
         features  VIF_value
0   TransactionID  33.669190
1   TransactionDT  34.468876
2  TransactionAmt   1.433875
3           card1   1.260775
4           card2   1.318741
5           card3  16.634823
6           card5   1.594273
7           addr1   1.199345
8           addr2   1.891200
9           dist1   1.224762
-------------------------
eliminamos  V321  con VIF de:  163.07469077037968
         features  VIF_value
0   TransactionID  33.667553
1   TransactionDT  34.466405
2  TransactionAmt   1.433833
3           card1   1.260361
4           card2   1.317986
5           card3  16.610015
6           card5   1.592317
7           addr1   1.198956
8           addr2   1.887214
9           dist1   1.224757
-------------------------
eliminamos  V181  con VIF de:  154.48252161687967
         features  VIF_value
0   TransactionID  33.667517
1   TransactionDT  34.466224
2  TransactionAmt   1.433695
3           card1   1.259793
4           card2   1.317907
5           card3  16.609891
6           card5   1.592292
7           addr1   1.198665
8           addr2   1.887210
9           dist1   1.224460
-------------------------
eliminamos  V247  con VIF de:  141.96114957945196
         features  VIF_value
0   TransactionID  33.656577
1   TransactionDT  34.457601
2  TransactionAmt   1.433479
3           card1   1.259086
4           card2   1.317902
5           card3  16.518563
6           card5   1.591396
7           addr1   1.198500
8           addr2   1.850545
9           dist1   1.224353
-------------------------
eliminamos  id_35_T  con VIF de:  136.36749000787188
         features  VIF_value
0   TransactionID  33.656547
1   TransactionDT  34.456342
2  TransactionAmt   1.432919
3           card1   1.259073
4           card2   1.313481
5           card3  16.499297
6           card5   1.580391
7           addr1   1.197042
8           addr2   1.836510
9           dist1   1.224337
-------------------------
eliminamos  V324  con VIF de:  133.7416914105452
         features  VIF_value
0   TransactionID  33.640898
1   TransactionDT  34.439921
2  TransactionAmt   1.432261
3           card1   1.253780
4           card2   1.313441
5           card3  15.742926
6           card5   1.580227
7           addr1   1.195744
8           addr2   1.639104
9           dist1   1.224144
-------------------------
eliminamos  C14  con VIF de:  132.99669635145946
         features  VIF_value
0   TransactionID  33.640659
1   TransactionDT  34.438867
2  TransactionAmt   1.431773
3           card1   1.253263
4           card2   1.313321
5           card3  15.723110
6           card5   1.578342
7           addr1   1.195507
8           addr2   1.638924
9           dist1   1.224123
-------------------------
eliminamos  V58  con VIF de:  121.67696990983309
         features  VIF_value
0   TransactionID  33.635028
1   TransactionDT  34.432520
2  TransactionAmt   1.431361
3           card1   1.251712
4           card2   1.313032
5           card3  15.721324
6           card5   1.578137
7           addr1   1.193701
8           addr2   1.638269
9           dist1   1.224121
-------------------------
eliminamos  V222  con VIF de:  115.1370325606619
         features  VIF_value
0   TransactionID  33.604277
1   TransactionDT  34.412353
2  TransactionAmt   1.429383
3           card1   1.251105
4           card2   1.312975
5           card3  15.563522
6           card5   1.576770
7           addr1   1.193527
8           addr2   1.632996
9           dist1   1.223972
-------------------------
eliminamos  V318  con VIF de:  111.39935712892446
         features  VIF_value
0   TransactionID  33.600958
1   TransactionDT  34.403442
2  TransactionAmt   1.429268
3           card1   1.250678
4           card2   1.312495
5           card3  15.473284
6           card5   1.576186
7           addr1   1.193053
8           addr2   1.630620
9           dist1   1.223961
-------------------------
eliminamos  id_28_New  con VIF de:  108.02212894689708
         features  VIF_value
0   TransactionID  33.600616
1   TransactionDT  34.403366
2  TransactionAmt   1.428677
3           card1   1.250551
4           card2   1.312089
5           card3  15.470000
6           card5   1.575710
7           addr1   1.191662
8           addr2   1.630437
9           dist1   1.223961
-------------------------
eliminamos  V32  con VIF de:  101.3939222657321
         features  VIF_value
0   TransactionID  33.479943
1   TransactionDT  34.285884
2  TransactionAmt   1.428435
3           card1   1.250527
4           card2   1.311744
5           card3  15.334266
6           card5   1.573305
7           addr1   1.191552
8           addr2   1.553758
9           dist1   1.223960
-------------------------
eliminamos  V64  con VIF de:  97.57661534481852
         features  VIF_value
0   TransactionID  33.476249
1   TransactionDT  34.278614
2  TransactionAmt   1.428070
3           card1   1.250390
4           card2   1.311729
5           card3  15.251183
6           card5   1.572385
7           addr1   1.191495
8           addr2   1.550989
9           dist1   1.223915
-------------------------
eliminamos  V330  con VIF de:  77.99757511452896
         features  VIF_value
0   TransactionID  33.474965
1   TransactionDT  34.276742
2  TransactionAmt   1.428052
3           card1   1.249006
4           card2   1.310784
5           card3  15.241822
6           card5   1.565861
7           addr1   1.191396
8           addr2   1.543798
9           dist1   1.223907
-------------------------
eliminamos  V74  con VIF de:  75.23106486873394
         features  VIF_value
0   TransactionID  33.474963
1   TransactionDT  34.276734
2  TransactionAmt   1.427747
3           card1   1.248955
4           card2   1.310764
5           card3  15.241820
6           card5   1.559293
7           addr1   1.188597
8           addr2   1.539580
9           dist1   1.223907
-------------------------
eliminamos  V169  con VIF de:  72.71151761180367
         features  VIF_value
0   TransactionID  33.450918
1   TransactionDT  34.246435
2  TransactionAmt   1.427642
3           card1   1.248556
4           card2   1.310761
5           card3  14.856072
6           card5   1.558825
7           addr1   1.188581
8           addr2   1.535607
9           dist1   1.223906
-------------------------
eliminamos  V50  con VIF de:  72.30876647641826
         features  VIF_value
0   TransactionID  33.446521
1   TransactionDT  34.241732
2  TransactionAmt   1.427635
3           card1   1.245283
4           card2   1.310615
5           card3  14.829866
6           card5   1.558111
7           addr1   1.186280
8           addr2   1.529919
9           dist1   1.223711
-------------------------
eliminamos  V315  con VIF de:  70.36365913337214
         features  VIF_value
0   TransactionID  33.445221
1   TransactionDT  34.241437
2  TransactionAmt   1.427315
3           card1   1.244555
4           card2   1.307463
5           card3  14.826968
6           card5   1.555570
7           addr1   1.186218
8           addr2   1.529897
9           dist1   1.223711
-------------------------
eliminamos  V84  con VIF de:  66.85787284753754
         features  VIF_value
0   TransactionID  33.445073
1   TransactionDT  34.240994
2  TransactionAmt   1.426363
3           card1   1.244202
4           card2   1.307184
5           card3  14.826968
6           card5   1.554980
7           addr1   1.186146
8           addr2   1.529895
9           dist1   1.223666
-------------------------
eliminamos  V39  con VIF de:  57.99564473142266
         features  VIF_value
0   TransactionID  33.443081
1   TransactionDT  34.240877
2  TransactionAmt   1.426281
3           card1   1.243575
4           card2   1.307179
5           card3  14.806771
6           card5   1.554962
7           addr1   1.186003
8           addr2   1.520272
9           dist1   1.223658
-------------------------
eliminamos  V280  con VIF de:  57.58172584867834
         features  VIF_value
0   TransactionID  33.431248
1   TransactionDT  34.218108
2  TransactionAmt   1.426210
3           card1   1.240821
4           card2   1.306809
5           card3  14.580073
6           card5   1.554594
7           addr1   1.185361
8           addr2   1.519933
9           dist1   1.223521
-------------------------
eliminamos  V176  con VIF de:  55.67810953826119
         features  VIF_value
0   TransactionID  33.430109
1   TransactionDT  34.215734
2  TransactionAmt   1.424516
3           card1   1.236884
4           card2   1.305673
5           card3  14.574245
6           card5   1.554347
7           addr1   1.179681
8           addr2   1.519865
9           dist1   1.223150
-------------------------
eliminamos  V134  con VIF de:  53.97692730140447
         features  VIF_value
0   TransactionID  33.401469
1   TransactionDT  34.173068
2  TransactionAmt   1.424466
3           card1   1.236863
4           card2   1.305588
5           card3  14.514362
6           card5   1.553881
7           addr1   1.179639
8           addr2   1.518729
9           dist1   1.222941
-------------------------
eliminamos  V48  con VIF de:  53.664862228326456
         features  VIF_value
0   TransactionID  33.401220
1   TransactionDT  34.172859
2  TransactionAmt   1.396848
3           card1   1.236273
4           card2   1.305373
5           card3  14.503739
6           card5   1.553841
7           addr1   1.178982
8           addr2   1.518629
9           dist1   1.221995
-------------------------
eliminamos  V221  con VIF de:  53.45685549078912
         features  VIF_value
0   TransactionID  33.394445
1   TransactionDT  34.160745
2  TransactionAmt   1.396103
3           card1   1.230508
4           card2   1.305274
5           card3  14.502139
6           card5   1.552454
7           addr1   1.178072
8           addr2   1.518449
9           dist1   1.221763
-------------------------
eliminamos  card4_visa  con VIF de:  51.817117751792075
         features  VIF_value
0   TransactionID  33.385565
1   TransactionDT  34.153363
2  TransactionAmt   1.396041
3           card1   1.230326
4           card2   1.304849
5           card3  14.427969
6           card5   1.552301
7           addr1   1.177814
8           addr2   1.507814
9           dist1   1.221735
-------------------------
eliminamos  V335  con VIF de:  49.52242262021089
         features  VIF_value
0   TransactionID  33.349005
1   TransactionDT  34.103001
2  TransactionAmt   1.396036
3           card1   1.230266
4           card2   1.304847
5           card3  14.325168
6           card5   1.535615
7           addr1   1.177703
8           addr2   1.504244
9           dist1   1.221654
-------------------------
eliminamos  V261  con VIF de:  48.699909712716725
         features  VIF_value
0   TransactionID  33.333723
1   TransactionDT  34.082495
2  TransactionAmt   1.396029
3           card1   1.230160
4           card2   1.304115
5           card3  14.320071
6           card5   1.534475
7           addr1   1.177479
8           addr2   1.503796
9           dist1   1.221649
-------------------------
eliminamos  V69  con VIF de:  46.86554000318486
         features  VIF_value
0   TransactionID  33.332656
1   TransactionDT  34.082495
2  TransactionAmt   1.395890
3           card1   1.228342
4           card2   1.300494
5           card3  14.294248
6           card5   1.532844
7           addr1   1.175532
8           addr2   1.502963
9           dist1   1.221644
-------------------------
eliminamos  C6  con VIF de:  46.82467976650013
         features  VIF_value
0   TransactionID  33.177409
1   TransactionDT  33.956851
2  TransactionAmt   1.395271
3           card1   1.228341
4           card2   1.300250
5           card3  14.293966
6           card5   1.523591
7           addr1   1.174706
8           addr2   1.502924
9           dist1   1.221502
-------------------------
eliminamos  V190  con VIF de:  45.83488331195104
         features  VIF_value
0   TransactionID  33.164451
1   TransactionDT  33.949991
2  TransactionAmt   1.395271
3           card1   1.228116
4           card2   1.300114
5           card3  14.291514
6           card5   1.522921
7           addr1   1.174353
8           addr2   1.502576
9           dist1   1.220401
-------------------------
eliminamos  V251  con VIF de:  44.5518272907412
         features  VIF_value
0   TransactionID  33.132291
1   TransactionDT  33.921718
2  TransactionAmt   1.395165
3           card1   1.227838
4           card2   1.298152
5           card3  14.286297
6           card5   1.521479
7           addr1   1.174009
8           addr2   1.501649
9           dist1   1.220395
-------------------------
eliminamos  V317  con VIF de:  43.9520614192257
         features  VIF_value
0   TransactionID  33.129471
1   TransactionDT  33.920032
2  TransactionAmt   1.394277
3           card1   1.218384
4           card2   1.296324
5           card3  14.146163
6           card5   1.514985
7           addr1   1.173472
8           addr2   1.492292
9           dist1   1.220247
-------------------------
eliminamos  V235  con VIF de:  42.859228914800084
         features  VIF_value
0   TransactionID  33.118606
1   TransactionDT  33.912476
2  TransactionAmt   1.394269
3           card1   1.218166
4           card2   1.294698
5           card3  14.145341
6           card5   1.514399
7           addr1   1.173152
8           addr2   1.492270
9           dist1   1.220215
-------------------------
eliminamos  V29  con VIF de:  41.59257340773909
         features  VIF_value
0   TransactionID  33.090371
1   TransactionDT  33.879649
2  TransactionAmt   1.393862
3           card1   1.218146
4           card2   1.294660
5           card3  14.143644
6           card5   1.514397
7           addr1   1.173134
8           addr2   1.491198
9           dist1   1.220215
-------------------------
eliminamos  V140  con VIF de:  40.15972007006905
         features  VIF_value
0   TransactionID  33.080120
1   TransactionDT  33.873043
2  TransactionAmt   1.392383
3           card1   1.217848
4           card2   1.294266
5           card3  14.130174
6           card5   1.513301
7           addr1   1.173031
8           addr2   1.490854
9           dist1   1.220211
-------------------------
eliminamos  V93  con VIF de:  37.79512752593319
         features  VIF_value
0   TransactionID  33.078715
1   TransactionDT  33.872265
2  TransactionAmt   1.392349
3           card1   1.217742
4           card2   1.294266
5           card3  14.123269
6           card5   1.513300
7           addr1   1.173020
8           addr2   1.484885
9           dist1   1.220138
-------------------------
eliminamos  C13  con VIF de:  35.616221996523024
         features  VIF_value
0   TransactionID  33.078018
1   TransactionDT  33.872171
2  TransactionAmt   1.392328
3           card1   1.217733
4           card2   1.293845
5           card3  13.737259
6           card5   1.513162
7           addr1   1.172677
8           addr2   1.482692
9           dist1   1.220110
-------------------------
eliminamos  V170  con VIF de:  35.38245725191496
         features  VIF_value
0   TransactionID  33.057399
1   TransactionDT  33.867522
2  TransactionAmt   1.392311
3           card1   1.215315
4           card2   1.292956
5           card3  13.734749
6           card5   1.511942
7           addr1   1.172673
8           addr2   1.482687
9           dist1   1.219433
-------------------------
eliminamos  TransactionDT  con VIF de:  33.86401479960552
         features  VIF_value
0   TransactionID  33.054349
1   TransactionDT  33.864015
2  TransactionAmt   1.392310
3           card1   1.214960
4           card2   1.290360
5           card3  13.729934
6           card5   1.511838
7           addr1   1.172312
8           addr2   1.481057
9           dist1   1.219429
-------------------------
eliminamos  V159  con VIF de:  33.58914823906917
         features  VIF_value
0   TransactionID   1.538269
1  TransactionAmt   1.392307
2           card1   1.214690
3           card2   1.285805
4           card3  13.729917
5           card5   1.511165
6           addr1   1.171822
7           addr2   1.475525
8           dist1   1.219420
9              C3   2.630662
-------------------------
eliminamos  V234  con VIF de:  31.82650002536366
         features  VIF_value
0   TransactionID   1.509431
1  TransactionAmt   1.392134
2           card1   1.214628
3           card2   1.284867
4           card3  13.716168
5           card5   1.511155
6           addr1   1.171778
7           addr2   1.474619
8           dist1   1.219418
9              C3   2.589563
-------------------------
eliminamos  V270  con VIF de:  31.564778626471416
         features  VIF_value
0   TransactionID   1.508600
1  TransactionAmt   1.391879
2           card1   1.214509
3           card2   1.281481
4           card3  13.709360
5           card5   1.511114
6           addr1   1.171451
7           addr2   1.474547
8           dist1   1.219413
9              C3   2.513504
-------------------------
eliminamos  V298  con VIF de:  31.301503460658655
         features  VIF_value
0   TransactionID   1.508287
1  TransactionAmt   1.391876
2           card1   1.214406
3           card2   1.278881
4           card3  13.700016
5           card5   1.508379
6           addr1   1.171079
7           addr2   1.472954
8           dist1   1.219408
9              C3   2.512960
-------------------------
eliminamos  V116  con VIF de:  30.171511165368887
         features  VIF_value
0   TransactionID   1.505250
1  TransactionAmt   1.391876
2           card1   1.214091
3           card2   1.277720
4           card3  13.694000
5           card5   1.508359
6           addr1   1.168337
7           addr2   1.472954
8           dist1   1.219242
9              C3   2.512799
-------------------------
eliminamos  ProductCD_H  con VIF de:  29.70043822718912
         features  VIF_value
0   TransactionID   1.498402
1  TransactionAmt   1.391813
2           card1   1.210237
3           card2   1.277646
4           card3  13.693642
5           card5   1.508288
6           addr1   1.168294
7           addr2   1.472953
8           dist1   1.219241
9              C3   2.512754
-------------------------
eliminamos  V172  con VIF de:  28.231261793319508
         features  VIF_value
0   TransactionID   1.498325
1  TransactionAmt   1.391356
2           card1   1.209793
3           card2   1.277493
4           card3  13.243803
5           card5   1.507170
6           addr1   1.168277
7           addr2   1.463189
8           dist1   1.218924
9              C3   2.509420
-------------------------
eliminamos  V36  con VIF de:  25.48307906049843
         features  VIF_value
0   TransactionID   1.496739
1  TransactionAmt   1.390786
2           card1   1.204708
3           card2   1.277278
4           card3  13.142132
5           card5   1.506606
6           addr1   1.167796
7           addr2   1.457649
8           dist1   1.218834
9              C3   2.493037
-------------------------
eliminamos  V245  con VIF de:  24.74346057460479
         features  VIF_value
0   TransactionID   1.496574
1  TransactionAmt   1.390643
2           card1   1.204696
3           card2   1.277027
4           card3  13.141731
5           card5   1.504430
6           addr1   1.167429
7           addr2   1.457641
8           dist1   1.218419
9              C3   2.492950
-------------------------
eliminamos  V302  con VIF de:  23.945544311175436
         features  VIF_value
0   TransactionID   1.495928
1  TransactionAmt   1.390635
2           card1   1.203480
3           card2   1.277026
4           card3  12.990131
5           card5   1.503511
6           addr1   1.167425
7           addr2   1.453775
8           dist1   1.218344
9              C3   2.492859
-------------------------
eliminamos  V81  con VIF de:  23.25815122463274
         features  VIF_value
0   TransactionID   1.495268
1  TransactionAmt   1.389057
2           card1   1.199591
3           card2   1.276003
4           card3  12.971648
5           card5   1.503059
6           addr1   1.167361
7           addr2   1.453396
8           dist1   1.218207
9              C3   2.484363
-------------------------
eliminamos  V196  con VIF de:  22.99677004063644
         features  VIF_value
0   TransactionID   1.495268
1  TransactionAmt   1.389056
2           card1   1.199362
3           card2   1.275911
4           card3  12.963656
5           card5   1.500088
6           addr1   1.167361
7           addr2   1.451124
8           dist1   1.218172
9              C3   2.482534
-------------------------
eliminamos  id_15_New  con VIF de:  22.557774813655705
         features  VIF_value
0   TransactionID   1.494704
1  TransactionAmt   1.388826
2           card1   1.199228
3           card2   1.275835
4           card3  12.941301
5           card5   1.495169
6           addr1   1.167312
7           addr2   1.448970
8           dist1   1.218172
9              C3   2.477962
-------------------------
eliminamos  V127  con VIF de:  22.394297255411452
         features  VIF_value
0   TransactionID   1.481217
1  TransactionAmt   1.388535
2           card1   1.196813
3           card2   1.275426
4           card3  12.834677
5           card5   1.494838
6           addr1   1.166168
7           addr2   1.426772
8           dist1   1.218133
9              C3   2.476033
-------------------------
eliminamos  V297  con VIF de:  21.713901582670335
         features  VIF_value
0   TransactionID   1.480493
1  TransactionAmt   1.378556
2           card1   1.194695
3           card2   1.275413
4           card3  12.815294
5           card5   1.494657
6           addr1   1.165843
7           addr2   1.426575
8           dist1   1.218125
9              C3   2.475808
-------------------------
eliminamos  V52  con VIF de:  21.345711326768757
         features  VIF_value
0   TransactionID   1.480457
1  TransactionAmt   1.373147
2           card1   1.194121
3           card2   1.272937
4           card3  12.814723
5           card5   1.494350
6           addr1   1.163567
7           addr2   1.426383
8           dist1   1.216886
9              C3   2.475763
-------------------------
eliminamos  V309  con VIF de:  21.02992864977823
         features  VIF_value
0   TransactionID   1.477152
1  TransactionAmt   1.373032
2           card1   1.193595
3           card2   1.269478
4           card3  11.530528
5           card5   1.491816
6           addr1   1.163512
7           addr2   1.425810
8           dist1   1.216885
9              C3   2.475471
-------------------------
eliminamos  V287  con VIF de:  20.366721958914326
         features  VIF_value
0   TransactionID   1.474879
1  TransactionAmt   1.371850
2           card1   1.189017
3           card2   1.269235
4           card3  11.525675
5           card5   1.491810
6           addr1   1.163508
7           addr2   1.425778
8           dist1   1.216834
9              C3   2.475467
-------------------------
eliminamos  V300  con VIF de:  20.279313864876556
         features  VIF_value
0   TransactionID   1.474485
1  TransactionAmt   1.371623
2           card1   1.188189
3           card2   1.269220
4           card3  11.520059
5           card5   1.491810
6           addr1   1.162931
7           addr2   1.425769
8           dist1   1.216801
9              C3   2.475308
-------------------------
eliminamos  V338  con VIF de:  19.945791847169406
         features  VIF_value
0   TransactionID   1.474328
1  TransactionAmt   1.371264
2           card1   1.188185
3           card2   1.269158
4           card3  11.517297
5           card5   1.491550
6           addr1   1.162931
7           addr2   1.425443
8           dist1   1.214773
9              C3   2.475139
-------------------------
eliminamos  V91  con VIF de:  19.786036883503716
         features  VIF_value
0   TransactionID   1.474279
1  TransactionAmt   1.370919
2           card1   1.187197
3           card2   1.268788
4           card3  11.481070
5           card5   1.489619
6           addr1   1.161370
7           addr2   1.423516
8           dist1   1.214714
9              C3   2.436344
-------------------------
eliminamos  V227  con VIF de:  18.699632185336966
         features  VIF_value
0   TransactionID   1.473072
1  TransactionAmt   1.369547
2           card1   1.187167
3           card2   1.264760
4           card3  11.475930
5           card5   1.489274
6           addr1   1.160665
7           addr2   1.423039
8           dist1   1.214702
9              C3   2.436206
-------------------------
eliminamos  DeviceType_otro  con VIF de:  18.573949801361753
         features  VIF_value
0   TransactionID   1.470371
1  TransactionAmt   1.369435
2           card1   1.187139
3           card2   1.264128
4           card3  11.472534
5           card5   1.488358
6           addr1   1.160659
7           addr2   1.421806
8           dist1   1.214700
9              C3   2.433794
-------------------------
eliminamos  D1  con VIF de:  18.556721705964687
         features  VIF_value
0   TransactionID   1.469993
1  TransactionAmt   1.369431
2           card1   1.186910
3           card2   1.263445
4           card3  11.460764
5           card5   1.486904
6           addr1   1.160623
7           addr2   1.419451
8           dist1   1.214700
9              C3   2.389220
-------------------------
eliminamos  V60  con VIF de:  18.056737353841836
         features  VIF_value
0   TransactionID   1.467116
1  TransactionAmt   1.369094
2           card1   1.186774
3           card2   1.262393
4           card3  11.451840
5           card5   1.486864
6           addr1   1.160403
7           addr2   1.419444
8           dist1   1.212626
9              C3   2.389041
-------------------------
eliminamos  V95  con VIF de:  17.165008288072794
         features  VIF_value
0   TransactionID   1.465784
1  TransactionAmt   1.368988
2           card1   1.186656
3           card2   1.262350
4           card3  11.015331
5           card5   1.486404
6           addr1   1.160176
7           addr2   1.418692
8           dist1   1.212615
9              C3   2.389040
-------------------------
eliminamos  V38  con VIF de:  17.064295135184487
         features  VIF_value
0   TransactionID   1.465561
1  TransactionAmt   1.368935
2           card1   1.186583
3           card2   1.262342
4           card3  11.013716
5           card5   1.486050
6           addr1   1.160170
7           addr2   1.416466
8           dist1   1.212531
9              C3   2.388865
-------------------------
eliminamos  id_17  con VIF de:  16.714114700959268
         features  VIF_value
0   TransactionID   1.464074
1  TransactionAmt   1.368672
2           card1   1.186345
3           card2   1.262320
4           card3  11.010201
5           card5   1.485422
6           addr1   1.158048
7           addr2   1.416376
8           dist1   1.212432
9              C3   2.388830
-------------------------
eliminamos  V76  con VIF de:  16.256187364277856
         features  VIF_value
0   TransactionID   1.463191
1  TransactionAmt   1.368420
2           card1   1.186339
3           card2   1.262060
4           card3   8.674934
5           card5   1.484266
6           addr1   1.157610
7           addr2   1.239732
8           dist1   1.212166
9              C3   2.388775
-------------------------
eliminamos  DeviceInfo_Windows  con VIF de:  16.220121665636857
         features  VIF_value
0   TransactionID   1.462676
1  TransactionAmt   1.368403
2           card1   1.185934
3           card2   1.258558
4           card3   8.646163
5           card5   1.484188
6           addr1   1.153390
7           addr2   1.238649
8           dist1   1.212148
9              C3   2.388628
-------------------------
eliminamos  V320  con VIF de:  15.71884069214635
         features  VIF_value
0   TransactionID   1.462670
1  TransactionAmt   1.368346
2           card1   1.181120
3           card2   1.257943
4           card3   8.645956
5           card5   1.484183
6           addr1   1.152351
7           addr2   1.169559
8           dist1   1.212148
9              C3   2.388620
-------------------------
eliminamos  V61  con VIF de:  15.675529527394703
         features  VIF_value
0   TransactionID   1.462669
1  TransactionAmt   1.368346
2           card1   1.180991
3           card2   1.257502
4           card3   8.645869
5           card5   1.484068
6           addr1   1.152327
7           addr2   1.169518
8           dist1   1.212072
9              C3   2.387909
-------------------------
eliminamos  V174  con VIF de:  15.567232242500017
         features  VIF_value
0   TransactionID   1.462625
1  TransactionAmt   1.368263
2           card1   1.180991
3           card2   1.256662
4           card3   8.645279
5           card5   1.483746
6           addr1   1.147512
7           addr2   1.169517
8           dist1   1.209881
9              C3   2.387839
-------------------------
eliminamos  V125  con VIF de:  15.138651232302042
         features  VIF_value
0   TransactionID   1.460152
1  TransactionAmt   1.368224
2           card1   1.180913
3           card2   1.256422
4           card3   8.513294
5           card5   1.480218
6           addr1   1.146850
7           addr2   1.168644
8           dist1   1.209875
9              C3   2.385181
-------------------------
eliminamos  V135  con VIF de:  14.39794462435514
         features  VIF_value
0   TransactionID   1.459058
1  TransactionAmt   1.367727
2           card1   1.180833
3           card2   1.256206
4           card3   8.513072
5           card5   1.480192
6           addr1   1.146758
7           addr2   1.167977
8           dist1   1.209798
9              C3   2.378838
-------------------------
eliminamos  V77  con VIF de:  14.394960646262504
         features  VIF_value
0   TransactionID   1.458726
1  TransactionAmt   1.366289
2           card1   1.180809
3           card2   1.255529
4           card3   8.513069
5           card5   1.480071
6           addr1   1.146727
7           addr2   1.167974
8           dist1   1.209797
9              C3   2.378635
-------------------------
eliminamos  V12  con VIF de:  13.73173588042403
         features  VIF_value
0   TransactionID   1.458103
1  TransactionAmt   1.365317
2           card1   1.180756
3           card2   1.255402
4           card3   8.409308
5           card5   1.478263
6           addr1   1.146621
7           addr2   1.167968
8           dist1   1.208273
9              C3   2.378301
-------------------------
eliminamos  V193  con VIF de:  13.707697282637962
         features  VIF_value
0   TransactionID   1.456860
1  TransactionAmt   1.364927
2           card1   1.180574
3           card2   1.254089
4           card3   8.397642
5           card5   1.477705
6           addr1   1.144758
7           addr2   1.166936
8           dist1   1.208069
9              C3   2.378186
-------------------------
eliminamos  V131  con VIF de:  13.256513296131262
         features  VIF_value
0   TransactionID   1.454494
1  TransactionAmt   1.364922
2           card1   1.180436
3           card2   1.253389
4           card3   8.391708
5           card5   1.477576
6           addr1   1.144749
7           addr2   1.166506
8           dist1   1.208058
9              C3   2.322992
-------------------------
eliminamos  V43  con VIF de:  13.177009843607626
         features  VIF_value
0   TransactionID   1.453687
1  TransactionAmt   1.355704
2           card1   1.179632
3           card2   1.252789
4           card3   8.391382
5           card5   1.477364
6           addr1   1.143904
7           addr2   1.166493
8           dist1   1.208051
9              C3   2.322754
-------------------------
eliminamos  V331  con VIF de:  12.114353918913094
         features  VIF_value
0   TransactionID   1.451989
1  TransactionAmt   1.355701
2           card1   1.179626
3           card2   1.250723
4           card3   8.216249
5           card5   1.476735
6           addr1   1.141698
7           addr2   1.165902
8           dist1   1.208009
9              C3   2.310220
-------------------------
eliminamos  V20  con VIF de:  11.865224837715134
         features  VIF_value
0   TransactionID   1.451988
1  TransactionAmt   1.355688
2           card1   1.176988
3           card2   1.250682
4           card3   8.209568
5           card5   1.473358
6           addr1   1.141696
7           addr2   1.165204
8           dist1   1.208007
9              C3   2.303161
-------------------------
eliminamos  V30  con VIF de:  11.47539647390508
         features  VIF_value
0   TransactionID   1.450546
1  TransactionAmt   1.355593
2           card1   1.176851
3           card2   1.250494
4           card3   8.194188
5           card5   1.473357
6           addr1   1.141649
7           addr2   1.165094
8           dist1   1.208007
9              C3   2.303160
-------------------------
eliminamos  V72  con VIF de:  11.374810231773223
         features  VIF_value
0   TransactionID   1.449873
1  TransactionAmt   1.355592
2           card1   1.176764
3           card2   1.248941
4           card3   8.193661
5           card5   1.472961
6           addr1   1.140935
7           addr2   1.165074
8           dist1   1.207928
9              C3   2.302993
-------------------------
eliminamos  V294  con VIF de:  10.788249390484841
         features  VIF_value
0   TransactionID   1.449823
1  TransactionAmt   1.354643
2           card1   1.176182
3           card2   1.246349
4           card3   6.130167
5           card5   1.472326
6           addr1   1.140804
7           addr2   1.165065
8           dist1   1.207862
9              C3   2.302947
-------------------------
eliminamos  V288  con VIF de:  10.73430876927588
         features  VIF_value
0   TransactionID   1.448554
1  TransactionAmt   1.352681
2           card1   1.175624
3           card2   1.242319
4           card3   6.129259
5           card5   1.470860
6           addr1   1.136079
7           addr2   1.164958
8           dist1   1.206587
9              C3   2.302929
-------------------------
eliminamos  id_31_ie 11.0 for desktop  con VIF de:  10.681839160015105
         features  VIF_value
0   TransactionID   1.448258
1  TransactionAmt   1.341483
2           card1   1.175484
3           card2   1.242318
4           card3   6.127120
5           card5   1.470630
6           addr1   1.134592
7           addr2   1.164958
8           dist1   1.206567
9              C3   2.301090
-------------------------
eliminamos  V44  con VIF de:  10.327379262288128
         features  VIF_value
0   TransactionID   1.444656
1  TransactionAmt   1.341432
2           card1   1.175452
3           card2   1.241954
4           card3   6.110527
5           card5   1.470481
6           addr1   1.134519
7           addr2   1.163872
8           dist1   1.206551
9              C3   2.254969
-------------------------
eliminamos  C5  con VIF de:  9.966232177309307
         features  VIF_value
0   TransactionID   1.444287
1  TransactionAmt   1.341360
2           card1   1.172952
3           card2   1.241339
4           card3   6.106872
5           card5   1.470467
6           addr1   1.132969
7           addr2   1.162795
8           dist1   1.206543
9              C3   2.254097
-------------------------
eliminamos  P_emaildomain_gmail.com  con VIF de:  9.88744436731282
         features  VIF_value
0   TransactionID   1.442961
1  TransactionAmt   1.341205
2           card1   1.171338
3           card2   1.241177
4           card3   6.106869
5           card5   1.469839
6           addr1   1.132637
7           addr2   1.162790
8           dist1   1.201174
9              C3   2.254075
-------------------------
eliminamos  V53  con VIF de:  9.686504707472592
         features  VIF_value
0   TransactionID   1.442643
1  TransactionAmt   1.339174
2           card1   1.171214
3           card2   1.240849
4           card3   6.106816
5           card5   1.469637
6           addr1   1.132229
7           addr2   1.162656
8           dist1   1.201104
9              C3   2.253806
-------------------------
eliminamos  V220  con VIF de:  9.598476682315207
         features  VIF_value
0   TransactionID   1.442520
1  TransactionAmt   1.338827
2           card1   1.171133
3           card2   1.239584
4           card3   6.096491
5           card5   1.469418
6           addr1   1.131437
7           addr2   1.157108
8           dist1   1.200053
9              C3   2.253330
-------------------------
eliminamos  V99  con VIF de:  8.995591135285682
         features  VIF_value
0   TransactionID   1.441965
1  TransactionAmt   1.338697
2           card1   1.168718
3           card2   1.239569
4           card3   6.035396
5           card5   1.468559
6           addr1   1.131164
7           addr2   1.155994
8           dist1   1.200020
9              C3   2.253253
-------------------------
eliminamos  V195  con VIF de:  8.70687904168498
         features  VIF_value
0   TransactionID   1.434159
1  TransactionAmt   1.336114
2           card1   1.166494
3           card2   1.239476
4           card3   6.034685
5           card5   1.466475
6           addr1   1.130927
7           addr2   1.155963
8           dist1   1.199645
9              C3   2.252214
-------------------------
eliminamos  V158  con VIF de:  8.521702105329256
         features  VIF_value
0   TransactionID   1.426925
1  TransactionAmt   1.335380
2           card1   1.164194
3           card2   1.235629
4           card3   6.031489
5           card5   1.463614
6           addr1   1.130791
7           addr2   1.153896
8           dist1   1.199593
9              C3   2.243110
-------------------------
eliminamos  id_29_NotFound  con VIF de:  8.512999362992023
         features  VIF_value
0   TransactionID   1.386527
1  TransactionAmt   1.335173
2           card1   1.163496
3           card2   1.235145
4           card3   5.991684
5           card5   1.461078
6           addr1   1.128621
7           addr2   1.138003
8           dist1   1.199391
9              C3   2.229771
-------------------------
eliminamos  V46  con VIF de:  8.506276813050102
         features  VIF_value
0   TransactionID   1.385350
1  TransactionAmt   1.333781
2           card1   1.161837
3           card2   1.232159
4           card3   5.972408
5           card5   1.460861
6           addr1   1.126965
7           addr2   1.133337
8           dist1   1.198231
9              C3   2.227900
-------------------------
eliminamos  V82  con VIF de:  8.412871000331
         features  VIF_value
0   TransactionID   1.384732
1  TransactionAmt   1.332401
2           card1   1.161790
3           card2   1.231562
4           card3   5.968898
5           card5   1.460818
6           addr1   1.126291
7           addr2   1.133253
8           dist1   1.198204
9              C3   2.227807
-------------------------
eliminamos  V210  con VIF de:  8.114817644523308
         features  VIF_value
0   TransactionID   1.384371
1  TransactionAmt   1.332400
2           card1   1.161532
3           card2   1.230852
4           card3   5.966445
5           card5   1.460402
6           addr1   1.126085
7           addr2   1.133099
8           dist1   1.198093
9              C3   2.227480
-------------------------
eliminamos  V290  con VIF de:  7.96056391375235
         features  VIF_value
0   TransactionID   1.383865
1  TransactionAmt   1.332369
2           card1   1.161524
3           card2   1.227325
4           card3   5.966424
5           card5   1.452171
6           addr1   1.125982
7           addr2   1.132504
8           dist1   1.198092
9              C3   2.226953
-------------------------
eliminamos  V90  con VIF de:  7.404264780793707
         features  VIF_value
0   TransactionID   1.380144
1  TransactionAmt   1.332282
2           card1   1.161200
3           card2   1.226652
4           card3   5.963145
5           card5   1.447627
6           addr1   1.125957
7           addr2   1.132491
8           dist1   1.196778
9              C3   2.223438
-------------------------
eliminamos  DeviceInfo_iOS Device  con VIF de:  7.222563752559045
         features  VIF_value
0   TransactionID   1.380125
1  TransactionAmt   1.331860
2           card1   1.159008
3           card2   1.220765
4           card3   5.962980
5           card5   1.446826
6           addr1   1.124272
7           addr2   1.132490
8           dist1   1.196750
9              C3   2.223404
-------------------------
eliminamos  ProductCD_R  con VIF de:  7.0051084449855345
         features  VIF_value
0   TransactionID   1.379528
1  TransactionAmt   1.331747
2           card1   1.158983
3           card2   1.219748
4           card3   5.962752
5           card5   1.446739
6           addr1   1.124259
7           addr2   1.131214
8           dist1   1.196734
9              C3   2.222669
-------------------------
eliminamos  V299  con VIF de:  6.836700299658739
         features  VIF_value
0   TransactionID   1.373416
1  TransactionAmt   1.331747
2           card1   1.158690
3           card2   1.219720
4           card3   5.859030
5           card5   1.446705
6           addr1   1.123572
7           addr2   1.128563
8           dist1   1.196552
9              C3   2.218204
-------------------------
eliminamos  V239  con VIF de:  6.57159839161204
         features  VIF_value
0   TransactionID   1.372954
1  TransactionAmt   1.317238
2           card1   1.158682
3           card2   1.219109
4           card3   5.851553
5           card5   1.446389
6           addr1   1.123565
7           addr2   1.128309
8           dist1   1.196552
9              C3   2.218133
-------------------------
eliminamos  V122  con VIF de:  6.51903430318997
         features  VIF_value
0   TransactionID   1.370662
1  TransactionAmt   1.317203
2           card1   1.157910
3           card2   1.217804
4           card3   5.844802
5           card5   1.443103
6           addr1   1.123362
7           addr2   1.128273
8           dist1   1.196552
9              C3   2.162908
-------------------------
eliminamos  V303  con VIF de:  6.38370815137876
         features  VIF_value
0   TransactionID   1.367100
1  TransactionAmt   1.316607
2           card1   1.157444
3           card2   1.217743
4           card3   5.844335
5           card5   1.443017
6           addr1   1.123067
7           addr2   1.128036
8           dist1   1.196552
9              C3   2.161613
-------------------------
eliminamos  V316  con VIF de:  6.330453405661963
         features  VIF_value
0   TransactionID   1.342650
1  TransactionAmt   1.316073
2           card1   1.157390
3           card2   1.216515
4           card3   5.840496
5           card5   1.441755
6           addr1   1.122994
7           addr2   1.117586
8           dist1   1.196060
9              C3   2.148043
-------------------------
eliminamos  V282  con VIF de:  6.251564194077829
         features  VIF_value
0   TransactionID   1.342232
1  TransactionAmt   1.311706
2           card1   1.157378
3           card2   1.216280
4           card3   5.840039
5           card5   1.441633
6           addr1   1.122747
7           addr2   1.117532
8           dist1   1.196060
9              C3   2.147627
-------------------------
eliminamos  V171  con VIF de:  5.950316574552438
         features  VIF_value
0   TransactionID   1.342131
1  TransactionAmt   1.311705
2           card1   1.156624
3           card2   1.215605
4           card3   5.839688
5           card5   1.438238
6           addr1   1.119192
7           addr2   1.117490
8           dist1   1.192666
9              C3   2.147400
-------------------------
eliminamos  R_emaildomain_gmail.com  con VIF de:  5.928259178777398
         features  VIF_value
0   TransactionID   1.341539
1  TransactionAmt   1.311689
2           card1   1.156624
3           card2   1.214317
4           card3   5.828300
5           card5   1.437811
6           addr1   1.119134
7           addr2   1.116801
8           dist1   1.192664
9              C3   2.144189
-------------------------
eliminamos  V312  con VIF de:  5.761792716823003
         features  VIF_value
0   TransactionID   1.337188
1  TransactionAmt   1.311535
2           card1   1.156464
3           card2   1.214270
4           card3   5.716182
5           card5   1.437210
6           addr1   1.118335
7           addr2   1.114719
8           dist1   1.192283
9              C3   2.144169
-------------------------
eliminamos  card3  con VIF de:  5.715901167241164
         features  VIF_value
0   TransactionID   1.337133
1  TransactionAmt   1.309736
2           card1   1.156433
3           card2   1.209366
4           card3   5.715901
5           card5   1.433677
6           addr1   1.118301
7           addr2   1.114718
8           dist1   1.191432
9              C3   2.144125
-------------------------
eliminamos  V260  con VIF de:  5.547547530469418
         features  VIF_value
0   TransactionID   1.334470
1  TransactionAmt   1.308516
2           card1   1.155287
3           card2   1.208773
4           card5   1.407100
5           addr1   1.118222
6           addr2   1.108521
7           dist1   1.191058
8              C3   2.144124
9              C7   3.414736
-------------------------
eliminamos  V103  con VIF de:  5.5077980702508995
         features  VIF_value
0   TransactionID   1.332789
1  TransactionAmt   1.308424
2           card1   1.154338
3           card2   1.208236
4           card5   1.404865
5           addr1   1.117974
6           addr2   1.108460
7           dist1   1.191038
8              C3   2.117724
9              C7   3.409843
-------------------------
eliminamos  V56  con VIF de:  5.3487235535449384
         features  VIF_value
0   TransactionID   1.329726
1  TransactionAmt   1.305300
2           card1   1.152704
3           card2   1.207726
4           card5   1.403138
5           addr1   1.112894
6           addr2   1.108147
7           dist1   1.190899
8              C3   2.117719
9              C7   3.409437
-------------------------
eliminamos  V313  con VIF de:  5.26187460680456
         features  VIF_value
0   TransactionID   1.316355
1  TransactionAmt   1.304582
2           card1   1.152637
3           card2   1.207398
4           card5   1.402510
5           addr1   1.112646
6           addr2   1.108147
7           dist1   1.190898
8              C3   2.117596
9              C7   3.409131
-------------------------
eliminamos  V256  con VIF de:  5.017493765701965
         features  VIF_value
0   TransactionID   1.316112
1  TransactionAmt   1.283972
2           card1   1.152522
3           card2   1.206521
4           card5   1.402175
5           addr1   1.112124
6           addr2   1.108118
7           dist1   1.190861
8              C3   2.117514
9              C7   3.399166
-------------------------
Ya no hay valores vif mayores a 5
         features  VIF_value
0   TransactionID   1.316005
1  TransactionAmt   1.283922
2           card1   1.151325
3           card2   1.205288
4           card5   1.402124
5           addr1   1.112121
6           addr2   1.107982
7           dist1   1.190845
8              C3   2.117513
9              C7   3.396869
</pre></div>
</div>
</div>
</div>
<p>capturamos las features o columnas que sobrevivieron a la limpieza VIF</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span><span class="o">=</span><span class="n">vif</span><span class="o">.</span><span class="n">features</span>
</pre></div>
</div>
</div>
</div>
<p>Las almacenamos en un .csv por seguridad (Por si se resetea el kernel)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vif</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;lastviff.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vif</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;lastviff.csv&#39;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finalmente definimos nuestro dataset X, con la data obtenida despues del OHE, pero solo con las <code class="docutils literal notranslate"><span class="pre">features</span></code> que sobrevivieron a la prueba VIF</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="n">vif</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;X.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Así quedó el dataset que usaremos para trabajar los modelos de ML</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(99999, 147)
</pre></div>
</div>
</div>
</div>
</section>
<section id="one-hot-encoder-para-variables-categoricas">
<h3>One Hot Encoder para variables categóricas<a class="headerlink" href="#one-hot-encoder-para-variables-categoricas" title="Permalink to this heading">#</a></h3>
<p>Para implimentar varios de los modelos lineales de ML, es necesario que todas las variables estén en forma numérica y escalada. Para lo cual, procederemos a aplicar la técnica One Hot Encoder para convertir las variables categóricas en columnas de <code class="docutils literal notranslate"><span class="pre">0</span></code> y <code class="docutils literal notranslate"><span class="pre">1</span></code></p>
</section>
</section>
<section id="evaluando-modelos-de-clasificacion-fraude">
<h2>EVALUANDO MODELOS DE CLASIFICACION - FRAUDE<a class="headerlink" href="#evaluando-modelos-de-clasificacion-fraude" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>KNN</p></li>
<li><p>Ridge</p></li>
<li><p>Lasso</p></li>
<li><p>Naive Bayes</p></li>
<li><p>XGBoost</p></li>
<li><p>SVM</p></li>
<li><p>MLP</p></li>
</ol>
<p>creados los dataframes <code class="docutils literal notranslate"><span class="pre">predictions</span></code> y <code class="docutils literal notranslate"><span class="pre">metrics</span></code>, para guardar los resultados arrojados por los modelos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;metrics.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span> <span class="c1">#Dataframe para guardar las predicciones de los modelos</span>
<span class="n">metrics</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<p>Realizamos la partición de los datos de training-validacion y de testing. Nos aseguramos que esta división sea estratificada, ya que, como vimos antes, las clases están desbalanceadas. De esta manera nos aseguramos que la proporción se conserve en las diferentes particiones.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Debe ser estratificada para que se conserve la proporción entre las clases, que ya verificamos que están desbalanceadas</span>
<span class="n">X_trainval</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_trainval</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">66</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="oversampling">
<h3>OVERSAMPLING<a class="headerlink" href="#oversampling" title="Permalink to this heading">#</a></h3>
<p>Para compensar el fuerte desbalance entre las clases, aplicamos Oversampling con diferentes tecnicas:
Para este examen, probamos la técnica <code class="docutils literal notranslate"><span class="pre">SMOTE</span></code>, <code class="docutils literal notranslate"><span class="pre">RandomOverSampler</span></code>, y <code class="docutils literal notranslate"><span class="pre">ADASYN</span></code>.</p>
<p>La que nos dió mejores resultados con el modelo KNN fue la <code class="docutils literal notranslate"><span class="pre">ADASYN</span></code>. Por lo que preferí dejar el analisis realizado con esta tecnica.</p>
<p><em>NOTA</em> Esta tecnica de oversampling la aplicamos solamente al set de training-validación, y no tocamos la partición de prueba.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">ADASYN</span>

<span class="c1">#smote=SMOTE(random_state=42)</span>
<span class="c1">#ros=RandomOverSampler(random_state=42)</span>
<span class="n">adasyn</span> <span class="o">=</span> <span class="n">ADASYN</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#X_trainval_resampled, y_trainval_resampled=smote.fit_resample(X_trainval,y_trainval)</span>
<span class="c1">#X_trainval_resampled, y_trainval_resampled=ros.fit_resample(X_trainval,y_trainval)</span>
<span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="o">=</span><span class="n">adasyn</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_trainval</span><span class="p">,</span><span class="n">y_trainval</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Luego de la tecnica oversampling, lógicamente el tamaño de nuestra data aumentó.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_trainval_resampled</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(146460, 147)
</pre></div>
</div>
</div>
</div>
<p>Probemos la efectividad de la tecnica, graficando nuevamente las clases.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Hagamos una gráfica para conocer el nuevo balance de las categorias</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">y_trainval_resampled</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Valor de la Variable Objetivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frecuencia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribucion de categorias despues de ADASYN&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Rotar las etiquetas del eje x si es necesario</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7e642d287baa648dde5f59f5fd7961efe4ffd999bb6b3336f5e9d8a6a387b894.png" src="_images/7e642d287baa648dde5f59f5fd7961efe4ffd999bb6b3336f5e9d8a6a387b894.png" />
</div>
</div>
<p>Ya estamos listos para empezar a entrenar los modelos.</p>
</section>
<section id="modelo-knn-clasificador">
<h3>Modelo KNN - Clasificador<a class="headerlink" href="#modelo-knn-clasificador" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
</pre></div>
</div>
</div>
</div>
<p>Instanciamos <em>el modelo</em>, <em>el escalador</em>, <em>el gridsearchCV</em> y el <em>Pipeline</em> a utilizar.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;K-NN&#39;</span> <span class="c1">#Esto es para la tabla final de metricas</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">escaler</span><span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;clf__n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">]}</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;escaler&#39;</span><span class="p">,</span> <span class="n">escaler</span> <span class="p">),</span> <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span><span class="n">clf</span><span class="p">)])</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)</span> <span class="c1">#Con ros</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-16" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, MinMaxScaler()),
                                       (&#x27;clf&#x27;, KNeighborsClassifier())]),
             param_grid={&#x27;clf__n_neighbors&#x27;: [5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-52" type="checkbox" ><label for="sk-estimator-id-52" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, MinMaxScaler()),
                                       (&#x27;clf&#x27;, KNeighborsClassifier())]),
             param_grid={&#x27;clf__n_neighbors&#x27;: [5, 10]})</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-53" type="checkbox" ><label for="sk-estimator-id-53" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;escaler&#x27;, MinMaxScaler()), (&#x27;clf&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-54" type="checkbox" ><label for="sk-estimator-id-54" class="sk-toggleable__label sk-toggleable__label-arrow">MinMaxScaler</label><div class="sk-toggleable__content"><pre>MinMaxScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-55" type="checkbox" ><label for="sk-estimator-id-55" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsClassifier</label><div class="sk-toggleable__content"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params:
{&#39;clf__n_neighbors&#39;: 5}

Best cross-validation score: 0.97
Test-set score: 0.94
Train-set score: 0.99
</pre></div>
</div>
</div>
</div>
<p>Estas metricas nos indican que este modelo tiene un <strong>accuracy muy alto</strong>, es decir que la proporcion de preducciones correctas vs las totales, es muy buena.</p>
<p>Sin embargo, para el objetivo del estudio, debemos mirar <strong>mas a fondo</strong>, ya que queremos ver el rendimiento de este modelo <strong>respecto a cada clase</strong>. En particular nos interesa detectar las transacciones <em>realmente fraudulentas</em>, es decir, el modelo que queremos debería ser muy bueno para predecir la <code class="docutils literal notranslate"><span class="pre">clase</span> <span class="pre">1</span></code>.</p>
<section id="evaluando-el-modelo">
<h4>Evaluando el modelo<a class="headerlink" href="#evaluando-el-modelo" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span><span class="n">auc</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span><span class="n">roc_auc_score</span><span class="p">,</span><span class="n">f1_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#predicciones</span>
<span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;KNNcls&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">KNNcls</span>
<span class="n">y_score</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#metricas</span>
<span class="n">cm</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precission</span><span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span><span class="o">=</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">fscore</span><span class="o">=</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc_score</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="c1">#creando el dataset de metricas</span>
<span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">precission</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span><span class="n">fscore</span><span class="p">,</span><span class="n">auc_score</span><span class="p">]</span> <span class="c1">#Guarda en df de metricas</span>
<span class="n">metricas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precission&#39;</span><span class="p">,</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span><span class="s1">&#39;auc_score&#39;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">metricas</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># funcion para matriz de confusion</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="k">def</span> <span class="nf">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Clase </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicciones&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Valores Verdaderos&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Matriz de Confusión Modelo &#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># Agrega esta línea si deseas mostrar la gráfica inmediatamente</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4dbd9c0eca299f8303dacaa33ab280f985abeb2a2775e04e8d49833ec8734b43.png" src="_images/4dbd9c0eca299f8303dacaa33ab280f985abeb2a2775e04e8d49833ec8734b43.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">report</span><span class="o">=</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       0.99      0.95      0.97     24360
         1.0       0.26      0.63      0.36       640

    accuracy                           0.94     25000
   macro avg       0.62      0.79      0.67     25000
weighted avg       0.97      0.94      0.96     25000
</pre></div>
</div>
</div>
</div>
<p><strong>ANALISIS</strong></p>
<ul class="simple">
<li><p>Viendo esta matriz es facil entender por qué el modelo nos arroja una alta accuracy, puesto que en la diagonal principal podemos encontrar que la mayoría de las predicciones son correctas, sin embargo, <em>teniendo en cuenta que nuestro dataset con los datos originales esta desequilibrado</em>, era de esperarse que el modelo fuera muy bueno para predecir la clase mayoritaria <code class="docutils literal notranslate"><span class="pre">clase</span> <span class="pre">0</span></code>. Las predicciones de la <code class="docutils literal notranslate"><span class="pre">clase</span> <span class="pre">1</span></code> aun no son muy buenas, hay muchos Falsos Positivos, sin embargo, para efectos monetarios, podemos decir que el modelo es <em>seguro</em></p></li>
<li><p>Sin embargo, aunque nuestro objetivo sea indetificar la <code class="docutils literal notranslate"><span class="pre">clase</span> <span class="pre">1</span></code>, y dentro de estas predicciones (que no son tan precisas), para el negocio bancario, es importante <strong>minimizar</strong> los <em>Falsos Negativos</em>. Es decir, transacciones que el modelo clasifica como <code class="docutils literal notranslate"><span class="pre">No</span> <span class="pre">Fraudulentas</span></code> <strong>pero que en realidad sí lo son</strong>, económicamente esto es catastrófico y ocasionadira pérdidas de dinero, debemos siempre enfocarnos en el <em>recall</em>, y alto valor de <em>recall</em>, nos indica que la tasa de falsos negativos es muy baja.</p></li>
<li><p>Por otro lado, los <em>Falsos Positivos</em> tampoco son deseados (y estan bastante altos) pero sus consecuencias <strong>no serían tan graves</strong>, pues se podría implementar verificaciones por parte del usuario para confirmar una transaccion sospechosa.</p></li>
</ul>
<p><strong>CONCLUSION</strong></p>
<ul class="simple">
<li><p>Teniendo en cuenta todo lo anterior, en este caso necesitamos enfocarnos en el <code class="docutils literal notranslate"><span class="pre">recall</span></code> para la <strong>clase 0</strong>.
Puesto que un falso negativo podría costar <strong>Dinero</strong>, mientras que muchos Falsos positivos, genera un modelo paranoico, su consecuencia sería incomodar a los clientes. Peca por demasiado prevenido. En este sentido, podemos decir que el modelo funciona muy bien, puesto que Recall de la clase 0 es 95.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Visualizacion Curva ROC</span>
<span class="k">def</span> <span class="nf">grafico_curvaROC</span> <span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grafico_curvaROC</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2568d7698ca75dd928c41ec7685e17d3620758ed3752f0e3f52b946c9c7afd18.png" src="_images/2568d7698ca75dd928c41ec7685e17d3620758ed3752f0e3f52b946c9c7afd18.png" />
</div>
</div>
<p><strong>INSIGHTS</strong>
La curva ROC muestra que la tasa de Verdaderos positivos es inferior al 80%, el área bajo la curva sin embargo, es 0.83/1, lo cual no es un mal resultado general.</p>
</section>
</section>
<section id="modelo-ridge">
<h3>MODELO RIDGE<a class="headerlink" href="#modelo-ridge" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifier</span>
</pre></div>
</div>
</div>
</div>
<p>Instanciamos el modelo definimos el gridsearchCV y el pipeline para el proceso.
Usamos los parámetros <code class="docutils literal notranslate"><span class="pre">alpha</span></code> (fuerza de la regularización) y <code class="docutils literal notranslate"><span class="pre">max_iter</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;Ridge&#39;</span> <span class="c1">#Esto es para la tabla final de metricas</span>
<span class="n">ridge_clas</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span>
<span class="n">escaler</span><span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ridge_clas__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
              <span class="s1">&#39;ridge_clas__max_iter&#39;</span><span class="p">:[</span><span class="mi">20</span><span class="p">,</span><span class="mi">50</span><span class="p">]}</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;escaler&#39;</span><span class="p">,</span> <span class="n">escaler</span> <span class="p">),</span> <span class="p">(</span><span class="s1">&#39;ridge_clas&#39;</span><span class="p">,</span><span class="n">ridge_clas</span><span class="p">)])</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Entrenamos el modelo</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-17" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;ridge_clas&#x27;, RidgeClassifier())]),
             param_grid={&#x27;ridge_clas__alpha&#x27;: [0.01, 1, 10],
                         &#x27;ridge_clas__max_iter&#x27;: [20, 50]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-56" type="checkbox" ><label for="sk-estimator-id-56" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;ridge_clas&#x27;, RidgeClassifier())]),
             param_grid={&#x27;ridge_clas__alpha&#x27;: [0.01, 1, 10],
                         &#x27;ridge_clas__max_iter&#x27;: [20, 50]})</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-57" type="checkbox" ><label for="sk-estimator-id-57" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                (&#x27;ridge_clas&#x27;, RidgeClassifier())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-58" type="checkbox" ><label for="sk-estimator-id-58" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-59" type="checkbox" ><label for="sk-estimator-id-59" class="sk-toggleable__label sk-toggleable__label-arrow">RidgeClassifier</label><div class="sk-toggleable__content"><pre>RidgeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params:
{&#39;ridge_clas__alpha&#39;: 1, &#39;ridge_clas__max_iter&#39;: 20}

Best cross-validation score: 0.79
Test-set score: 0.79
Train-set score: 0.79
</pre></div>
</div>
</div>
</div>
<p>Revisamos los mejores parámetros encontrados para el modelo, los cuales nos ofrecieron un score regular en la validación cruzada, y tanto en los sets de training y testing.  Como sabemos, por lo descrito anteriormente, no podemos juzgar el modelo a prior, solo con estos datos, vamos a mirar un poco mas a detalle como funciona y si es bueno o no para lo que nos interesa, que es la predicción correcta de la <code class="docutils literal notranslate"><span class="pre">clase</span> <span class="pre">0</span></code>. Es decir, la tasa de <em>Falsos Negativos</em>.</p>
<section id="id1">
<h4>Evaluando el modelo<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h4>
<p>Acumulamos las predicciones en el df predictions y lo guardamos como .csv para asegurarlo en caso que falla del sistema.
Además calculamos las métricas solicitadas y las almacenamos en el df metrics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;Ridge&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">Ridge</span>
<span class="n">y_score</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#metricas</span>
<span class="n">cm</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precission</span><span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span><span class="o">=</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">fscore</span><span class="o">=</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc_score</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="c1">#creando el dataset de metricas</span>
<span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">precission</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span><span class="n">fscore</span><span class="p">,</span><span class="n">auc_score</span><span class="p">]</span> <span class="c1">#Guarda en df de metricas</span>
<span class="n">metricas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precission&#39;</span><span class="p">,</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span><span class="s1">&#39;auc_score&#39;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">metricas</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precission</th>
      <th>recall</th>
      <th>f1_score</th>
      <th>auc_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>K-NN</th>
      <td>0.256671</td>
      <td>0.631250</td>
      <td>0.364950</td>
      <td>0.826935</td>
    </tr>
    <tr>
      <th>Ridge</th>
      <td>0.086051</td>
      <td>0.729688</td>
      <td>0.153948</td>
      <td>0.845046</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1dbfda095be7884352a0d7ebd5a6a4d5781a7277483e362ab814c049dfb7f749.png" src="_images/1dbfda095be7884352a0d7ebd5a6a4d5781a7277483e362ab814c049dfb7f749.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grafico_curvaROC</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d8d5b2517de7233cf53f61ef1f1ce44606b86c764673e4cb282ad5182e340f76.png" src="_images/d8d5b2517de7233cf53f61ef1f1ce44606b86c764673e4cb282ad5182e340f76.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">report</span><span class="o">=</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       0.99      0.80      0.88     24360
         1.0       0.09      0.73      0.15       640

    accuracy                           0.79     25000
   macro avg       0.54      0.76      0.52     25000
weighted avg       0.97      0.79      0.86     25000
</pre></div>
</div>
</div>
</div>
<p>Este modelo muestra una ligera mejoría en cuando al área bajo la curva, y demostrando mejor habilidad para predecir la clase 1 en detrimento de la predicción de la clase 0.</p>
<p>Para nuestro propósito, no resulta muy conveniente que se aumenten los falsos negativos, por lo que la disminución en el recall de la clase 0, genera pérdidas para la empresa.</p>
</section>
</section>
<section id="modelo-lasso-regresion-logistica-con-regularizacion-l1">
<h3>MODELO LASSO - Regresión Logística con Regularización L1<a class="headerlink" href="#modelo-lasso-regresion-logistica-con-regularizacion-l1" title="Permalink to this heading">#</a></h3>
<p>Para los problemas de clasificación binaria, no está definido un modelo LASSO, sino que utilizamos la Regresion Logística y le aplicamos un parámetro de regularización L1, es decir, tipo LASSO.</p>
<p>En este caso, además, usamos como parámetro para medir el inverso de la fuerza de la regularización el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>, y probamos 2 tipos de <code class="docutils literal notranslate"><span class="pre">solver</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;Lasso(LoReg)&#39;</span> <span class="c1">#Esto es para la tabla final de metricas</span>
<span class="n">lasso_clas</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">)</span> <span class="c1"># Aplicamos la regularizacion LASSO</span>
<span class="n">escaler</span><span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lasso_clas__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
              <span class="s1">&#39;lasso_clas__solver&#39;</span><span class="p">:[</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span><span class="s1">&#39;saga&#39;</span><span class="p">]}</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;escaler&#39;</span><span class="p">,</span> <span class="n">escaler</span> <span class="p">),</span> <span class="p">(</span><span class="s1">&#39;lasso_clas&#39;</span><span class="p">,</span><span class="n">lasso_clas</span><span class="p">)])</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-18" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;lasso_clas&#x27;,
                                        LogisticRegression(penalty=&#x27;l1&#x27;))]),
             param_grid={&#x27;lasso_clas__C&#x27;: [0.01, 1, 10],
                         &#x27;lasso_clas__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-60" type="checkbox" ><label for="sk-estimator-id-60" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;lasso_clas&#x27;,
                                        LogisticRegression(penalty=&#x27;l1&#x27;))]),
             param_grid={&#x27;lasso_clas__C&#x27;: [0.01, 1, 10],
                         &#x27;lasso_clas__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;]})</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-61" type="checkbox" ><label for="sk-estimator-id-61" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                (&#x27;lasso_clas&#x27;, LogisticRegression(penalty=&#x27;l1&#x27;))])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-62" type="checkbox" ><label for="sk-estimator-id-62" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-63" type="checkbox" ><label for="sk-estimator-id-63" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(penalty=&#x27;l1&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params:
{&#39;lasso_clas__C&#39;: 1, &#39;lasso_clas__solver&#39;: &#39;saga&#39;}

Best cross-validation score: 0.80
Test-set score: 0.82
Train-set score: 0.81
</pre></div>
</div>
</div>
</div>
<p>En comparación a los demás, este modelo  nos arroja mejores valores generales de accuracy, siendo los del testing, incluyo mayores a los del training</p>
<section id="id2">
<h4>Evaluando el modelo<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;Lasso_LoReg&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#Hacemos predicciones y las guardamos en los df</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">Lasso_LoReg</span>
<span class="n">y_score</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#metricas</span>
<span class="n">cm</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precission</span><span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span><span class="o">=</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">fscore</span><span class="o">=</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc_score</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="c1">#creando el dataset de metricas</span>
<span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">precission</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span><span class="n">fscore</span><span class="p">,</span><span class="n">auc_score</span><span class="p">]</span> <span class="c1">#Guarda en df de metricas</span>
<span class="n">metricas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precission&#39;</span><span class="p">,</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span><span class="s1">&#39;auc_score&#39;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">metricas</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">#Calculamos metricas y las guardamos en los df</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;metrics.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/88d51728b7aed8bf1dea136e25b46f53fd75a952ede2bdc43d4ef7b9d06b4569.png" src="_images/88d51728b7aed8bf1dea136e25b46f53fd75a952ede2bdc43d4ef7b9d06b4569.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grafico_curvaROC</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e90e504693237264704a8de99c58ef14dd7274d7f576e80e72a71b55c4e58075.png" src="_images/e90e504693237264704a8de99c58ef14dd7274d7f576e80e72a71b55c4e58075.png" />
</div>
</div>
</section>
</section>
<section id="modelo-naive-bayes">
<h3>MODELO NAIVE BAYES<a class="headerlink" href="#modelo-naive-bayes" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;NaiveBayes&#39;</span> <span class="c1">#Esto es para la tabla final de metricas</span>
<span class="n">nb</span><span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">score_cv</span><span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">nb</span><span class="p">,</span> <span class="n">X_trainval_resampled</span><span class="p">,</span><span class="n">y_trainval_resampled</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span> <span class="p">)</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span><span class="n">y_trainval_resampled</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-19" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-64" type="checkbox" checked><label for="sk-estimator-id-64" class="sk-toggleable__label sk-toggleable__label-arrow">GaussianNB</label><div class="sk-toggleable__content"><pre>GaussianNB()</pre></div></div></div></div></div></div></div>
</div>
<section id="id3">
<h4>Evaluando el modelo<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;NaiveBayes&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">NaiveBayes</span>
<span class="n">y_score</span><span class="o">=</span><span class="n">nb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#metricas</span>
<span class="n">cm</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precission</span><span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span><span class="o">=</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">fscore</span><span class="o">=</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc_score</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="c1">#creando el dataset de metricas</span>
<span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">precission</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span><span class="n">fscore</span><span class="p">,</span><span class="n">auc_score</span><span class="p">]</span> <span class="c1">#Guarda en df de metricas</span>
<span class="n">metricas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precission&#39;</span><span class="p">,</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span><span class="s1">&#39;auc_score&#39;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">metricas</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;metrics.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precission</th>
      <th>recall</th>
      <th>f1_score</th>
      <th>auc_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>K-NN</th>
      <td>0.256671</td>
      <td>0.631250</td>
      <td>0.364950</td>
      <td>0.826935</td>
    </tr>
    <tr>
      <th>Ridge</th>
      <td>0.086051</td>
      <td>0.729688</td>
      <td>0.153948</td>
      <td>0.845046</td>
    </tr>
    <tr>
      <th>Lasso(LoReg)</th>
      <td>0.093852</td>
      <td>0.715625</td>
      <td>0.165942</td>
      <td>0.847390</td>
    </tr>
    <tr>
      <th>NaiveBayes</th>
      <td>0.030398</td>
      <td>0.756250</td>
      <td>0.058447</td>
      <td>0.643038</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/02db913b17b5dd290148211c8295a154c57af670a517b05857576904976cd50f.png" src="_images/02db913b17b5dd290148211c8295a154c57af670a517b05857576904976cd50f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grafico_curvaROC</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/894a47b84ac5b7f1f6c3cb0477c6acaec72d223f8959b7595457d0739f4998ac.png" src="_images/894a47b84ac5b7f1f6c3cb0477c6acaec72d223f8959b7595457d0739f4998ac.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">report</span><span class="o">=</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       0.98      0.37      0.53     24360
         1.0       0.03      0.76      0.06       640

    accuracy                           0.38     25000
   macro avg       0.51      0.56      0.30     25000
weighted avg       0.96      0.38      0.52     25000
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="modelo-xgboost">
<h3>MODELO XGBoost<a class="headerlink" href="#modelo-xgboost" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;XGBoost&#39;</span> <span class="c1">#Esto es para la tabla final de metricas</span>
<span class="n">xgb</span><span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">escaler</span><span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;xgb__n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span>
    <span class="s1">&#39;xgb__learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="s1">&#39;xgb__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;escaler&#39;</span><span class="p">,</span> <span class="n">escaler</span> <span class="p">),</span> <span class="p">(</span><span class="s1">&#39;xgb&#39;</span><span class="p">,</span><span class="n">xgb</span><span class="p">)])</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-20" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;xgb&#x27;,
                                        XGBClassifier(base_score=None,
                                                      booster=None,
                                                      callbacks=None,
                                                      colsample_bylevel=None,
                                                      colsample_bynode=None,
                                                      colsample_bytree=None,
                                                      device=None,
                                                      early_stopping_rounds=None,
                                                      enable_categorical=False,
                                                      eval_metric=None,
                                                      feature_types=None,
                                                      gamma=None,
                                                      grow_policy=None,
                                                      importance_type=N...
                                                      max_cat_threshold=None,
                                                      max_cat_to_onehot=None,
                                                      max_delta_step=None,
                                                      max_depth=None,
                                                      max_leaves=None,
                                                      min_child_weight=None,
                                                      missing=nan,
                                                      monotone_constraints=None,
                                                      multi_strategy=None,
                                                      n_estimators=None,
                                                      n_jobs=None,
                                                      num_parallel_tree=None,
                                                      random_state=None, ...))]),
             param_grid={&#x27;xgb__learning_rate&#x27;: [0.01, 0.1],
                         &#x27;xgb__max_depth&#x27;: [3, 4, 5],
                         &#x27;xgb__n_estimators&#x27;: [100, 200, 300]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-65" type="checkbox" ><label for="sk-estimator-id-65" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;xgb&#x27;,
                                        XGBClassifier(base_score=None,
                                                      booster=None,
                                                      callbacks=None,
                                                      colsample_bylevel=None,
                                                      colsample_bynode=None,
                                                      colsample_bytree=None,
                                                      device=None,
                                                      early_stopping_rounds=None,
                                                      enable_categorical=False,
                                                      eval_metric=None,
                                                      feature_types=None,
                                                      gamma=None,
                                                      grow_policy=None,
                                                      importance_type=N...
                                                      max_cat_threshold=None,
                                                      max_cat_to_onehot=None,
                                                      max_delta_step=None,
                                                      max_depth=None,
                                                      max_leaves=None,
                                                      min_child_weight=None,
                                                      missing=nan,
                                                      monotone_constraints=None,
                                                      multi_strategy=None,
                                                      n_estimators=None,
                                                      n_jobs=None,
                                                      num_parallel_tree=None,
                                                      random_state=None, ...))]),
             param_grid={&#x27;xgb__learning_rate&#x27;: [0.01, 0.1],
                         &#x27;xgb__max_depth&#x27;: [3, 4, 5],
                         &#x27;xgb__n_estimators&#x27;: [100, 200, 300]})</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-66" type="checkbox" ><label for="sk-estimator-id-66" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                (&#x27;xgb&#x27;,
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=None,
                               num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-67" type="checkbox" ><label for="sk-estimator-id-67" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-68" type="checkbox" ><label for="sk-estimator-id-68" class="sk-toggleable__label sk-toggleable__label-arrow">XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params:
{&#39;xgb__learning_rate&#39;: 0.1, &#39;xgb__max_depth&#39;: 5, &#39;xgb__n_estimators&#39;: 300}

Best cross-validation score: 0.99
Test-set score: 0.98
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train-set score: 0.99
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">XGBoost</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="id4">
<h4>Evaluando el modelo<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">XGBoost</span>
<span class="n">y_score</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#metricas</span>
<span class="n">cm</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precission</span><span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span><span class="o">=</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">fscore</span><span class="o">=</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc_score</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="c1">#creando el dataset de metricas</span>
<span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">precission</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span><span class="n">fscore</span><span class="p">,</span><span class="n">auc_score</span><span class="p">]</span> <span class="c1">#Guarda en df de metricas</span>
<span class="n">metricas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precission&#39;</span><span class="p">,</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span><span class="s1">&#39;auc_score&#39;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">metricas</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;metrics.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precission</th>
      <th>recall</th>
      <th>f1_score</th>
      <th>auc_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>K-NN</th>
      <td>0.256671</td>
      <td>0.631250</td>
      <td>0.364950</td>
      <td>0.826935</td>
    </tr>
    <tr>
      <th>Ridge</th>
      <td>0.086051</td>
      <td>0.729688</td>
      <td>0.153948</td>
      <td>0.845046</td>
    </tr>
    <tr>
      <th>Lasso(LoReg)</th>
      <td>0.093852</td>
      <td>0.715625</td>
      <td>0.165942</td>
      <td>0.847390</td>
    </tr>
    <tr>
      <th>NaiveBayes</th>
      <td>0.030398</td>
      <td>0.756250</td>
      <td>0.058447</td>
      <td>0.643038</td>
    </tr>
    <tr>
      <th>XGBoost</th>
      <td>0.893617</td>
      <td>0.393750</td>
      <td>0.546638</td>
      <td>0.910266</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1f02717d46861ea9f6ff824f7a876eabb5759e63f3741d2129ba18194f4a8dff.png" src="_images/1f02717d46861ea9f6ff824f7a876eabb5759e63f3741d2129ba18194f4a8dff.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grafico_curvaROC</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/22f218cf5bc8926cb921b763b6f0f1cbbc6b94ac08389c85d8a5881429c05474.png" src="_images/22f218cf5bc8926cb921b763b6f0f1cbbc6b94ac08389c85d8a5881429c05474.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">report</span><span class="o">=</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

         0.0       0.98      1.00      0.99     24360
         1.0       0.89      0.39      0.55       640

    accuracy                           0.98     25000
   macro avg       0.94      0.70      0.77     25000
weighted avg       0.98      0.98      0.98     25000
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="reduccion-de-dataset-para-poder-correr-los-modelos-faltantes">
<h2>Reducción de dataset para poder correr los modelos faltantes:<a class="headerlink" href="#reduccion-de-dataset-para-poder-correr-los-modelos-faltantes" title="Permalink to this heading">#</a></h2>
<p>Debido a multiples intentos fallidos de entrenar los modelos a continuación, me vi en la necesidad de reducir la cantidad de filas del dataset.</p>
<p>Para eso, utilizaré el 10% de los datos que obtendré a través de un sampling aleatorio.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_trainval_reduced</span> <span class="o">=</span> <span class="n">X_trainval_resampled</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">y_trainval_reduced</span> <span class="o">=</span> <span class="n">y_trainval_resampled</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="modelo-svm">
<h3>MODELO SVM<a class="headerlink" href="#modelo-svm" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;SVM&#39;</span> <span class="c1">#Esto es para la tabla final de metricas</span>
<span class="n">svc</span><span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">escaler</span><span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;svc__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s1">&#39;svc__gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;scv__kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span><span class="s1">&#39;rbf&#39;</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;escaler&#39;</span><span class="p">,</span> <span class="n">escaler</span> <span class="p">),</span> <span class="p">(</span><span class="s1">&#39;svc&#39;</span><span class="p">,</span><span class="n">svc</span><span class="p">)])</span>
<span class="n">grid_svc</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval_reduced</span><span class="p">,</span> <span class="n">y_trainval_reduced</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, MinMaxScaler()),
                                       (&#x27;svc&#x27;, SVC())]),
             param_grid={&#x27;svc__C&#x27;: [0.1, 1, 10], &#x27;svc__gamma&#x27;: [0.01, 0.1, 1]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, MinMaxScaler()),
                                       (&#x27;svc&#x27;, SVC())]),
             param_grid={&#x27;svc__C&#x27;: [0.1, 1, 10], &#x27;svc__gamma&#x27;: [0.01, 0.1, 1]})</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;escaler&#x27;, MinMaxScaler()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">MinMaxScaler</label><div class="sk-toggleable__content"><pre>MinMaxScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">joblib</span>
<span class="n">mejor_svm</span> <span class="o">=</span> <span class="n">grid_svc</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">mejor_svm</span><span class="p">,</span> <span class="s1">&#39;SVM_fraud.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;SVM_fraud.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_svc</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_svc</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid_svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params:
{&#39;svc__C&#39;: 10, &#39;svc__gamma&#39;: 1}

Best cross-validation score: 0.97
Test-set score: 0.96
Train-set score: 0.98
</pre></div>
</div>
</div>
</div>
<section id="id5">
<h4>Evaluando el modelo<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;SVM&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">SVM</span>
<span class="n">y_score</span><span class="o">=</span><span class="n">grid_svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#metricas</span>
<span class="n">cm</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precission</span><span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span><span class="o">=</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">fscore</span><span class="o">=</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc_score</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="c1">#creando el dataset de metricas</span>
<span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">precission</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span><span class="n">fscore</span><span class="p">,</span><span class="n">auc_score</span><span class="p">]</span> <span class="c1">#Guarda en df de metricas</span>
<span class="n">metricas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precission&#39;</span><span class="p">,</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span><span class="s1">&#39;auc_score&#39;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">metricas</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;metrics.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-321ab6a1-30cf-498a-b75f-1b48fe759289" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precission</th>
      <th>recall</th>
      <th>f1_score</th>
      <th>auc_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>K-NN</th>
      <td>0.256671</td>
      <td>0.631250</td>
      <td>0.364950</td>
      <td>0.826935</td>
    </tr>
    <tr>
      <th>Ridge</th>
      <td>0.086051</td>
      <td>0.729688</td>
      <td>0.153948</td>
      <td>0.845046</td>
    </tr>
    <tr>
      <th>Lasso(LoReg)</th>
      <td>0.093852</td>
      <td>0.715625</td>
      <td>0.165942</td>
      <td>0.847390</td>
    </tr>
    <tr>
      <th>NaiveBayes</th>
      <td>0.030398</td>
      <td>0.756250</td>
      <td>0.058447</td>
      <td>0.643038</td>
    </tr>
    <tr>
      <th>XGBoost</th>
      <td>0.893617</td>
      <td>0.393750</td>
      <td>0.546638</td>
      <td>0.910266</td>
    </tr>
    <tr>
      <th>SVM</th>
      <td>0.329486</td>
      <td>0.490625</td>
      <td>0.394225</td>
      <td>0.872142</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-321ab6a1-30cf-498a-b75f-1b48fe759289')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-321ab6a1-30cf-498a-b75f-1b48fe759289 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-321ab6a1-30cf-498a-b75f-1b48fe759289');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-b1cd3bc6-95e5-4ef2-960d-1d13d9b8ba4e">
  <button class="colab-df-quickchart" onclick="quickchart('df-b1cd3bc6-95e5-4ef2-960d-1d13d9b8ba4e')"
            title="Suggest charts."
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-b1cd3bc6-95e5-4ef2-960d-1d13d9b8ba4e button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1b5837c533aa8f773c88a0e9665a052d83899f9262c81ec5770baa3b1d27a12f.png" src="_images/1b5837c533aa8f773c88a0e9665a052d83899f9262c81ec5770baa3b1d27a12f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grafico_curvaROC</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f43e792feabb71a5310058d640c49f0bb31e5e77102e29c6ba0c508f0980d7e0.png" src="_images/f43e792feabb71a5310058d640c49f0bb31e5e77102e29c6ba0c508f0980d7e0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">report</span><span class="o">=</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="modelo-mlp">
<h3>MODELO MLP<a class="headerlink" href="#modelo-mlp" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;MLP&#39;</span> <span class="c1">#Esto es para la tabla final de metricas</span>
<span class="n">mlp</span><span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">()</span>
<span class="n">escaler</span><span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;mlp__hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span>
    <span class="s1">&#39;mlp__activation&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="s1">&#39;tanh&#39;</span><span class="p">],</span>
    <span class="s1">&#39;mlp__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="p">}</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;escaler&#39;</span><span class="p">,</span> <span class="n">escaler</span> <span class="p">),</span> <span class="p">(</span><span class="s1">&#39;mlp&#39;</span><span class="p">,</span><span class="n">mlp</span><span class="p">)])</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainval_reduced</span><span class="p">,</span> <span class="n">y_trainval_reduced</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;mlp&#x27;, MLPClassifier())]),
             param_grid={&#x27;mlp__activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],
                         &#x27;mlp__alpha&#x27;: [0.0001, 0.001, 0.01],
                         &#x27;mlp__hidden_layer_sizes&#x27;: [50, 20]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" ><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()),
                                       (&#x27;mlp&#x27;, MLPClassifier())]),
             param_grid={&#x27;mlp__activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],
                         &#x27;mlp__alpha&#x27;: [0.0001, 0.001, 0.01],
                         &#x27;mlp__hidden_layer_sizes&#x27;: [50, 20]})</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;escaler&#x27;, StandardScaler()), (&#x27;mlp&#x27;, MLPClassifier())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">MLPClassifier</label><div class="sk-toggleable__content"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best params:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best cross-validation score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train-set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_trainval_resampled</span><span class="p">,</span> <span class="n">y_trainval_resampled</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best params:
{&#39;mlp__activation&#39;: &#39;relu&#39;, &#39;mlp__alpha&#39;: 0.01, &#39;mlp__hidden_layer_sizes&#39;: 50}

Best cross-validation score: 0.94
Test-set score: 0.92
Train-set score: 0.95
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;MLP&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">MLP</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="id6">
<h4>Evaluando el modelo<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;MLP&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span><span class="o">=</span><span class="n">predictions</span><span class="o">.</span><span class="n">MLP</span>
<span class="n">y_score</span><span class="o">=</span><span class="n">grid</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predictions.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#metricas</span>
<span class="n">cm</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">precission</span><span class="o">=</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span><span class="o">=</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">fscore</span><span class="o">=</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">auc_score</span><span class="o">=</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="o">=</span><span class="n">y_score</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="c1">#creando el dataset de metricas</span>
<span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">precission</span><span class="p">,</span><span class="n">recall</span><span class="p">,</span><span class="n">fscore</span><span class="p">,</span><span class="n">auc_score</span><span class="p">]</span> <span class="c1">#Guarda en df de metricas</span>
<span class="n">metricas</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;precission&#39;</span><span class="p">,</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span><span class="s1">&#39;auc_score&#39;</span><span class="p">]</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">(</span><span class="n">metricas</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-90cb9f79-84ce-4406-8a01-bbf7856363c0" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precission</th>
      <th>recall</th>
      <th>f1_score</th>
      <th>auc_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>K-NN</th>
      <td>0.256671</td>
      <td>0.631250</td>
      <td>0.364950</td>
      <td>0.826935</td>
    </tr>
    <tr>
      <th>Ridge</th>
      <td>0.086051</td>
      <td>0.729688</td>
      <td>0.153948</td>
      <td>0.845046</td>
    </tr>
    <tr>
      <th>Lasso(LoReg)</th>
      <td>0.093852</td>
      <td>0.715625</td>
      <td>0.165942</td>
      <td>0.847390</td>
    </tr>
    <tr>
      <th>NaiveBayes</th>
      <td>0.030398</td>
      <td>0.756250</td>
      <td>0.058447</td>
      <td>0.643038</td>
    </tr>
    <tr>
      <th>XGBoost</th>
      <td>0.893617</td>
      <td>0.393750</td>
      <td>0.546638</td>
      <td>0.910266</td>
    </tr>
    <tr>
      <th>SVM</th>
      <td>0.329486</td>
      <td>0.490625</td>
      <td>0.394225</td>
      <td>0.872142</td>
    </tr>
    <tr>
      <th>MLP</th>
      <td>0.179944</td>
      <td>0.600000</td>
      <td>0.276857</td>
      <td>0.852134</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-90cb9f79-84ce-4406-8a01-bbf7856363c0')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-90cb9f79-84ce-4406-8a01-bbf7856363c0 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-90cb9f79-84ce-4406-8a01-bbf7856363c0');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-80da561e-65d7-40a5-9b76-8ed1f674b368">
  <button class="colab-df-quickchart" onclick="quickchart('df-80da561e-65d7-40a5-9b76-8ed1f674b368')"
            title="Suggest charts."
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-80da561e-65d7-40a5-9b76-8ed1f674b368 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">confusion_matriz</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/07b84ccb880a692a03eaa01a0dff99254ef7ab5c38b1bd1ad95ac98eac0213c3.png" src="_images/07b84ccb880a692a03eaa01a0dff99254ef7ab5c38b1bd1ad95ac98eac0213c3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grafico_curvaROC</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">roc_auc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e9f21020a384b76196433c1d7feeb8b58a82b5c14e72c53836f56c161377e47a.png" src="_images/e9f21020a384b76196433c1d7feeb8b58a82b5c14e72c53836f56c161377e47a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">report</span><span class="o">=</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.99      0.93      0.96     24360
           1       0.18      0.60      0.28       640

    accuracy                           0.92     25000
   macro avg       0.58      0.76      0.62     25000
weighted avg       0.97      0.92      0.94     25000
</pre></div>
</div>
</div>
</div>
<p>Una vez entrenados y evaluados los modelos, escojamos el mejor a partir de la Métrica AUC</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-866cc446-811e-4622-a017-bf63f247ef69" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>precission</th>
      <th>recall</th>
      <th>f1_score</th>
      <th>auc_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>K-NN</th>
      <td>0.256671</td>
      <td>0.631250</td>
      <td>0.364950</td>
      <td>0.826935</td>
    </tr>
    <tr>
      <th>Ridge</th>
      <td>0.086051</td>
      <td>0.729688</td>
      <td>0.153948</td>
      <td>0.845046</td>
    </tr>
    <tr>
      <th>Lasso(LoReg)</th>
      <td>0.093852</td>
      <td>0.715625</td>
      <td>0.165942</td>
      <td>0.847390</td>
    </tr>
    <tr>
      <th>NaiveBayes</th>
      <td>0.030398</td>
      <td>0.756250</td>
      <td>0.058447</td>
      <td>0.643038</td>
    </tr>
    <tr>
      <th>XGBoost</th>
      <td>0.893617</td>
      <td>0.393750</td>
      <td>0.546638</td>
      <td>0.910266</td>
    </tr>
    <tr>
      <th>SVM</th>
      <td>0.329486</td>
      <td>0.490625</td>
      <td>0.394225</td>
      <td>0.872142</td>
    </tr>
    <tr>
      <th>MLP</th>
      <td>0.179944</td>
      <td>0.600000</td>
      <td>0.276857</td>
      <td>0.852134</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-866cc446-811e-4622-a017-bf63f247ef69')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-866cc446-811e-4622-a017-bf63f247ef69 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-866cc446-811e-4622-a017-bf63f247ef69');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-93a13e80-f863-4559-8ad1-343a92d3f01a">
  <button class="colab-df-quickchart" onclick="quickchart('df-93a13e80-f863-4559-8ad1-343a92d3f01a')"
            title="Suggest charts."
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-93a13e80-f863-4559-8ad1-343a92d3f01a button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
    </div>
  </div>
</div></div>
</div>
</section>
</section>
</section>
<section id="mejor-modelo">
<h2>MEJOR MODELO<a class="headerlink" href="#mejor-modelo" title="Permalink to this heading">#</a></h2>
<p>El mejor modelo para clasificar transacciones fraudulentas a partir de su AUC sería el <strong>XGBoost</strong>, sin embargo, para el objetivo de este caso, yo necesito realmente un modelo que tenga un excelente recall en la clase 0. El XGBoost aunque es muy bueno detectando la clase 1, tiene muchas fallas en la clase 0, lo cual me costaría mucho dinero, tiene muchos <em>falsos negativos</em>.</p>
<p>En este sentido, el que tiene menor cantidad de Falsons Negativos es Naive Bayes, pero sus Falsos Positivos son desproporcionados, lo cual tampoco es lo ideal, este modelo sería extremadamente paranoico.</p>
<p>Considero que el modelo con el que mejor podríamos trabajar los casos de fraude sería el de <strong>Ridge</strong>, tiene muy baja tasa de falsos negativos, en buen balance con los falsos positivos, su recall es bueno para el negocio. Además sus otras métricas como precisión, AUC también son muy buenas.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Welcome to your Jupyter Book</p>
      </div>
    </a>
    <a class="right-next"
       href="WIND_SPEED.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">EJERCICIO 4B Y 5. PREDICCIONES DE VELOCIDAD DEL VIENTO</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lectura-de-datos-y-merge">Lectura de datos y merge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manejo-de-datos-nulos">MANEJO DE DATOS NULOS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizaciones-y-estadistica-descriptiva">VISUALIZACIONES Y ESTADISTICA DESCRIPTIVA</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-bivariado">Analisis Bivariado</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering">FEATURE ENGINEERING</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#identificando-columnas-altamente-correlacionadas-con-vif">IDENTIFICANDO COLUMNAS ALTAMENTE CORRELACIONADAS CON VIF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-hot-encoder-para-variables-categoricas">One Hot Encoder para variables categóricas</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluando-modelos-de-clasificacion-fraude">EVALUANDO MODELOS DE CLASIFICACION - FRAUDE</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#oversampling">OVERSAMPLING</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-knn-clasificador">Modelo KNN - Clasificador</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluando-el-modelo">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-ridge">MODELO RIDGE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-lasso-regresion-logistica-con-regularizacion-l1">MODELO LASSO - Regresión Logística con Regularización L1</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-naive-bayes">MODELO NAIVE BAYES</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-xgboost">MODELO XGBoost</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Evaluando el modelo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reduccion-de-dataset-para-poder-correr-los-modelos-faltantes">Reducción de dataset para poder correr los modelos faltantes:</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-svm">MODELO SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Evaluando el modelo</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-mlp">MODELO MLP</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Evaluando el modelo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mejor-modelo">MEJOR MODELO</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gina Buvoli
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>